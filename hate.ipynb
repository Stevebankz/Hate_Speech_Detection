{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1mdyaiJgIINv0TY4bTWVh0-KdFXCNLmZ2",
      "authorship_tag": "ABX9TyMxCmUXQfzBWsAwlJkOP5yD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce3f389f3e144cd781ed28ad6a07b2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e27d450cc7614d728c2f41e25300ddc7",
              "IPY_MODEL_d61acd224c0b4eb3b7bf7b413f25ace4",
              "IPY_MODEL_6fff5f5d51784dedad041626293c3760"
            ],
            "layout": "IPY_MODEL_166e7698b7a94d508259b1f3b6dd4745"
          }
        },
        "e27d450cc7614d728c2f41e25300ddc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e33ef85610da49daa2a7e88409c96516",
            "placeholder": "​",
            "style": "IPY_MODEL_1c6c9cae14e649afa3fcd2b57f8c7bc5",
            "value": "Map: 100%"
          }
        },
        "d61acd224c0b4eb3b7bf7b413f25ace4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3e24e5607d54895b11c98e58b5921fe",
            "max": 15383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea8b0743d3a94499a1804278ab6f312e",
            "value": 15383
          }
        },
        "6fff5f5d51784dedad041626293c3760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1aa00545a96401aa8741fdce1362edc",
            "placeholder": "​",
            "style": "IPY_MODEL_c6cba0cb20074a9cbefc7c7412d54cb1",
            "value": " 15383/15383 [00:01&lt;00:00, 10751.79 examples/s]"
          }
        },
        "166e7698b7a94d508259b1f3b6dd4745": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e33ef85610da49daa2a7e88409c96516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6c9cae14e649afa3fcd2b57f8c7bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3e24e5607d54895b11c98e58b5921fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea8b0743d3a94499a1804278ab6f312e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1aa00545a96401aa8741fdce1362edc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6cba0cb20074a9cbefc7c7412d54cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a98418f9531841c7b56ba3d55a600a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63255c1ef487417995dc19e8e05aeb0a",
              "IPY_MODEL_e3b4df6d3fad40c091a7c2874f83d496",
              "IPY_MODEL_50e508462daf41429b8fcb55cd93a1e9"
            ],
            "layout": "IPY_MODEL_b3485cc3d0314fdfad8f3a8346563b15"
          }
        },
        "63255c1ef487417995dc19e8e05aeb0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d666371fcf4ad387867c4fa445e312",
            "placeholder": "​",
            "style": "IPY_MODEL_ca68266624244a5dbd9294eb7f45cab0",
            "value": "Map: 100%"
          }
        },
        "e3b4df6d3fad40c091a7c2874f83d496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61bd5fd83bc94ceb98e13e0a11408bb9",
            "max": 1922,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3efeb7ec4184a4887ca4ffd3259ec05",
            "value": 1922
          }
        },
        "50e508462daf41429b8fcb55cd93a1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3a485ed9110468a8820337e73b8328a",
            "placeholder": "​",
            "style": "IPY_MODEL_f4945d5e2f514de9995a5ada386dab00",
            "value": " 1922/1922 [00:00&lt;00:00, 10762.13 examples/s]"
          }
        },
        "b3485cc3d0314fdfad8f3a8346563b15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01d666371fcf4ad387867c4fa445e312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca68266624244a5dbd9294eb7f45cab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61bd5fd83bc94ceb98e13e0a11408bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3efeb7ec4184a4887ca4ffd3259ec05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3a485ed9110468a8820337e73b8328a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4945d5e2f514de9995a5ada386dab00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b00b396db160437bb365d2dd88656299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c74d7e69b8dc4b498c84901c052035c2",
              "IPY_MODEL_fc0491247aa54d6b9c5e338b0e4d9480",
              "IPY_MODEL_fd2884d09df24b6ea3e8767cadd06869"
            ],
            "layout": "IPY_MODEL_c44a16051b0542efa431ee35acea1490"
          }
        },
        "c74d7e69b8dc4b498c84901c052035c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_855d93c25a4b44dc9a793d2a1355aa32",
            "placeholder": "​",
            "style": "IPY_MODEL_4d4add54d7724054956a3198abc545b7",
            "value": "Map: 100%"
          }
        },
        "fc0491247aa54d6b9c5e338b0e4d9480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37f0f063cf02450981b98aeb6c3a5d3d",
            "max": 1924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a5298c146314f8ea212ab41f5647fbb",
            "value": 1924
          }
        },
        "fd2884d09df24b6ea3e8767cadd06869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_118e72c7564c4384954ad228bc89d956",
            "placeholder": "​",
            "style": "IPY_MODEL_b9fbaca37c894616baa4b9ba0f3b7570",
            "value": " 1924/1924 [00:00&lt;00:00, 9619.70 examples/s]"
          }
        },
        "c44a16051b0542efa431ee35acea1490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "855d93c25a4b44dc9a793d2a1355aa32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d4add54d7724054956a3198abc545b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37f0f063cf02450981b98aeb6c3a5d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a5298c146314f8ea212ab41f5647fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "118e72c7564c4384954ad228bc89d956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9fbaca37c894616baa4b9ba0f3b7570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80f1d95d6b32434aa72a9e6b99d1f73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e5aa10b9b134bffa038403850d76c77",
              "IPY_MODEL_1ea3880fea3c49bea08a7f18b85b4361",
              "IPY_MODEL_d96d527cddc849df86bc35119fada77a"
            ],
            "layout": "IPY_MODEL_867c1bb91018415583d6a960bd963ce4"
          }
        },
        "3e5aa10b9b134bffa038403850d76c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a54cda9cd1048558d10cebe5df15223",
            "placeholder": "​",
            "style": "IPY_MODEL_8780315e2a7549af8a66cee0f55d1772",
            "value": "Bootstrapping: 100%"
          }
        },
        "1ea3880fea3c49bea08a7f18b85b4361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8efdd97071447998eb86073ee547357",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19f9af90563c43e49b120ff50a1001f4",
            "value": 1000
          }
        },
        "d96d527cddc849df86bc35119fada77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_491c89a152db4fc8a8197f12c3960310",
            "placeholder": "​",
            "style": "IPY_MODEL_b14fbc98a5484c71a088dd564804c321",
            "value": " 1000/1000 [56:02&lt;00:00,  3.34s/it]"
          }
        },
        "867c1bb91018415583d6a960bd963ce4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "6a54cda9cd1048558d10cebe5df15223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8780315e2a7549af8a66cee0f55d1772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8efdd97071447998eb86073ee547357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f9af90563c43e49b120ff50a1001f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "491c89a152db4fc8a8197f12c3960310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b14fbc98a5484c71a088dd564804c321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97a16f9addc74d8da08c077c076a91aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7da48a629f2f4015b49e6b63ecf9a72b",
              "IPY_MODEL_a1793d283e4544b5ab8b03a8dbedeeac",
              "IPY_MODEL_92acf3eca42c4f5e8880cb19181a895f"
            ],
            "layout": "IPY_MODEL_ad77fd70b75d43b6a9d5e6944346e950"
          }
        },
        "7da48a629f2f4015b49e6b63ecf9a72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_850b5cfb90ea4582b2caa53c73cfa0ac",
            "placeholder": "​",
            "style": "IPY_MODEL_77ed0f213ca34cd69dcb6a68fef25680",
            "value": "Map: 100%"
          }
        },
        "a1793d283e4544b5ab8b03a8dbedeeac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a211dbb0fff84a359b8cc1e504afa718",
            "max": 15383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b610bfccd884ca3b9db6faa6883dba9",
            "value": 15383
          }
        },
        "92acf3eca42c4f5e8880cb19181a895f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f61d8138d2374e8fa92fcc83a191fc01",
            "placeholder": "​",
            "style": "IPY_MODEL_3d62fd30369b49fdbfed5eff84fede13",
            "value": " 15383/15383 [00:01&lt;00:00, 10762.75 examples/s]"
          }
        },
        "ad77fd70b75d43b6a9d5e6944346e950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "850b5cfb90ea4582b2caa53c73cfa0ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ed0f213ca34cd69dcb6a68fef25680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a211dbb0fff84a359b8cc1e504afa718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b610bfccd884ca3b9db6faa6883dba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f61d8138d2374e8fa92fcc83a191fc01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d62fd30369b49fdbfed5eff84fede13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99f4ca6684694c40add3ac0e88671690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff4baaf7b2404b9c959da0e25859ee46",
              "IPY_MODEL_7f82c6030f3947faa6d03d6ec947077d",
              "IPY_MODEL_737687709b6c443fa593b08d309ab103"
            ],
            "layout": "IPY_MODEL_cacbf5dec92b424c9dea3718cee28be1"
          }
        },
        "ff4baaf7b2404b9c959da0e25859ee46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_effed0e8982449daa6fcab8a9aa213a0",
            "placeholder": "​",
            "style": "IPY_MODEL_8a336180fae64bf4bcbec016b76bb95c",
            "value": "Map: 100%"
          }
        },
        "7f82c6030f3947faa6d03d6ec947077d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6fe396f44414ce19baf9818887747c2",
            "max": 1922,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8e7d66fa6cd4a17abd12e3ef1fd226e",
            "value": 1922
          }
        },
        "737687709b6c443fa593b08d309ab103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c3e4839acb54b52843e603d9b2c373a",
            "placeholder": "​",
            "style": "IPY_MODEL_536775d93af1456bb814d5ff7ed017ae",
            "value": " 1922/1922 [00:00&lt;00:00, 11045.07 examples/s]"
          }
        },
        "cacbf5dec92b424c9dea3718cee28be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "effed0e8982449daa6fcab8a9aa213a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a336180fae64bf4bcbec016b76bb95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6fe396f44414ce19baf9818887747c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8e7d66fa6cd4a17abd12e3ef1fd226e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c3e4839acb54b52843e603d9b2c373a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "536775d93af1456bb814d5ff7ed017ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27bc0b1b4be447a384da70b5df52b787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9debc472234043ed84e626203b7cf645",
              "IPY_MODEL_07021ec0c4774a0e925ec2599789d4f7",
              "IPY_MODEL_b3bdac77d99c4b76906570aa4b88ebbf"
            ],
            "layout": "IPY_MODEL_2401d16d1d374179b7b2b194356a6baa"
          }
        },
        "9debc472234043ed84e626203b7cf645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e61ad21ed6804df4a1f3ff3fbbc3f4e2",
            "placeholder": "​",
            "style": "IPY_MODEL_9f8368fc293b47a78f27a804c2948c86",
            "value": "Map: 100%"
          }
        },
        "07021ec0c4774a0e925ec2599789d4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab7c8d8c73e04b82826e2c59c294ed97",
            "max": 1924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03c3890c65f0480da77c38f9aa111280",
            "value": 1924
          }
        },
        "b3bdac77d99c4b76906570aa4b88ebbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_746fbe62ba9f47ec8d622813dbd13139",
            "placeholder": "​",
            "style": "IPY_MODEL_1e152d199235483faf9ac7e84e8d3904",
            "value": " 1924/1924 [00:00&lt;00:00, 10763.17 examples/s]"
          }
        },
        "2401d16d1d374179b7b2b194356a6baa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e61ad21ed6804df4a1f3ff3fbbc3f4e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f8368fc293b47a78f27a804c2948c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab7c8d8c73e04b82826e2c59c294ed97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03c3890c65f0480da77c38f9aa111280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "746fbe62ba9f47ec8d622813dbd13139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e152d199235483faf9ac7e84e8d3904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82a3c3b4bee4452c8927ad663d25337a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f41dbb982162433582c7cb96ab7fdc64",
              "IPY_MODEL_bd7bf77597e94802ad7ae7dc5799d09c",
              "IPY_MODEL_9bdafc90174045108dad24843a8f89b0"
            ],
            "layout": "IPY_MODEL_8ecbc8564d944459896a6b9a166cb085"
          }
        },
        "f41dbb982162433582c7cb96ab7fdc64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf5639e4970842b0b82408739827a798",
            "placeholder": "​",
            "style": "IPY_MODEL_0d10fa7987b94e2a984b775868ae9b56",
            "value": "structural_typo:  59%"
          }
        },
        "bd7bf77597e94802ad7ae7dc5799d09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9636a38df29406b8910ea3576a4d530",
            "max": 928,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a34c92a3d50848759edd464601a50cc8",
            "value": 928
          }
        },
        "9bdafc90174045108dad24843a8f89b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c0ba49a7ae9443f8052aa1217c122a1",
            "placeholder": "​",
            "style": "IPY_MODEL_4fdf17468ccc406fac9d4c8ca8ccd11a",
            "value": " 543/928 [00:00&lt;00:00, 5429.07it/s]"
          }
        },
        "8ecbc8564d944459896a6b9a166cb085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "bf5639e4970842b0b82408739827a798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d10fa7987b94e2a984b775868ae9b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9636a38df29406b8910ea3576a4d530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34c92a3d50848759edd464601a50cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c0ba49a7ae9443f8052aa1217c122a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fdf17468ccc406fac9d4c8ca8ccd11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c278938dab84f7399894340765d5f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b9efb5614e24780aa8d182b73605b55",
              "IPY_MODEL_22bd8d9a39aa42d0937b1676f7e2f78f",
              "IPY_MODEL_6ed97a521fd043b991423dc2a4d8a50f"
            ],
            "layout": "IPY_MODEL_ca7b49bcd47342e1924e61772917c5d0"
          }
        },
        "1b9efb5614e24780aa8d182b73605b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59d4fe28421342de8a4ba419a28002da",
            "placeholder": "​",
            "style": "IPY_MODEL_3922cecd723c47d2887f8f5272a0195a",
            "value": "structural_insert:  67%"
          }
        },
        "22bd8d9a39aa42d0937b1676f7e2f78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce311821ac1e4f9f94e2e9c56f2802e2",
            "max": 928,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73c935a2a9f24a0a857fbc075fcbbe58",
            "value": 928
          }
        },
        "6ed97a521fd043b991423dc2a4d8a50f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9c75d37fc254b0ca2e859cd7b1a7738",
            "placeholder": "​",
            "style": "IPY_MODEL_4ba03d33c6c74b10aaa1afaf6dfc589d",
            "value": " 623/928 [00:00&lt;00:00, 6217.32it/s]"
          }
        },
        "ca7b49bcd47342e1924e61772917c5d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "59d4fe28421342de8a4ba419a28002da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3922cecd723c47d2887f8f5272a0195a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce311821ac1e4f9f94e2e9c56f2802e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73c935a2a9f24a0a857fbc075fcbbe58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9c75d37fc254b0ca2e859cd7b1a7738": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ba03d33c6c74b10aaa1afaf6dfc589d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5792058584d84d3788e40a7688896ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4224eca29eb04fb4a902efe1a29c9fde",
              "IPY_MODEL_bc68921440b5433ea63afb53ae1cc4f7",
              "IPY_MODEL_1fc88f37d0b440919ab13d33f1b83ed2"
            ],
            "layout": "IPY_MODEL_7689cbf2cf5044faaa379106d5203764"
          }
        },
        "4224eca29eb04fb4a902efe1a29c9fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dd0faf1f9284a49b8d7a4ffaa582d6d",
            "placeholder": "​",
            "style": "IPY_MODEL_7125c375a5ef4d73b1ed837f5a720490",
            "value": "structural_case:   0%"
          }
        },
        "bc68921440b5433ea63afb53ae1cc4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f654bba71cf8450ca02778b0fa2fcf98",
            "max": 928,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c692022b9814a7eb19feae90bd8dfd1",
            "value": 928
          }
        },
        "1fc88f37d0b440919ab13d33f1b83ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_744a63035630426782f7ad4abafc6c49",
            "placeholder": "​",
            "style": "IPY_MODEL_31f7def20bf74993855f5a7dfdc93e39",
            "value": " 0/928 [00:00&lt;?, ?it/s]"
          }
        },
        "7689cbf2cf5044faaa379106d5203764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "0dd0faf1f9284a49b8d7a4ffaa582d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7125c375a5ef4d73b1ed837f5a720490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f654bba71cf8450ca02778b0fa2fcf98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c692022b9814a7eb19feae90bd8dfd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "744a63035630426782f7ad4abafc6c49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f7def20bf74993855f5a7dfdc93e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed04f6d2467e4292856ba682eb632628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13cd5baa1d5b4e86a4d8ddaf4df62e4a",
              "IPY_MODEL_6a935f6bbba04852b2f53e422a10faab",
              "IPY_MODEL_78e7acd2d8014e76a5e783d409072447"
            ],
            "layout": "IPY_MODEL_0c42dd78246746c5aa8eb84b826df1a9"
          }
        },
        "13cd5baa1d5b4e86a4d8ddaf4df62e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_445f9359ce724636be5d475b4c1ef553",
            "placeholder": "​",
            "style": "IPY_MODEL_6b64f2c0c64a41028e6f2aa2bfe74a14",
            "value": "semantic_synonym:  96%"
          }
        },
        "6a935f6bbba04852b2f53e422a10faab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109541a9790445a389336c540b0d460b",
            "max": 928,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9cd3e743fe04e578bdb70d9e0ec8954",
            "value": 928
          }
        },
        "78e7acd2d8014e76a5e783d409072447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d755b8e6a5240de847e793c0a7e17b2",
            "placeholder": "​",
            "style": "IPY_MODEL_236298b4133a41ce98f472e6abea2b58",
            "value": " 895/928 [00:00&lt;00:00, 1130.61it/s]"
          }
        },
        "0c42dd78246746c5aa8eb84b826df1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "445f9359ce724636be5d475b4c1ef553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b64f2c0c64a41028e6f2aa2bfe74a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "109541a9790445a389336c540b0d460b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9cd3e743fe04e578bdb70d9e0ec8954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d755b8e6a5240de847e793c0a7e17b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "236298b4133a41ce98f472e6abea2b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce22140665e947e08301265087974789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e421c4681327420388eea72aca0f819c",
              "IPY_MODEL_48fe72652adc49a299d4c28271e9f8bf",
              "IPY_MODEL_1ad73f04c8c347ed9285ce510d4e7006"
            ],
            "layout": "IPY_MODEL_c91fb7b9a9054896a80c2e20553a333c"
          }
        },
        "e421c4681327420388eea72aca0f819c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ab5e30778ee40669c042f3dc676b154",
            "placeholder": "​",
            "style": "IPY_MODEL_782c9bd4420945ca97b283fbb9672420",
            "value": "semantic_coded:   0%"
          }
        },
        "48fe72652adc49a299d4c28271e9f8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56b9a63062134addb7c95f71319ce3aa",
            "max": 928,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a253b939d864ed4ac8df268c024b88d",
            "value": 928
          }
        },
        "1ad73f04c8c347ed9285ce510d4e7006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73104f6aa62147669fc7741b766d473e",
            "placeholder": "​",
            "style": "IPY_MODEL_8c11a330cfa242a086720b743ce1290b",
            "value": " 0/928 [00:00&lt;?, ?it/s]"
          }
        },
        "c91fb7b9a9054896a80c2e20553a333c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7ab5e30778ee40669c042f3dc676b154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "782c9bd4420945ca97b283fbb9672420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56b9a63062134addb7c95f71319ce3aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a253b939d864ed4ac8df268c024b88d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73104f6aa62147669fc7741b766d473e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c11a330cfa242a086720b743ce1290b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27e9ddfbb12d4b5195ab4d94c51c8617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d8a2383b39849b28119b4dd6ded6ed3",
              "IPY_MODEL_4ae25966565247efa014ff0843e54462",
              "IPY_MODEL_0764b8dbab7a4c9daf48b4165b908709"
            ],
            "layout": "IPY_MODEL_7c5e12c27bb94af290928bbef7a0881b"
          }
        },
        "2d8a2383b39849b28119b4dd6ded6ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4edab488e709437282ff794a9ce1e6ee",
            "placeholder": "​",
            "style": "IPY_MODEL_2f3951783d3c4766b3a9dbce2f72e338",
            "value": "feature_slur_removal:   0%"
          }
        },
        "4ae25966565247efa014ff0843e54462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce379ba5d1549b3b8e9b13fccc1b1c8",
            "max": 928,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_227481091aea48fe9230b896a5d6a03e",
            "value": 928
          }
        },
        "0764b8dbab7a4c9daf48b4165b908709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9ad0c0dea0e452982fbc2eb51a9f431",
            "placeholder": "​",
            "style": "IPY_MODEL_90b3913a0e524294ac1fbcb1ff1388d1",
            "value": " 0/928 [00:00&lt;?, ?it/s]"
          }
        },
        "7c5e12c27bb94af290928bbef7a0881b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "4edab488e709437282ff794a9ce1e6ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f3951783d3c4766b3a9dbce2f72e338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bce379ba5d1549b3b8e9b13fccc1b1c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "227481091aea48fe9230b896a5d6a03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9ad0c0dea0e452982fbc2eb51a9f431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90b3913a0e524294ac1fbcb1ff1388d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb4ad2120c534c0da2e198c3883a51f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6f277e6ba1749aa9a462c572f8aa782",
              "IPY_MODEL_48a34179311b4109a48b78d574d89123",
              "IPY_MODEL_38012fa5302748a38baf2a82c9bd8346"
            ],
            "layout": "IPY_MODEL_30e8cbc7e6ee4d07bd36d6d2dc932d09"
          }
        },
        "c6f277e6ba1749aa9a462c572f8aa782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77d5bca07e6e41bb986d17ce1373ddc8",
            "placeholder": "​",
            "style": "IPY_MODEL_67f7b5b2c2674234aa4f7e36a2d8d32f",
            "value": "structural_typo:   0%"
          }
        },
        "48a34179311b4109a48b78d574d89123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ec0a58fccc489a8ce6075a796dda09",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39c2086f848843bfbfc4f369d5a38109",
            "value": 22
          }
        },
        "38012fa5302748a38baf2a82c9bd8346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7922df282607478181f297f035f63255",
            "placeholder": "​",
            "style": "IPY_MODEL_ae4bca5acf754b0aae58c93bacc451ed",
            "value": " 0/22 [00:00&lt;?, ?it/s]"
          }
        },
        "30e8cbc7e6ee4d07bd36d6d2dc932d09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "77d5bca07e6e41bb986d17ce1373ddc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f7b5b2c2674234aa4f7e36a2d8d32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67ec0a58fccc489a8ce6075a796dda09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39c2086f848843bfbfc4f369d5a38109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7922df282607478181f297f035f63255": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae4bca5acf754b0aae58c93bacc451ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbfe46f159cf4579bc207d0a434f1494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0f6eb77390e473abf74513cef4b9873",
              "IPY_MODEL_7982f50eff244632a39103adfbe7d7d4",
              "IPY_MODEL_062cc6f3c2614e5caa92024b0bfd3829"
            ],
            "layout": "IPY_MODEL_1eb27dda4dcc4ba4a7d33612634f1755"
          }
        },
        "f0f6eb77390e473abf74513cef4b9873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c23b1fef0e046b9b61ab9413df731fc",
            "placeholder": "​",
            "style": "IPY_MODEL_474b9d09f15d4f63809346f79eda0946",
            "value": "structural_insert:   0%"
          }
        },
        "7982f50eff244632a39103adfbe7d7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccaaffdc7af14fff91017a73fbdb34ce",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0934499b2754b0da0516242c217011d",
            "value": 22
          }
        },
        "062cc6f3c2614e5caa92024b0bfd3829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99923880baf94c8eb026660ac2d803db",
            "placeholder": "​",
            "style": "IPY_MODEL_fa3975744b1e4cf7ab5f58394d9117ad",
            "value": " 0/22 [00:00&lt;?, ?it/s]"
          }
        },
        "1eb27dda4dcc4ba4a7d33612634f1755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "0c23b1fef0e046b9b61ab9413df731fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474b9d09f15d4f63809346f79eda0946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccaaffdc7af14fff91017a73fbdb34ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0934499b2754b0da0516242c217011d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99923880baf94c8eb026660ac2d803db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa3975744b1e4cf7ab5f58394d9117ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a72d1ab0dfd048cc83faf61e50a729bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dbd95898c214b19af7f0a0179d2a057",
              "IPY_MODEL_77af48280df14f9e9ebea1c3aaf67e8b",
              "IPY_MODEL_4714746792854773a328f1234392b783"
            ],
            "layout": "IPY_MODEL_724346869a5c499984360910e4196e99"
          }
        },
        "4dbd95898c214b19af7f0a0179d2a057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95c812a0d029456eab9b6d075585cc9d",
            "placeholder": "​",
            "style": "IPY_MODEL_1f84c1836a534466afa4ea670e2cc215",
            "value": "structural_case:   0%"
          }
        },
        "77af48280df14f9e9ebea1c3aaf67e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cc52028fc0c459b9bc7f9aefbeb9470",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c0879d199bf4a7da731930106b1886d",
            "value": 22
          }
        },
        "4714746792854773a328f1234392b783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_049637958a38473f9432a569bac1547f",
            "placeholder": "​",
            "style": "IPY_MODEL_7d821f8916fc403da974b48474effffa",
            "value": " 0/22 [00:00&lt;?, ?it/s]"
          }
        },
        "724346869a5c499984360910e4196e99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "95c812a0d029456eab9b6d075585cc9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f84c1836a534466afa4ea670e2cc215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cc52028fc0c459b9bc7f9aefbeb9470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0879d199bf4a7da731930106b1886d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "049637958a38473f9432a569bac1547f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d821f8916fc403da974b48474effffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad7cef0a1e744530973a8cc89d9601f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_759dbbbcfb7842dda1bf34012a365afb",
              "IPY_MODEL_3b8fe6da1b8944e584e57f6342def0c4",
              "IPY_MODEL_19153c92511e4f08af811239641c676f"
            ],
            "layout": "IPY_MODEL_32396861feb140d08ab9e384991c2550"
          }
        },
        "759dbbbcfb7842dda1bf34012a365afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1bbb08b70af4a5483d154b961ac85f9",
            "placeholder": "​",
            "style": "IPY_MODEL_ed768e0186244601a8f6c0376603de6d",
            "value": "semantic_synonym:   0%"
          }
        },
        "3b8fe6da1b8944e584e57f6342def0c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_812273d09fec44a88ddc3f8bab251609",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_135b5354e96e476b894ddef3e78f6d75",
            "value": 22
          }
        },
        "19153c92511e4f08af811239641c676f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5524201022149db8b6383c68a66bd9b",
            "placeholder": "​",
            "style": "IPY_MODEL_5c668fd7a5714c8bb0944cc85d383771",
            "value": " 0/22 [00:00&lt;?, ?it/s]"
          }
        },
        "32396861feb140d08ab9e384991c2550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "d1bbb08b70af4a5483d154b961ac85f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed768e0186244601a8f6c0376603de6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "812273d09fec44a88ddc3f8bab251609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "135b5354e96e476b894ddef3e78f6d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5524201022149db8b6383c68a66bd9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c668fd7a5714c8bb0944cc85d383771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "865514ce16b64d46a4d27e0d726ea067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b77ca096a17463c967a8198dc7b41cb",
              "IPY_MODEL_2a1d0a90a53f4c9d9c3ba09f1d6b1f24",
              "IPY_MODEL_d7e0db830d584ce087a52bb0ff6774a0"
            ],
            "layout": "IPY_MODEL_80c45ffe32c74e9fac7d5122ba2b3f7a"
          }
        },
        "9b77ca096a17463c967a8198dc7b41cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43591a8a49444b1f9ecc784d1860febb",
            "placeholder": "​",
            "style": "IPY_MODEL_b56fa61398e840c48263d308d03a58a6",
            "value": "semantic_coded:   0%"
          }
        },
        "2a1d0a90a53f4c9d9c3ba09f1d6b1f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e388a2190744e52939c19739637e351",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58a088f932af451f82a916b116c88369",
            "value": 22
          }
        },
        "d7e0db830d584ce087a52bb0ff6774a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_353fac709b81466f9194f9fafc4cfd54",
            "placeholder": "​",
            "style": "IPY_MODEL_6b4d52d9ab034a6082e2067360cec9ce",
            "value": " 0/22 [00:00&lt;?, ?it/s]"
          }
        },
        "80c45ffe32c74e9fac7d5122ba2b3f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "43591a8a49444b1f9ecc784d1860febb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56fa61398e840c48263d308d03a58a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e388a2190744e52939c19739637e351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a088f932af451f82a916b116c88369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "353fac709b81466f9194f9fafc4cfd54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b4d52d9ab034a6082e2067360cec9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ee0b9fc9d2f4b4587970052a2d99551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7a173336ea6450dabc293de35232fe6",
              "IPY_MODEL_a2effc89569b4a37b59f1de4c2d3dd09",
              "IPY_MODEL_cd4d08492c6f452d8d04a7fee0291b57"
            ],
            "layout": "IPY_MODEL_e28727a2561f4166b293fbfe5d452ad7"
          }
        },
        "c7a173336ea6450dabc293de35232fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d70439ae36234bebaf291b95acd7c75f",
            "placeholder": "​",
            "style": "IPY_MODEL_116dd84a05f5411ab4a401684c86dc1f",
            "value": "feature_slur_removal:   0%"
          }
        },
        "a2effc89569b4a37b59f1de4c2d3dd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6d1ed7856304f48877821a8b1ac4129",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b02c3402cf3481fb0ca9abb767726a5",
            "value": 22
          }
        },
        "cd4d08492c6f452d8d04a7fee0291b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f7dfda72cde48628f945cb008d35468",
            "placeholder": "​",
            "style": "IPY_MODEL_1245d4adc5ef424da355397e68c61bb7",
            "value": " 0/22 [00:00&lt;?, ?it/s]"
          }
        },
        "e28727a2561f4166b293fbfe5d452ad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "d70439ae36234bebaf291b95acd7c75f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "116dd84a05f5411ab4a401684c86dc1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6d1ed7856304f48877821a8b1ac4129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b02c3402cf3481fb0ca9abb767726a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f7dfda72cde48628f945cb008d35468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1245d4adc5ef424da355397e68c61bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3bda7b4f18549ecb50fff79af98c236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a17a1e5feb04ed2bda70b44bcb4d60c",
              "IPY_MODEL_ec9a8b560c0f447db8a7c97d5702d6be",
              "IPY_MODEL_d8887528199a4e1a9ff1c0488aab63b5"
            ],
            "layout": "IPY_MODEL_f61c6e29aa6c4d49949f51a395c8e889"
          }
        },
        "1a17a1e5feb04ed2bda70b44bcb4d60c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff7b382e1104fd583d48cd4ec3201e3",
            "placeholder": "​",
            "style": "IPY_MODEL_be5aa5f71bb84181a16b4ab3f99b534d",
            "value": "Generating test split: "
          }
        },
        "ec9a8b560c0f447db8a7c97d5702d6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e4b9fbc6e4b4badb1ba92b009636225",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13ed1ed551224643bdaf2f487d8830cc",
            "value": 1
          }
        },
        "d8887528199a4e1a9ff1c0488aab63b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40c0b0bc9de94928b20353ad2c1b4635",
            "placeholder": "​",
            "style": "IPY_MODEL_239b0e3569344ce8872048a9e20e1d2e",
            "value": " 1924/0 [00:00&lt;00:00, 53180.98 examples/s]"
          }
        },
        "f61c6e29aa6c4d49949f51a395c8e889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ff7b382e1104fd583d48cd4ec3201e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be5aa5f71bb84181a16b4ab3f99b534d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e4b9fbc6e4b4badb1ba92b009636225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "13ed1ed551224643bdaf2f487d8830cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40c0b0bc9de94928b20353ad2c1b4635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "239b0e3569344ce8872048a9e20e1d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22880230a7ab4c498c4157193991efe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be665d7524874e77a866c5e5017a47c8",
              "IPY_MODEL_2c07dad7f8484c55878932b001be4161",
              "IPY_MODEL_ccfe69a8170b4557926a0dc3ed7994fb"
            ],
            "layout": "IPY_MODEL_9c8d2f4ed1ab4fa69f093dac9dd09a30"
          }
        },
        "be665d7524874e77a866c5e5017a47c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_264f589bd6bc4afb9b7ea1533f8ad8be",
            "placeholder": "​",
            "style": "IPY_MODEL_bbcc331048944b90a4d620cc5389c334",
            "value": "config.json: 100%"
          }
        },
        "2c07dad7f8484c55878932b001be4161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8547bf98e4b042e9bfa2432d49f8c283",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a5c239d3b4b4bd9ae4c0a72e0310603",
            "value": 625
          }
        },
        "ccfe69a8170b4557926a0dc3ed7994fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6804799e35f4df1b0f6833c2fb41aa1",
            "placeholder": "​",
            "style": "IPY_MODEL_4e5c4ffcf08144aca735dfc4ec2337d2",
            "value": " 625/625 [00:00&lt;00:00, 72.4kB/s]"
          }
        },
        "9c8d2f4ed1ab4fa69f093dac9dd09a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "264f589bd6bc4afb9b7ea1533f8ad8be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbcc331048944b90a4d620cc5389c334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8547bf98e4b042e9bfa2432d49f8c283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a5c239d3b4b4bd9ae4c0a72e0310603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6804799e35f4df1b0f6833c2fb41aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e5c4ffcf08144aca735dfc4ec2337d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "689640d8a9434534b1d30fd31e039971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa5bf3fdc85b479ab2af7355e87cf529",
              "IPY_MODEL_c4195fd693c6407f9443cea79a394094",
              "IPY_MODEL_8f2f7f822dce45b8ba0323277c73a554"
            ],
            "layout": "IPY_MODEL_ffdb1c470a9e4b9db771b2e0d9ed5cb2"
          }
        },
        "aa5bf3fdc85b479ab2af7355e87cf529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8de5f1325cee4613b9150ddd2793b4b3",
            "placeholder": "​",
            "style": "IPY_MODEL_d5ec4ea32c1040a3af39272917f7fe93",
            "value": "model.safetensors: 100%"
          }
        },
        "c4195fd693c6407f9443cea79a394094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d75e0fb62fd429e9eb519e72ba34e40",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85a3383293184e528322d61d2cfa4b98",
            "value": 714290682
          }
        },
        "8f2f7f822dce45b8ba0323277c73a554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_337daf0e5e3b41988a37df6d7121ea2f",
            "placeholder": "​",
            "style": "IPY_MODEL_7472ae1240a7474e98295d40e9d2d1d2",
            "value": " 714M/714M [00:02&lt;00:00, 535MB/s]"
          }
        },
        "ffdb1c470a9e4b9db771b2e0d9ed5cb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8de5f1325cee4613b9150ddd2793b4b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5ec4ea32c1040a3af39272917f7fe93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d75e0fb62fd429e9eb519e72ba34e40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a3383293184e528322d61d2cfa4b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "337daf0e5e3b41988a37df6d7121ea2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7472ae1240a7474e98295d40e9d2d1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df6ac738edd54a2485a7ab0c6d1769a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_657a9694962744c99ada5af00470b3dd",
              "IPY_MODEL_393aa52cf6214ec79d1118164231652e",
              "IPY_MODEL_ad72e5c4243c432f89c750b7e86be7f0"
            ],
            "layout": "IPY_MODEL_d4a183a03ae34337bfa6035ced85ab4b"
          }
        },
        "657a9694962744c99ada5af00470b3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3140fd6dfb9f46d38fb6edc1c172b7b8",
            "placeholder": "​",
            "style": "IPY_MODEL_9055d956cfd746b28d819800cbdab728",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "393aa52cf6214ec79d1118164231652e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f8354463dd46eda374722142a6411d",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd0c970444ef498193c0ea37f1cce214",
            "value": 25
          }
        },
        "ad72e5c4243c432f89c750b7e86be7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d07765549bbb48f38856b9f6ccf3bff9",
            "placeholder": "​",
            "style": "IPY_MODEL_bd277eea6ca845edb14a8554fac766de",
            "value": " 25.0/25.0 [00:00&lt;00:00, 3.33kB/s]"
          }
        },
        "d4a183a03ae34337bfa6035ced85ab4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3140fd6dfb9f46d38fb6edc1c172b7b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9055d956cfd746b28d819800cbdab728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78f8354463dd46eda374722142a6411d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0c970444ef498193c0ea37f1cce214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d07765549bbb48f38856b9f6ccf3bff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd277eea6ca845edb14a8554fac766de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "928af9d495bc40258cc28035d0112c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e27bc9ae61344291a56f9c2243848ecb",
              "IPY_MODEL_010b60932e5f43eb879554fadbfae1c1",
              "IPY_MODEL_0b6380bba7fa4e168276d8fa670b2ee9"
            ],
            "layout": "IPY_MODEL_b3429e36508149f9913d8293b416e481"
          }
        },
        "e27bc9ae61344291a56f9c2243848ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d0a524505a4452da4020d9f1c3ef7d9",
            "placeholder": "​",
            "style": "IPY_MODEL_0d9e69ade2714fa48dfea1020bf1e7e2",
            "value": "config.json: 100%"
          }
        },
        "010b60932e5f43eb879554fadbfae1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c507d8ea3c143be9b98c159d1fe9367",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b956f76547114777a5d9636adac71330",
            "value": 615
          }
        },
        "0b6380bba7fa4e168276d8fa670b2ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9223d748493a49beb7313eabd33e0c31",
            "placeholder": "​",
            "style": "IPY_MODEL_39e5c69432154f199964ce7c35e199b4",
            "value": " 615/615 [00:00&lt;00:00, 82.5kB/s]"
          }
        },
        "b3429e36508149f9913d8293b416e481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d0a524505a4452da4020d9f1c3ef7d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d9e69ade2714fa48dfea1020bf1e7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c507d8ea3c143be9b98c159d1fe9367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b956f76547114777a5d9636adac71330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9223d748493a49beb7313eabd33e0c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39e5c69432154f199964ce7c35e199b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa2c9cb6984043c49c91e80417712bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab289549c720446482433fef13fd700d",
              "IPY_MODEL_2627aa812bd841aa9052217a959503d1",
              "IPY_MODEL_af059f9721f24303a08d20267b429540"
            ],
            "layout": "IPY_MODEL_2ea66461bd864709a7d07ae10a9b6387"
          }
        },
        "ab289549c720446482433fef13fd700d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f36646f41c9b474f822406dd4e150453",
            "placeholder": "​",
            "style": "IPY_MODEL_aa12d8acb3d9416fba94b5b13c445caf",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "2627aa812bd841aa9052217a959503d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_220f64f7b8be4afbb7c307218424804b",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7718d770ed4c411db028675b8ffe84e1",
            "value": 5069051
          }
        },
        "af059f9721f24303a08d20267b429540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2afe515d3b24c37a44a60dce28a1b3b",
            "placeholder": "​",
            "style": "IPY_MODEL_3e50d98382f8452085323ddaf9cedb37",
            "value": " 5.07M/5.07M [00:01&lt;00:00, 4.04MB/s]"
          }
        },
        "2ea66461bd864709a7d07ae10a9b6387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f36646f41c9b474f822406dd4e150453": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa12d8acb3d9416fba94b5b13c445caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "220f64f7b8be4afbb7c307218424804b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7718d770ed4c411db028675b8ffe84e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2afe515d3b24c37a44a60dce28a1b3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e50d98382f8452085323ddaf9cedb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c779d39f3ee54d2a838fef7cf93aa0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8970b676b8f04fcdb69ac44ae247b23a",
              "IPY_MODEL_7487ca9f14c046b8a9d1b686021778ff",
              "IPY_MODEL_c8774bc4c3604f76ac7ea63999149cd5"
            ],
            "layout": "IPY_MODEL_4c72f851c12d4a54820e282c99b24ab3"
          }
        },
        "8970b676b8f04fcdb69ac44ae247b23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b6a8d06a29c416184a61360f8da87c2",
            "placeholder": "​",
            "style": "IPY_MODEL_1a6d91f5263b4103b6a4aebc2b73a482",
            "value": "tokenizer.json: 100%"
          }
        },
        "7487ca9f14c046b8a9d1b686021778ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9d32a43d6374d748b9ef9de44826609",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_440a8f5eefc441a0b2447630494ef6c4",
            "value": 9096718
          }
        },
        "c8774bc4c3604f76ac7ea63999149cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6edbc089e8704acaa220ac2d9a0892ef",
            "placeholder": "​",
            "style": "IPY_MODEL_98114257003c4b158e1d7159f51e94be",
            "value": " 9.10M/9.10M [00:01&lt;00:00, 8.43MB/s]"
          }
        },
        "4c72f851c12d4a54820e282c99b24ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b6a8d06a29c416184a61360f8da87c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a6d91f5263b4103b6a4aebc2b73a482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9d32a43d6374d748b9ef9de44826609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "440a8f5eefc441a0b2447630494ef6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6edbc089e8704acaa220ac2d9a0892ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98114257003c4b158e1d7159f51e94be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3e9f44536fe464fa2c0b38a3f881438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_caa6a826b9e74ed2869aeb9983633778",
              "IPY_MODEL_d6657e1e9443493584695049324fa564",
              "IPY_MODEL_1fc3d74eefac4e1fb0f2b731b06aa6be"
            ],
            "layout": "IPY_MODEL_6111a0b3b7b14aabb31ad6489623cf9d"
          }
        },
        "caa6a826b9e74ed2869aeb9983633778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72e8cad1195f4e618871a6abff9e11dc",
            "placeholder": "​",
            "style": "IPY_MODEL_a0d86574539c489daf617028a569d828",
            "value": "model.safetensors: 100%"
          }
        },
        "d6657e1e9443493584695049324fa564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bd583e102c14279b04d3f517a132da3",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be1b9d1a67184e39b117306620f6586f",
            "value": 1115567652
          }
        },
        "1fc3d74eefac4e1fb0f2b731b06aa6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3edcf42816042ba98561567512da382",
            "placeholder": "​",
            "style": "IPY_MODEL_999f91846ef44867a58eef105bf4d326",
            "value": " 1.12G/1.12G [00:01&lt;00:00, 1.12GB/s]"
          }
        },
        "6111a0b3b7b14aabb31ad6489623cf9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72e8cad1195f4e618871a6abff9e11dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0d86574539c489daf617028a569d828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bd583e102c14279b04d3f517a132da3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be1b9d1a67184e39b117306620f6586f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3edcf42816042ba98561567512da382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999f91846ef44867a58eef105bf4d326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stevebankz/Hate_Speech_Detection/blob/main/hate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 1: Install Dependencies ---\n",
        "\n",
        "print(\"Installing required libraries...\")\n",
        "!pip install transformers datasets scikit-learn -q\n",
        "\n",
        "print(\"--- Cell 1 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 2: Import Libraries & Mount Google Drive ---\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "# Import individual metric functions\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils import resample\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "import gc # Garbage collector\n",
        "\n",
        "# Mount your Google Drive\n",
        "# This will prompt you for authorization.\n",
        "#print(\"Mounting Google Drive...\")\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "print(\"--- Cell 2 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 3: Define Configuration and Paths ---\n",
        "# We'll set all our paths and hyperparameters here.\n",
        "# This makes it super easy to change things later.\n",
        "\n",
        "class Config:\n",
        "    # --- Paths ---\n",
        "    # This is the base path in your Google Drive\n",
        "    DRIVE_PATH = '/content/drive/MyDrive/hate'\n",
        "\n",
        "    # --- IMPORTANT ---\n",
        "    # Change 'csv' to 'json' or 'parquet' if your files are not CSVs\n",
        "    DATA_FILE_TYPE = 'csv'\n",
        "\n",
        "    # Paths to your data files\n",
        "    TRAIN_FILE = os.path.join(DRIVE_PATH, 'train.csv')\n",
        "    VAL_FILE = os.path.join(DRIVE_PATH, 'val.csv')\n",
        "    TEST_FILE = os.path.join(DRIVE_PATH, 'test.csv')\n",
        "\n",
        "    # Where we will save the trained model\n",
        "    MODEL_SAVE_PATH = os.path.join(DRIVE_PATH, 'models/step1_bert_baseline')\n",
        "\n",
        "    # --- Model Configuration ---\n",
        "    # Since your data is multilingual, we CANNOT use 'bert-base-uncased'.\n",
        "    # We MUST use a multilingual model. 'bert-base-multilingual-cased' (mBERT)\n",
        "    # is the standard and perfect for this baseline.\n",
        "    MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "\n",
        "    # --- Training Hyperparameters ---\n",
        "    MAX_LENGTH = 128  # Max token length for sentences\n",
        "    BATCH_SIZE = 16   # Batch size for training and eval\n",
        "    EPOCHS = 5        # Number of training epochs (5 is a good start)\n",
        "    LEARNING_RATE = 2e-5 # Standard learning rate for fine-tuning BERT\n",
        "\n",
        "    # --- Labels ---\n",
        "    NUM_LABELS = 2 # 0 (Non-hate) and 1 (Hate)\n",
        "\n",
        "    # --- Evaluation ---\n",
        "    N_BOOTSTRAPS = 1000 # Number of bootstrap samples for CIs\n",
        "\n",
        "print(\"Configuration defined.\")\n",
        "print(f\"Model to be trained: {Config.MODEL_NAME}\")\n",
        "print(f\"Model will be saved to: {Config.MODEL_SAVE_PATH}\")\n",
        "print(f\"Will run {Config.N_BOOTSTRAPS} bootstrap iterations for CI.\")\n",
        "print(\"--- Cell 3 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 4: Check for GPU ---\n",
        "# Let's make sure we're using a GPU. Colab notebooks should have one.\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Awesome! We are using the GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"No GPU found. We are using the CPU (this will be SLOW).\")\n",
        "\n",
        "print(\"--- Cell 4 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 5: Load Dataset ---\n",
        "# We use the 'datasets' library to load our split files directly\n",
        "# into a DatasetDict object.\n",
        "\n",
        "print(f\"Loading data from {Config.DRIVE_PATH}...\")\n",
        "try:\n",
        "    data_files = {\n",
        "        'train': Config.TRAIN_FILE,\n",
        "        'validation': Config.VAL_FILE,\n",
        "        'test': Config.TEST_FILE\n",
        "    }\n",
        "\n",
        "\n",
        "    raw_datasets = load_dataset(Config.DATA_FILE_TYPE, data_files=data_files)\n",
        "\n",
        "    print(\"Data loaded successfully!\")\n",
        "    print(raw_datasets)\n",
        "\n",
        "    # Let's see an example\n",
        "    print(\"\\nExample from training set:\")\n",
        "    print(raw_datasets['train'][0])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"--- ERROR LOADING DATA ---\")\n",
        "    print(f\"Could not load data. Check your paths and file type ('{Config.DATA_FILE_TYPE}').\")\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "    raise\n",
        "\n",
        "print(\"--- Cell 5 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 6: Preprocessing (Tokenization) ---\n",
        "# convert our 'text' into numbers (tokens) .\n",
        "\n",
        "print(f\"Loading tokenizer for {Config.MODEL_NAME}...\")\n",
        "# We use AutoTokenizer to automatically load the correct one for mBERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "\n",
        "# This function will be applied to our entire dataset\n",
        "def tokenize_function(batch):\n",
        "    # 'text' is your text column.\n",
        "    # 'padding=\"max_length\"' pads all sentences to 128 tokens.\n",
        "    # 'truncation=True' cuts off sentences longer than 128 tokens.\n",
        "    return tokenizer(\n",
        "        batch['text'],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "print(\"Tokenizing datasets... (this may take a minute)\")\n",
        "\n",
        "# use .map() to apply the tokenization function to all splits\n",
        "# batched=True makes it much faster.\n",
        "# remove the original columns we don't need for training.\n",
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=['post_id', 'text', 'label_name', 'label_3class', 'targets'] # Remove all non-essential columns\n",
        ")\n",
        "\n",
        "# The Trainer expects the label column to be named 'labels'\n",
        "# rename our 'label' column\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# Set the format to 'torch' so it returns PyTorch tensors\n",
        "tokenized_datasets.set_format('torch')\n",
        "\n",
        "print(\"Tokenization complete.\")\n",
        "print(tokenized_datasets)\n",
        "print(\"\\nExample of processed data:\")\n",
        "print(tokenized_datasets['train'][0])\n",
        "\n",
        "print(\"--- Cell 6 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 7: Load Baseline Model ---\n",
        "# load the mBERT model, configured for sequence classification.\n",
        "\n",
        "print(f\"Loading pre-trained model: {Config.MODEL_NAME}...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    Config.MODEL_NAME,\n",
        "    num_labels=Config.NUM_LABELS # 2 labels: 0 (Non-hate) and 1 (Hate)\n",
        ")\n",
        "\n",
        "# Move the model to the GPU\n",
        "model.to(device)\n",
        "print(\"Model loaded and moved to GPU.\")\n",
        "print(\"--- Cell 7 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 8: Define Evaluation Metrics ---\n",
        "# This function is passed to the Trainer.\n",
        "# It calculates the F1, Precision, and Recall .\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Called by the Trainer at evaluation time.\n",
        "    \"\"\"\n",
        "    # eval_pred is a tuple of (logits, labels)\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    # Get the most likely prediction (index with the highest logit)\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Calculate metrics using individual functions\n",
        "    # We use 'macro' averaging as it's good for potentially imbalanced datasets\n",
        "    # and standard for classification tasks.\n",
        "    precision = precision_score(labels, predictions, average='macro')\n",
        "    recall = recall_score(labels, predictions, average='macro')\n",
        "    f1 = f1_score(labels, predictions, average='macro')\n",
        "\n",
        "\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    # Return as a dictionary\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "print(\"Metrics function 'compute_metrics' defined.\")\n",
        "print(\"--- Cell 8 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 9: Configure Training Arguments ---\n",
        "# This object holds all the training settings.\n",
        "\n",
        "print(\"Configuring training arguments...\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=Config.MODEL_SAVE_PATH,\n",
        "\n",
        "    # --- Training Hyperparameters ---\n",
        "    num_train_epochs=Config.EPOCHS,\n",
        "    learning_rate=Config.LEARNING_RATE,\n",
        "    per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "    per_device_eval_batch_size=Config.BATCH_SIZE * 2,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    # --- Evaluation and Saving ---\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "\n",
        "    # --- Logging (silence step logs, keep only tqdm bars) ---\n",
        "    report_to=\"none\",\n",
        "    logging_strategy=\"no\",     # <- no step/epoch log lines\n",
        "    disable_tqdm=False         # <- keep progress bars\n",
        ")\n",
        "\n",
        "\n",
        "print(\"--- Cell 9 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 10: Initialize Trainer ---\n",
        "# The Trainer class handles all the complexity of training and evaluation.\n",
        "\n",
        "print(\"Initializing Trainer...\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # The model we just loaded\n",
        "    args=training_args,                  # The training arguments we just defined\n",
        "    train_dataset=tokenized_datasets[\"train\"], # Our tokenized training data\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],  # Our tokenized validation data\n",
        "    tokenizer=tokenizer,                 # The tokenizer (so it can be saved with the model)\n",
        "    compute_metrics=compute_metrics      # The function to calculate our metrics\n",
        ")\n",
        "\n",
        "print(\"Trainer initialized.\")\n",
        "print(\"--- Cell 10 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 11: Train the Model ---\n",
        "#  We call .train() to start fine-tuning.\n",
        "\n",
        "print(\"--- STARTING BASELINE MODEL TRAINING ---\")\n",
        "print(f\"Training for {Config.EPOCHS} epochs...\")\n",
        "\n",
        "training_results = trainer.train()\n",
        "\n",
        "print(\"--- TRAINING COMPLETE ---\")\n",
        "print(\"--- Cell 11 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 12: Save the Best Model and Results ---\n",
        "\n",
        "\n",
        "print(f\"Saving the best model to {Config.MODEL_SAVE_PATH}...\")\n",
        "\n",
        "# This saves the model, tokenizer, and config files\n",
        "trainer.save_model(Config.MODEL_SAVE_PATH)\n",
        "\n",
        "# We'll also save the training results\n",
        "trainer.save_state()\n",
        "\n",
        "print(f\"Model successfully saved to {Config.MODEL_SAVE_PATH}\")\n",
        "print(\"--- Cell 12 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 13: Evaluate on the TEST Set (with Bootstrap CIs) ---\n",
        "\n",
        "\n",
        "print(\"--- EVALUATING ON THE TEST SET (SINGLE PASS) ---\")\n",
        "\n",
        "# We run one clean pass to get the point-estimate\n",
        "clean_test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "\n",
        "print(\"\\n\\n--- FINAL BASELINE MODEL TEST RESULTS (CLEAN) ---\")\n",
        "print(f\"Model: {Config.MODEL_NAME}\")\n",
        "print(f\"Test F1-Score:   {clean_test_results['eval_f1']:.4f}\")\n",
        "print(f\"Test Accuracy:   {clean_test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"Test Precision:  {clean_test_results['eval_precision']:.4f}\")\n",
        "print(f\"Test Recall:     {clean_test_results['eval_recall']:.4f}\")\n",
        "print(\"---------------------------------------------------\\n\")\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "print(f\"--- STARTING BOOTSTRAP EVALUATION ({Config.N_BOOTSTRAPS} iterations) ---\")\n",
        "\n",
        "test_dataset = tokenized_datasets[\"test\"]\n",
        "n_samples = len(test_dataset)\n",
        "boot_f1_scores = []\n",
        "boot_accuracy_scores = []\n",
        "boot_precision_scores = []\n",
        "boot_recall_scores = []\n",
        "\n",
        "for _ in tqdm(range(Config.N_BOOTSTRAPS), desc=\"Bootstrapping\", leave=False):\n",
        "    boot_indices = resample(range(n_samples), replace=True, n_samples=n_samples)\n",
        "    boot_sample = test_dataset.select(boot_indices)\n",
        "    boot_results = trainer.evaluate(boot_sample, metric_key_prefix=\"boot\")\n",
        "    boot_f1_scores.append(boot_results['boot_f1'])\n",
        "    boot_accuracy_scores.append(boot_results['boot_accuracy'])\n",
        "    boot_precision_scores.append(boot_results['boot_precision'])\n",
        "    boot_recall_scores.append(boot_results['boot_recall'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- BOOTSTRAP EVALUATION COMPLETE ---\")\n",
        "\n",
        "# Convert lists to numpy arrays for percentile calculation\n",
        "boot_f1_scores = np.array(boot_f1_scores)\n",
        "boot_accuracy_scores = np.array(boot_accuracy_scores)\n",
        "boot_precision_scores = np.array(boot_precision_scores)\n",
        "boot_recall_scores = np.array(boot_recall_scores)\n",
        "\n",
        "# Calculate 95% confidence intervals (from 2.5th to 97.5th percentile)\n",
        "f1_ci = np.percentile(boot_f1_scores, [2.5, 97.5])\n",
        "acc_ci = np.percentile(boot_accuracy_scores, [2.5, 97.5])\n",
        "prec_ci = np.percentile(boot_precision_scores, [2.5, 97.5])\n",
        "rec_ci = np.percentile(boot_recall_scores, [2.5, 97.5])\n",
        "\n",
        "# Calculate means\n",
        "f1_mean = np.mean(boot_f1_scores)\n",
        "acc_mean = np.mean(boot_accuracy_scores)\n",
        "prec_mean = np.mean(boot_precision_scores)\n",
        "rec_mean = np.mean(boot_recall_scores)\n",
        "\n",
        "print(\"\\n\\n--- FINAL BASELINE MODEL TEST RESULTS (BOOTSTRAPPED) ---\")\n",
        "print(f\"Metrics based on {Config.N_BOOTSTRAPS} bootstrap samples.\")\n",
        "print(f\"Format: Mean (95% CI)\")\n",
        "print(\"----------------------------------------------------------\")\n",
        "print(f\"Test F1-Score:   {f1_mean:.4f} (95% CI: [{f1_ci[0]:.4f}, {f1_ci[1]:.4f}])\")\n",
        "print(f\"Test Accuracy:   {acc_mean:.4f} (95% CI: [{acc_ci[0]:.4f}, {acc_ci[1]:.4f}])\")\n",
        "print(f\"Test Precision:  {prec_mean:.4f} (95% CI: [{prec_ci[0]:.4f}, {prec_ci[1]:.4f}])\")\n",
        "print(f\"Test Recall:     {rec_mean:.4f} (95% CI: [{rec_ci[0]:.4f}, {rec_ci[1]:.4f}])\")\n",
        "print(\"----------------------------------------------------------\\n\")\n",
        "\n",
        "\n",
        "# save these results to a file for our records\n",
        "results_file = os.path.join(Config.DRIVE_PATH, 'models', 'step1_baseline_results.txt')\n",
        "with open(results_file, 'w') as f:\n",
        "    f.write(\"--- FINAL BASELINE MODEL TEST RESULTS ---\\n\\n\")\n",
        "    f.write(f\"Model: {Config.MODEL_NAME}\\n\\n\")\n",
        "\n",
        "    f.write(\"--- SINGLE PASS (CLEAN) RESULTS ---\\n\")\n",
        "    f.write(f\"Test F1-Score:   {clean_test_results['eval_f1']:.4f}\\n\")\n",
        "    f.write(f\"Test Accuracy:   {clean_test_results['eval_accuracy']:.4f}\\n\")\n",
        "    f.write(f\"Test Precision:  {clean_test_results['eval_precision']:.4f}\\n\")\n",
        "    f.write(f\"Test Recall:     {clean_test_results['eval_recall']:.4f}\\n\\n\")\n",
        "\n",
        "    f.write(f\"--- BOOTSTRAPPED RESULTS ({Config.N_BOOTSTRAPS} samples) ---\\n\")\n",
        "    f.write(f\"Format: Mean (95% CI)\\n\")\n",
        "    f.write(f\"Test F1-Score:   {f1_mean:.4f} (95% CI: [{f1_ci[0]:.4f}, {f1_ci[1]:.4f}])\\n\")\n",
        "    f.write(f\"Test Accuracy:   {acc_mean:.4f} (95% CI: [{acc_ci[0]:.4f}, {acc_ci[1]:.4f}])\\n\")\n",
        "    f.write(f\"Test Precision:  {prec_mean:.4f} (95% CI: [{prec_ci[0]:.4f}, {prec_ci[1]:.4f}])\\n\")\n",
        "    f.write(f\"Test Recall:     {rec_mean:.4f} (95% CI: [{rec_ci[0]:.4f}, {rec_ci[1]:.4f}])\\n\")\n",
        "\n",
        "\n",
        "print(f\"Test results saved to {results_file}\")\n",
        "print(\"--- Cell 13 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 14: Clean Up Memory ---\n",
        "\n",
        "\n",
        "print(\"Cleaning up memory...\")\n",
        "del model\n",
        "del trainer\n",
        "del tokenized_datasets\n",
        "del raw_datasets\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"--- STEP 1 COMPLETE ---\")\n",
        "print(\"You now have a trained, saved, and evaluated baseline model.\")"
      ],
      "metadata": {
        "id": "umJXMbHxXTMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 1: Install Dependencies ---\n",
        "print(\"Installing required libraries...\")\n",
        "!pip install transformers datasets scikit-learn -q\n",
        "\n",
        "print(\"--- Cell 1 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 2: Import Libraries & Mount Google Drive ---\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset, DatasetDict\n",
        "# Import individual metric functions\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils import resample\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModel,\n",
        "    AutoConfig,\n",
        "    PreTrainedModel,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "import torch.nn as nn\n",
        "import gc  # Garbage collector\n",
        "\n",
        "# (Leave Drive mount commented if you don't need it right now)\n",
        "# print(\"Mounting Google Drive...\")\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "print(\"--- Cell 2 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 3: Define Configuration and Paths ---\n",
        "class Config:\n",
        "    # --- Paths ---\n",
        "    DRIVE_PATH = '/content/drive/MyDrive/hate'\n",
        "\n",
        "    # --- File type ---\n",
        "    DATA_FILE_TYPE = 'csv'\n",
        "\n",
        "    # Paths to your data files\n",
        "    TRAIN_FILE = os.path.join(DRIVE_PATH, 'train.csv')\n",
        "    VAL_FILE = os.path.join(DRIVE_PATH, 'val.csv')\n",
        "    TEST_FILE = os.path.join(DRIVE_PATH, 'test.csv')\n",
        "\n",
        "    # Save path: use a distinct folder for the gated model\n",
        "    MODEL_SAVE_PATH = os.path.join(DRIVE_PATH, 'models/step1_gated_fusion')\n",
        "\n",
        "    # --- Model Configuration ---\n",
        "    # BASE model for tokenizer & encoder\n",
        "    BASE_MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "    # Public-facing name for this experiment\n",
        "    MODEL_NAME = 'gated'\n",
        "\n",
        "    # --- Training Hyperparameters ---\n",
        "    MAX_LENGTH = 128\n",
        "    BATCH_SIZE = 16\n",
        "    EPOCHS = 5\n",
        "    LEARNING_RATE = 2e-5\n",
        "\n",
        "    # --- Labels ---\n",
        "    NUM_LABELS = 2  # 0 (Non-hate), 1 (Hate)\n",
        "\n",
        "    # --- Evaluation ---\n",
        "    N_BOOTSTRAPS = 1000\n",
        "\n",
        "print(\"Configuration defined.\")\n",
        "print(f\"Model to be trained: {Config.MODEL_NAME}\")\n",
        "print(f\"Base encoder: {Config.BASE_MODEL_NAME}\")\n",
        "print(f\"Model will be saved to: {Config.MODEL_SAVE_PATH}\")\n",
        "print(f\"Will run {Config.N_BOOTSTRAPS} bootstrap iterations for CI.\")\n",
        "print(\"--- Cell 3 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 4: Check for GPU ---\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Awesome! We are using the GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"No GPU found. We are using the CPU (this will be SLOW).\")\n",
        "\n",
        "print(\"--- Cell 4 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 5: Load Dataset ---\n",
        "print(f\"Loading data from {Config.DRIVE_PATH}...\")\n",
        "try:\n",
        "    data_files = {\n",
        "        'train': Config.TRAIN_FILE,\n",
        "        'validation': Config.VAL_FILE,\n",
        "        'test': Config.TEST_FILE\n",
        "    }\n",
        "    raw_datasets = load_dataset(Config.DATA_FILE_TYPE, data_files=data_files)\n",
        "\n",
        "    print(\"Data loaded successfully!\")\n",
        "    print(raw_datasets)\n",
        "\n",
        "    print(\"\\nExample from training set:\")\n",
        "    print(raw_datasets['train'][0])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"--- ERROR LOADING DATA ---\")\n",
        "    print(f\"Could not load data. Check your paths and file type ('{Config.DATA_FILE_TYPE}').\")\n",
        "    print(f\"Error: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"--- Cell 5 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 6: Preprocessing (Tokenization) ---\n",
        "print(f\"Loading tokenizer for {Config.BASE_MODEL_NAME}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(Config.BASE_MODEL_NAME)\n",
        "\n",
        "def tokenize_function(batch):\n",
        "    return tokenizer(\n",
        "        batch['text'],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "print(\"Tokenizing datasets... (this may take a minute)\")\n",
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=['post_id', 'text', 'label_name', 'label_3class', 'targets']\n",
        ")\n",
        "\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format('torch')\n",
        "\n",
        "print(\"Tokenization complete.\")\n",
        "print(tokenized_datasets)\n",
        "print(\"\\nExample of processed data:\")\n",
        "print(tokenized_datasets['train'][0])\n",
        "\n",
        "print(\"--- Cell 6 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 7: Gated-Fusion Model (fixed & drop-in) ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoConfig, PreTrainedModel, PretrainedConfig\n",
        "\n",
        "class GFConfig(PretrainedConfig):\n",
        "    \"\"\"Config that can be safely constructed with no args by HF internals.\"\"\"\n",
        "    model_type = \"gated_fusion_wrapper\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_model_name: str = \"bert-base-multilingual-cased\",\n",
        "        num_labels: int = 2,\n",
        "        gate_hidden: int = 256,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.base_model_name = base_model_name\n",
        "        self.num_labels = num_labels\n",
        "        self.gate_hidden = gate_hidden\n",
        "\n",
        "class GatedFusionForSequenceClassification(PreTrainedModel):\n",
        "    config_class = GFConfig\n",
        "\n",
        "    def __init__(self, config: GFConfig):\n",
        "        super().__init__(config)\n",
        "        self.base_cfg = AutoConfig.from_pretrained(config.base_model_name)\n",
        "        self.encoder = AutoModel.from_pretrained(config.base_model_name, config=self.base_cfg)\n",
        "        hidden = self.base_cfg.hidden_size\n",
        "\n",
        "        # Gate over hidden dims using [CLS] and masked-mean pooled token reps\n",
        "        self.gate_mlp = nn.Sequential(\n",
        "            nn.Linear(2 * hidden, config.gate_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.gate_hidden, hidden),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.dropout = nn.Dropout(getattr(self.base_cfg, \"hidden_dropout_prob\", 0.1))\n",
        "        self.classifier = nn.Linear(hidden, config.num_labels)\n",
        "\n",
        "        self.post_init()\n",
        "\n",
        "    @staticmethod\n",
        "    def masked_mean(last_hidden_state, attention_mask):\n",
        "        # attention_mask: [B, L], last_hidden_state: [B, L, H]\n",
        "        mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)  # [B, L, 1]\n",
        "        summed = (last_hidden_state * mask).sum(dim=1)                  # [B, H]\n",
        "        denom = mask.sum(dim=1).clamp(min=1e-6)                         # [B, 1]\n",
        "        return summed / denom\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        labels=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        # Drop Trainer-injected / unknown kwargs that the base model won't accept\n",
        "        allowed = {\n",
        "            \"position_ids\", \"head_mask\", \"inputs_embeds\",\n",
        "            \"output_attentions\", \"output_hidden_states\", \"return_dict\",\n",
        "            \"past_key_values\", \"encoder_hidden_states\", \"encoder_attention_mask\"\n",
        "        }\n",
        "        safe_kwargs = {k: v for k, v in kwargs.items() if k in allowed}\n",
        "        safe_kwargs.pop(\"num_items_in_batch\", None)\n",
        "\n",
        "        enc = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            **safe_kwargs\n",
        "        )\n",
        "\n",
        "        # CLS and masked mean pooling\n",
        "        h_cls = enc.last_hidden_state[:, 0, :]                           # [B, H]\n",
        "        h_mean = self.masked_mean(enc.last_hidden_state, attention_mask) # [B, H]\n",
        "\n",
        "        # Gated fusion\n",
        "        gate_inp = torch.cat([h_cls, h_mean], dim=-1)                    # [B, 2H]\n",
        "        g = self.gate_mlp(gate_inp)                                      # [B, H] in (0,1)\n",
        "        fused = g * h_cls + (1.0 - g) * h_mean\n",
        "        fused = self.dropout(fused)\n",
        "        logits = self.classifier(fused)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "print(f\"Loading gated-fusion head on base encoder: {Config.BASE_MODEL_NAME}\")\n",
        "gf_config = GFConfig(\n",
        "    base_model_name=Config.BASE_MODEL_NAME,\n",
        "    num_labels=Config.NUM_LABELS,\n",
        "    gate_hidden=256\n",
        ")\n",
        "model = GatedFusionForSequenceClassification(gf_config).to(device)\n",
        "print(\"Gated-fusion model loaded and moved to device.\")\n",
        "print(\"--- Cell 7 Complete ---\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Cell 8: Define Evaluation Metrics ---\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision = precision_score(labels, predictions, average='macro')\n",
        "    recall = recall_score(labels, predictions, average='macro')\n",
        "    f1 = f1_score(labels, predictions, average='macro')\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n",
        "\n",
        "print(\"Metrics function 'compute_metrics' defined.\")\n",
        "print(\"--- Cell 8 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 9: Configure Training Arguments ---\n",
        "print(\"Configuring training arguments...\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=Config.MODEL_SAVE_PATH,\n",
        "\n",
        "    # --- Training Hyperparameters ---\n",
        "    num_train_epochs=Config.EPOCHS,\n",
        "    learning_rate=Config.LEARNING_RATE,\n",
        "    per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "    per_device_eval_batch_size=Config.BATCH_SIZE * 2,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    # --- Evaluation and Saving ---\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "\n",
        "    # --- Logging (progress bars only) ---\n",
        "    report_to=\"none\",\n",
        "    logging_strategy=\"no\",\n",
        "    disable_tqdm=False\n",
        ")\n",
        "\n",
        "print(\"--- Cell 9 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 10: Initialize Trainer ---\n",
        "print(\"Initializing Trainer...\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"Trainer initialized.\")\n",
        "print(\"--- Cell 10 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 11: Train the Model ---\n",
        "print(\"--- STARTING GATED MODEL TRAINING ---\")\n",
        "print(f\"Training for {Config.EPOCHS} epochs...\")\n",
        "\n",
        "training_results = trainer.train()\n",
        "\n",
        "print(\"--- TRAINING COMPLETE ---\")\n",
        "print(\"--- Cell 11 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 12: Save the Best Model and Results ---\n",
        "print(f\"Saving the best model to {Config.MODEL_SAVE_PATH}...\")\n",
        "trainer.save_model(Config.MODEL_SAVE_PATH)\n",
        "trainer.save_state()\n",
        "print(f\"Model successfully saved to {Config.MODEL_SAVE_PATH}\")\n",
        "print(\"--- Cell 12 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 13: Evaluate on the TEST Set (with Bootstrap CIs) ---\n",
        "print(\"--- EVALUATING ON THE TEST SET (SINGLE PASS) ---\")\n",
        "\n",
        "clean_test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "\n",
        "print(\"\\n\\n--- FINAL GATED MODEL TEST RESULTS (CLEAN) ---\")\n",
        "print(f\"Model: {Config.MODEL_NAME}\")\n",
        "print(f\"Test F1-Score:   {clean_test_results['eval_f1']:.4f}\")\n",
        "print(f\"Test Accuracy:   {clean_test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"Test Precision:  {clean_test_results['eval_precision']:.4f}\")\n",
        "print(f\"Test Recall:     {clean_test_results['eval_recall']:.4f}\")\n",
        "print(\"---------------------------------------------------\\n\")\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "print(f\"--- STARTING BOOTSTRAP EVALUATION ({Config.N_BOOTSTRAPS} iterations) ---\")\n",
        "\n",
        "test_dataset = tokenized_datasets[\"test\"]\n",
        "n_samples = len(test_dataset)\n",
        "boot_f1_scores = []\n",
        "boot_accuracy_scores = []\n",
        "boot_precision_scores = []\n",
        "boot_recall_scores = []\n",
        "\n",
        "for _ in tqdm(range(Config.N_BOOTSTRAPS), desc=\"Bootstrapping\", leave=False):\n",
        "    boot_indices = resample(range(n_samples), replace=True, n_samples=n_samples)\n",
        "    boot_sample = test_dataset.select(boot_indices)\n",
        "    boot_results = trainer.evaluate(boot_sample, metric_key_prefix=\"boot\")\n",
        "    boot_f1_scores.append(boot_results['boot_f1'])\n",
        "    boot_accuracy_scores.append(boot_results['boot_accuracy'])\n",
        "    boot_precision_scores.append(boot_results['boot_precision'])\n",
        "    boot_recall_scores.append(boot_results['boot_recall'])\n",
        "\n",
        "print(\"--- BOOTSTRAP EVALUATION COMPLETE ---\")\n",
        "\n",
        "boot_f1_scores = np.array(boot_f1_scores)\n",
        "boot_accuracy_scores = np.array(boot_accuracy_scores)\n",
        "boot_precision_scores = np.array(boot_precision_scores)\n",
        "boot_recall_scores = np.array(boot_recall_scores)\n",
        "\n",
        "f1_ci = np.percentile(boot_f1_scores, [2.5, 97.5])\n",
        "acc_ci = np.percentile(boot_accuracy_scores, [2.5, 97.5])\n",
        "prec_ci = np.percentile(boot_precision_scores, [2.5, 97.5])\n",
        "rec_ci = np.percentile(boot_recall_scores, [2.5, 97.5])\n",
        "\n",
        "f1_mean = np.mean(boot_f1_scores)\n",
        "acc_mean = np.mean(boot_accuracy_scores)\n",
        "prec_mean = np.mean(boot_precision_scores)\n",
        "rec_mean = np.mean(boot_recall_scores)\n",
        "\n",
        "print(\"\\n\\n--- FINAL GATED MODEL TEST RESULTS (BOOTSTRAPPED) ---\")\n",
        "print(f\"Metrics based on {Config.N_BOOTSTRAPS} bootstrap samples.\")\n",
        "print(f\"Format: Mean (95% CI)\")\n",
        "print(\"----------------------------------------------------------\")\n",
        "print(f\"Test F1-Score:   {f1_mean:.4f} (95% CI: [{f1_ci[0]:.4f}, {f1_ci[1]:.4f}])\")\n",
        "print(f\"Test Accuracy:   {acc_mean:.4f} (95% CI: [{acc_ci[0]:.4f}, {acc_ci[1]:.4f}])\")\n",
        "print(f\"Test Precision:  {prec_mean:.4f} (95% CI: [{prec_ci[0]:.4f}, {prec_ci[1]:.4f}])\")\n",
        "print(f\"Test Recall:     {rec_mean:.4f} (95% CI: [{rec_ci[0]:.4f}, {rec_ci[1]:.4f}])\")\n",
        "print(\"----------------------------------------------------------\\n\")\n",
        "\n",
        "results_file = os.path.join(Config.DRIVE_PATH, 'models', 'step1_gated_baseline_results.txt')\n",
        "with open(results_file, 'w') as f:\n",
        "    f.write(\"--- FINAL GATED MODEL TEST RESULTS ---\\n\\n\")\n",
        "    f.write(f\"Model: {Config.MODEL_NAME}\\n\\n\")\n",
        "\n",
        "    f.write(\"--- SINGLE PASS (CLEAN) RESULTS ---\\n\")\n",
        "    f.write(f\"Test F1-Score:   {clean_test_results['eval_f1']:.4f}\\n\")\n",
        "    f.write(f\"Test Accuracy:   {clean_test_results['eval_accuracy']:.4f}\\n\")\n",
        "    f.write(f\"Test Precision:  {clean_test_results['eval_precision']:.4f}\\n\")\n",
        "    f.write(f\"Test Recall:     {clean_test_results['eval_recall']:.4f}\\n\\n\")\n",
        "\n",
        "    f.write(f\"--- BOOTSTRAPPED RESULTS ({Config.N_BOOTSTRAPS} samples) ---\\n\")\n",
        "    f.write(f\"Format: Mean (95% CI)\\n\")\n",
        "    f.write(f\"Test F1-Score:   {f1_mean:.4f} (95% CI: [{f1_ci[0]:.4f}, {f1_ci[1]:.4f}])\\n\")\n",
        "    f.write(f\"Test Accuracy:   {acc_mean:.4f} (95% CI: [{acc_ci[0]:.4f}, {acc_ci[1]:.4f}])\\n\")\n",
        "    f.write(f\"Test Precision:  {prec_mean:.4f} (95% CI: [{prec_ci[0]:.4f}, {prec_ci[1]:.4f}])\\n\")\n",
        "    f.write(f\"Test Recall:     {rec_mean:.4f} (95% CI: [{rec_ci[0]:.4f}, {rec_ci[1]:.4f}])\\n\")\n",
        "\n",
        "print(f\"Test results saved to {results_file}\")\n",
        "print(\"--- Cell 13 Complete ---\")\n",
        "\n",
        "\n",
        "# --- Cell 14: Clean Up Memory ---\n",
        "print(\"Cleaning up memory...\")\n",
        "del model\n",
        "del trainer\n",
        "del tokenized_datasets\n",
        "del raw_datasets\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"--- STEP 1 COMPLETE ---\")\n",
        "print(\"You now have a trained, saved, and evaluated GATED model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ce3f389f3e144cd781ed28ad6a07b2cd",
            "e27d450cc7614d728c2f41e25300ddc7",
            "d61acd224c0b4eb3b7bf7b413f25ace4",
            "6fff5f5d51784dedad041626293c3760",
            "166e7698b7a94d508259b1f3b6dd4745",
            "e33ef85610da49daa2a7e88409c96516",
            "1c6c9cae14e649afa3fcd2b57f8c7bc5",
            "f3e24e5607d54895b11c98e58b5921fe",
            "ea8b0743d3a94499a1804278ab6f312e",
            "a1aa00545a96401aa8741fdce1362edc",
            "c6cba0cb20074a9cbefc7c7412d54cb1",
            "a98418f9531841c7b56ba3d55a600a51",
            "63255c1ef487417995dc19e8e05aeb0a",
            "e3b4df6d3fad40c091a7c2874f83d496",
            "50e508462daf41429b8fcb55cd93a1e9",
            "b3485cc3d0314fdfad8f3a8346563b15",
            "01d666371fcf4ad387867c4fa445e312",
            "ca68266624244a5dbd9294eb7f45cab0",
            "61bd5fd83bc94ceb98e13e0a11408bb9",
            "c3efeb7ec4184a4887ca4ffd3259ec05",
            "c3a485ed9110468a8820337e73b8328a",
            "f4945d5e2f514de9995a5ada386dab00",
            "b00b396db160437bb365d2dd88656299",
            "c74d7e69b8dc4b498c84901c052035c2",
            "fc0491247aa54d6b9c5e338b0e4d9480",
            "fd2884d09df24b6ea3e8767cadd06869",
            "c44a16051b0542efa431ee35acea1490",
            "855d93c25a4b44dc9a793d2a1355aa32",
            "4d4add54d7724054956a3198abc545b7",
            "37f0f063cf02450981b98aeb6c3a5d3d",
            "4a5298c146314f8ea212ab41f5647fbb",
            "118e72c7564c4384954ad228bc89d956",
            "b9fbaca37c894616baa4b9ba0f3b7570",
            "80f1d95d6b32434aa72a9e6b99d1f73e",
            "3e5aa10b9b134bffa038403850d76c77",
            "1ea3880fea3c49bea08a7f18b85b4361",
            "d96d527cddc849df86bc35119fada77a",
            "867c1bb91018415583d6a960bd963ce4",
            "6a54cda9cd1048558d10cebe5df15223",
            "8780315e2a7549af8a66cee0f55d1772",
            "c8efdd97071447998eb86073ee547357",
            "19f9af90563c43e49b120ff50a1001f4",
            "491c89a152db4fc8a8197f12c3960310",
            "b14fbc98a5484c71a088dd564804c321"
          ]
        },
        "collapsed": true,
        "id": "P7ta4-j3f7rb",
        "outputId": "04171fd2-be02-408d-c6d3-560e06f196a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required libraries...\n",
            "--- Cell 1 Complete ---\n",
            "--- Cell 2 Complete ---\n",
            "Configuration defined.\n",
            "Model to be trained: gated\n",
            "Base encoder: bert-base-multilingual-cased\n",
            "Model will be saved to: /content/drive/MyDrive/hate/models/step1_gated_fusion\n",
            "Will run 1000 bootstrap iterations for CI.\n",
            "--- Cell 3 Complete ---\n",
            "Awesome! We are using the GPU: NVIDIA A100-SXM4-80GB\n",
            "--- Cell 4 Complete ---\n",
            "Loading data from /content/drive/MyDrive/hate...\n",
            "Data loaded successfully!\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['post_id', 'text', 'label_name', 'targets', 'label_3class', 'label'],\n",
            "        num_rows: 15383\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['post_id', 'text', 'label_name', 'targets', 'label_3class', 'label'],\n",
            "        num_rows: 1922\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['post_id', 'text', 'label_name', 'targets', 'label_3class', 'label'],\n",
            "        num_rows: 1924\n",
            "    })\n",
            "})\n",
            "\n",
            "Example from training set:\n",
            "{'post_id': '23107796_gab', 'text': 'u really think i would not have been raped by feral hindu or muslim back in india or bangladesh and a neo nazi would rape me as well just to see me cry', 'label_name': 'offensive', 'targets': 'Islam, Other, Hindu', 'label_3class': 1, 'label': 1}\n",
            "--- Cell 5 Complete ---\n",
            "Loading tokenizer for bert-base-multilingual-cased...\n",
            "Tokenizing datasets... (this may take a minute)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/15383 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce3f389f3e144cd781ed28ad6a07b2cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1922 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a98418f9531841c7b56ba3d55a600a51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1924 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b00b396db160437bb365d2dd88656299"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete.\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 15383\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 1922\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 1924\n",
            "    })\n",
            "})\n",
            "\n",
            "Example of processed data:\n",
            "{'labels': tensor(1), 'input_ids': tensor([   101,    189,  30181,  27874,    177,  10894,  10472,  10529,  10590,\n",
            "         82523,  10162,  10155,  82460,  10161,  19911,  11460,  10345,  12361,\n",
            "        105826,  12014,  10106,  55210,  10345,  17937,  62564,  10237,  10111,\n",
            "           169,  50071,  50756,  10894,  82523,  10911,  10146,  11206,  12820,\n",
            "         10114,  12888,  10911,    171,  10908,    102,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "--- Cell 6 Complete ---\n",
            "Loading gated-fusion head on base encoder: bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4067793330.py:297: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gated-fusion model loaded and moved to device.\n",
            "--- Cell 7 Complete ---\n",
            "Metrics function 'compute_metrics' defined.\n",
            "--- Cell 8 Complete ---\n",
            "Configuring training arguments...\n",
            "--- Cell 9 Complete ---\n",
            "Initializing Trainer...\n",
            "Trainer initialized.\n",
            "--- Cell 10 Complete ---\n",
            "--- STARTING GATED MODEL TRAINING ---\n",
            "Training for 5 epochs...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4810' max='4810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4810/4810 07:38, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.502913</td>\n",
              "      <td>0.751301</td>\n",
              "      <td>0.744570</td>\n",
              "      <td>0.743022</td>\n",
              "      <td>0.747106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.497491</td>\n",
              "      <td>0.765869</td>\n",
              "      <td>0.757647</td>\n",
              "      <td>0.757349</td>\n",
              "      <td>0.757962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.609933</td>\n",
              "      <td>0.747659</td>\n",
              "      <td>0.716740</td>\n",
              "      <td>0.762064</td>\n",
              "      <td>0.710710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.762321</td>\n",
              "      <td>0.758065</td>\n",
              "      <td>0.748169</td>\n",
              "      <td>0.749386</td>\n",
              "      <td>0.747147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.077664</td>\n",
              "      <td>0.763267</td>\n",
              "      <td>0.750610</td>\n",
              "      <td>0.756382</td>\n",
              "      <td>0.747287</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TRAINING COMPLETE ---\n",
            "--- Cell 11 Complete ---\n",
            "Saving the best model to /content/drive/MyDrive/hate/models/step1_gated_fusion...\n",
            "Model successfully saved to /content/drive/MyDrive/hate/models/step1_gated_fusion\n",
            "--- Cell 12 Complete ---\n",
            "--- EVALUATING ON THE TEST SET (SINGLE PASS) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='61061' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [61/61 56:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- FINAL GATED MODEL TEST RESULTS (CLEAN) ---\n",
            "Model: gated\n",
            "Test F1-Score:   0.7751\n",
            "Test Accuracy:   0.7827\n",
            "Test Precision:  0.7748\n",
            "Test Recall:     0.7755\n",
            "---------------------------------------------------\n",
            "\n",
            "--- STARTING BOOTSTRAP EVALUATION (1000 iterations) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Bootstrapping:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80f1d95d6b32434aa72a9e6b99d1f73e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- BOOTSTRAP EVALUATION COMPLETE ---\n",
            "\n",
            "\n",
            "--- FINAL GATED MODEL TEST RESULTS (BOOTSTRAPPED) ---\n",
            "Metrics based on 1000 bootstrap samples.\n",
            "Format: Mean (95% CI)\n",
            "----------------------------------------------------------\n",
            "Test F1-Score:   0.7745 (95% CI: [0.7544, 0.7945])\n",
            "Test Accuracy:   0.7823 (95% CI: [0.7630, 0.8015])\n",
            "Test Precision:  0.7743 (95% CI: [0.7546, 0.7941])\n",
            "Test Recall:     0.7749 (95% CI: [0.7546, 0.7949])\n",
            "----------------------------------------------------------\n",
            "\n",
            "Test results saved to /content/drive/MyDrive/hate/models/step1_gated_baseline_results.txt\n",
            "--- Cell 13 Complete ---\n",
            "Cleaning up memory...\n",
            "--- STEP 1 COMPLETE ---\n",
            "You now have a trained, saved, and evaluated GATED model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SINGLE CELL: self-contained adversarial suite runner\n",
        "# 1) Set your paths here:\n",
        "DRIVE_BASE          = r\"/content/drive/MyDrive/hate\"\n",
        "TRAIN_FILE          = f\"{DRIVE_BASE}/train.csv\"\n",
        "VAL_FILE            = f\"{DRIVE_BASE}/val.csv\"\n",
        "TEST_FILE           = f\"{DRIVE_BASE}/test.csv\"\n",
        "BASELINE_CHECKPOINT = f\"{DRIVE_BASE}/models/step1_bert_baseline\"     # saved baseline model\n",
        "GATED_CHECKPOINT    = f\"{DRIVE_BASE}/models/step1_gated_fusion\"      # saved gated model (folder)\n",
        "\n",
        "# 2) Install deps\n",
        "!pip -q install nlpaug nltk transformers datasets -q\n",
        "\n",
        "# 3) Imports\n",
        "import os, re, json, random\n",
        "from copy import deepcopy\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "from datasets import Dataset, load_dataset\n",
        "import nlpaug.augmenter.char as nac\n",
        "from nlpaug.augmenter.word import SynonymAug\n",
        "import nltk\n",
        "nltk.download('wordnet', quiet=True)\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    AutoConfig,\n",
        "    AutoModel,\n",
        "    PreTrainedModel,\n",
        "    PretrainedConfig\n",
        ")\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------\n",
        "# Gated model class + config\n",
        "# -----------------------\n",
        "class GFConfig(PretrainedConfig):\n",
        "    model_type = \"gated_fusion_wrapper\"\n",
        "    def __init__(self, base_model_name: str = \"bert-base-multilingual-cased\", num_labels: int = 2, gate_hidden: int = 256, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.base_model_name = base_model_name\n",
        "        self.num_labels = num_labels\n",
        "        self.gate_hidden = gate_hidden\n",
        "\n",
        "class GatedFusionForSequenceClassification(PreTrainedModel):\n",
        "    config_class = GFConfig\n",
        "    def __init__(self, config: GFConfig):\n",
        "        super().__init__(config)\n",
        "        self.base_cfg = AutoConfig.from_pretrained(config.base_model_name)\n",
        "        self.encoder = AutoModel.from_pretrained(config.base_model_name, config=self.base_cfg)\n",
        "        hidden = self.base_cfg.hidden_size\n",
        "        self.gate_mlp = nn.Sequential(\n",
        "            nn.Linear(2 * hidden, config.gate_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.gate_hidden, hidden),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.dropout = nn.Dropout(getattr(self.base_cfg, \"hidden_dropout_prob\", 0.1))\n",
        "        self.classifier = nn.Linear(hidden, config.num_labels)\n",
        "        self.post_init()\n",
        "    @staticmethod\n",
        "    def masked_mean(last_hidden_state, attention_mask):\n",
        "        mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n",
        "        summed = (last_hidden_state * mask).sum(dim=1)\n",
        "        denom = mask.sum(dim=1).clamp(min=1e-6)\n",
        "        return summed / denom\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
        "        allowed = {\"position_ids\", \"head_mask\", \"inputs_embeds\", \"output_attentions\", \"output_hidden_states\", \"return_dict\", \"past_key_values\", \"encoder_hidden_states\", \"encoder_attention_mask\"}\n",
        "        safe_kwargs = {k: v for k, v in kwargs.items() if k in allowed}\n",
        "        safe_kwargs.pop(\"num_items_in_batch\", None)\n",
        "        enc = self.encoder(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **safe_kwargs)\n",
        "        h_cls = enc.last_hidden_state[:, 0, :]\n",
        "        h_mean = self.masked_mean(enc.last_hidden_state, attention_mask)\n",
        "        gate_inp = torch.cat([h_cls, h_mean], dim=-1)\n",
        "        g = self.gate_mlp(gate_inp)\n",
        "        fused = g * h_cls + (1.0 - g) * h_mean\n",
        "        fused = self.dropout(fused)\n",
        "        logits = self.classifier(fused)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "# -----------------------\n",
        "# Attack tools (working set)\n",
        "# -----------------------\n",
        "structural_typo   = nac.KeyboardAug()\n",
        "structural_insert = nac.RandomCharAug(action=\"insert\")\n",
        "\n",
        "def attack_structural_case(text, p_char=0.15):\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "    out = []\n",
        "    for ch in text:\n",
        "        if ch.isalpha() and random.random() < p_char:\n",
        "            out.append(ch.upper() if ch.islower() else ch.lower())\n",
        "        else:\n",
        "            out.append(ch)\n",
        "    return \"\".join(out)\n",
        "\n",
        "synonym_aug = SynonymAug(aug_src='wordnet', aug_p=0.15)\n",
        "\n",
        "def attack_structural_typo(text):\n",
        "    try:\n",
        "        return structural_typo.augment(text)[0]\n",
        "    except Exception:\n",
        "        return text\n",
        "\n",
        "def attack_structural_insert(text):\n",
        "    try:\n",
        "        return structural_insert.augment(text)[0]\n",
        "    except Exception:\n",
        "        return text\n",
        "\n",
        "def attack_semantic_synonym(text):\n",
        "    try:\n",
        "        out = synonym_aug.augment(text)\n",
        "        if isinstance(out, list) and len(out) > 0:\n",
        "            return out[0]\n",
        "        return out\n",
        "    except Exception:\n",
        "        if not isinstance(text, str): return text\n",
        "        toks = text.split()\n",
        "        idxs = list(range(len(toks))); random.shuffle(idxs)\n",
        "        for i in idxs:\n",
        "            tok = toks[i]\n",
        "            synsets = wn.synsets(tok)\n",
        "            if not synsets: continue\n",
        "            lemmas = []\n",
        "            for syn in synsets[:3]:\n",
        "                for l in syn.lemmas():\n",
        "                    cand = l.name().replace('_', ' ')\n",
        "                    if cand.lower() != tok.lower(): lemmas.append(cand)\n",
        "            if lemmas:\n",
        "                toks[i] = random.choice(lemmas); break\n",
        "        return \" \".join(toks)\n",
        "\n",
        "CODED_LEXICON = {\n",
        "    r'\\bmuslims?\\b': 'skittles',\n",
        "    r'\\bblack( people)?\\b': 'googles',\n",
        "    r'\\bjews?\\b': 'skypes',\n",
        "    r'\\bmexicans?\\b': 'bings',\n",
        "}\n",
        "CODED_PATTERNS = [(re.compile(k, flags=re.IGNORECASE), v) for k, v in CODED_LEXICON.items()]\n",
        "def attack_semantic_coded(text):\n",
        "    if not isinstance(text, str): return text\n",
        "    out = text\n",
        "    for pat, repl in CODED_PATTERNS:\n",
        "        out = pat.sub(repl, out)\n",
        "    return out\n",
        "\n",
        "SLUR_LEXICON = [\n",
        "    r\"\\bmongol(s)?\\b\", r\"\\bretard(s|ed)?\\b\", r\"\\btolol\\b\", r\"\\bkontol\\b\",\n",
        "    r\"\\bbajingan\\b\", r\"\\bbabi\\b\", r\"\\bbhen ?chod\\b\", r\"\\bmadar ?chod\\b\",\n",
        "    r\"\\brandi\\b\", r\"\\bperra\\b\", r\"\\bzorra\\b\", r\"\\bputa\\b\"\n",
        "]\n",
        "SLUR_PATTERNS = [re.compile(p, flags=re.IGNORECASE) for p in SLUR_LEXICON]\n",
        "def attack_feature_slur_removal(text, replacement='[removed]'):\n",
        "    if not isinstance(text, str): return text\n",
        "    out = text\n",
        "    for pat in SLUR_PATTERNS:\n",
        "        out = pat.sub(replacement, out)\n",
        "    return out\n",
        "\n",
        "def apply_attack_texts(texts, attack_fn, desc=\"Attacking\"):\n",
        "    return [attack_fn(t) for t in tqdm(texts, desc=desc, leave=False)]\n",
        "\n",
        "# -----------------------\n",
        "# Per-class metrics helper\n",
        "# -----------------------\n",
        "def _per_class_metrics(y_true, y_pred, labels=(0, 1)):\n",
        "    p, r, f1, sup = precision_recall_fscore_support(y_true, y_pred, labels=list(labels), zero_division=0)\n",
        "    return [\n",
        "        {\"label\": int(lbl), \"precision\": float(p[i]), \"recall\": float(r[i]), \"f1\": float(f1[i]), \"support\": int(sup[i])}\n",
        "        for i, lbl in enumerate(labels)\n",
        "    ]\n",
        "\n",
        "# -----------------------\n",
        "# Data bootstrap (auto-load if absent)\n",
        "# -----------------------\n",
        "def _ensure_data_loaded():\n",
        "    global raw_datasets, tokenized_datasets\n",
        "    need_raw = 'raw_datasets' not in globals()\n",
        "    need_tok = 'tokenized_datasets' not in globals()\n",
        "    if not (need_raw or need_tok):\n",
        "        return  # already present\n",
        "\n",
        "    # Load CSVs into a datasets.DatasetDict\n",
        "    data_files = {}\n",
        "    if os.path.isfile(TRAIN_FILE): data_files['train'] = TRAIN_FILE\n",
        "    if os.path.isfile(VAL_FILE):   data_files['validation'] = VAL_FILE\n",
        "    if os.path.isfile(TEST_FILE):  data_files['test'] = TEST_FILE\n",
        "    if not data_files:\n",
        "        raise RuntimeError(\"No data files found. Set TRAIN_FILE/VAL_FILE/TEST_FILE correctly.\")\n",
        "\n",
        "    raw_datasets = load_dataset(\"csv\", data_files=data_files)\n",
        "\n",
        "    # Choose a tokenizer: prefer baseline checkpoint tokenizer if present, else default multilingual BERT\n",
        "    tok_path = BASELINE_CHECKPOINT if os.path.isdir(BASELINE_CHECKPOINT) else \"bert-base-multilingual-cased\"\n",
        "    _tokenizer = AutoTokenizer.from_pretrained(tok_path)\n",
        "\n",
        "    def tokenize_batch(batch):\n",
        "        return _tokenizer(batch['text'], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "    tokenized_datasets = raw_datasets.map(tokenize_batch, batched=True)\n",
        "    # rename label->labels for Trainer compatibility & set torch format\n",
        "    if 'label' in tokenized_datasets['test'].column_names:\n",
        "        tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "    tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "_ensure_data_loaded()\n",
        "\n",
        "# -----------------------\n",
        "# Eval helpers & suite\n",
        "# -----------------------\n",
        "def evaluate_on_texts(trainer, tokenizer, texts, labels, max_length=128):\n",
        "    encodings = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
        "    ds = Dataset.from_dict({k: encodings[k].tolist() for k in encodings})\n",
        "    ds = ds.add_column(\"label\", labels)\n",
        "    ds.set_format(type='torch', columns=list(encodings.keys()) + [\"label\"])\n",
        "    preds_out = trainer.predict(ds)\n",
        "    logits = preds_out.predictions\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    metrics = {}\n",
        "    return preds, logits, metrics\n",
        "\n",
        "def run_attack_and_report(trainer, tokenizer, raw_test_dataset, tokenized_test_dataset, attack_fn, attack_name, attack_mode='tp', save_dir=None):\n",
        "    preds_out = trainer.predict(tokenized_test_dataset)\n",
        "    clean_logits = preds_out.predictions\n",
        "    clean_preds = np.argmax(clean_logits, axis=-1)\n",
        "    clean_labels = preds_out.label_ids\n",
        "\n",
        "    # Per-class metrics (clean)\n",
        "    clean_per_class = _per_class_metrics(clean_labels, clean_preds)\n",
        "\n",
        "    # Extract raw texts & labels\n",
        "    raw_texts = list(raw_test_dataset['text'])\n",
        "    raw_labels = list(raw_test_dataset['label'])\n",
        "    n = len(raw_texts)\n",
        "    assert n == len(clean_preds) == len(clean_labels)\n",
        "\n",
        "    # choose indices\n",
        "    if attack_mode == 'tp':\n",
        "        target_indices = [i for i, (lab, pred) in enumerate(zip(clean_labels, clean_preds)) if lab == 1 and pred == 1]\n",
        "    elif attack_mode == 'full':\n",
        "        target_indices = list(range(n))\n",
        "    else:\n",
        "        raise ValueError(\"attack_mode must be 'tp' or 'full'\")\n",
        "\n",
        "    if len(target_indices) == 0:\n",
        "        report = {\n",
        "            'attack_name': attack_name, 'attack_mode': attack_mode,\n",
        "            'clean_metrics': {}, 'clean_per_class': clean_per_class,\n",
        "            'attacked_metrics': None, 'attacked_per_class': None,\n",
        "            'attack_changed': 0, 'tp_count_targeted': 0, 'note': 'no targets'\n",
        "        }\n",
        "        if save_dir:\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "            with open(os.path.join(save_dir, f\"{attack_name}_{attack_mode}.json\"), \"w\") as f: json.dump(report, f, indent=2)\n",
        "        return report\n",
        "\n",
        "    attacked_texts = raw_texts.copy()\n",
        "    to_attack = [raw_texts[i] for i in target_indices]\n",
        "    attacked_outs = apply_attack_texts(to_attack, attack_fn, desc=attack_name)\n",
        "    attack_count = 0\n",
        "    for idx, new_text in zip(target_indices, attacked_outs):\n",
        "        if new_text != raw_texts[idx]:\n",
        "            attacked_texts[idx] = new_text\n",
        "            attack_count += 1\n",
        "\n",
        "    if attack_count == 0:\n",
        "        report = {\n",
        "            'attack_name': attack_name, 'attack_mode': attack_mode,\n",
        "            'clean_metrics': {}, 'clean_per_class': clean_per_class,\n",
        "            'attacked_metrics': None, 'attacked_per_class': None,\n",
        "            'attack_changed': 0, 'tp_count_targeted': len(target_indices),\n",
        "            'note': 'no modification made by attack_fn'\n",
        "        }\n",
        "        if save_dir:\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "            with open(os.path.join(save_dir, f\"{attack_name}_{attack_mode}.json\"), \"w\") as f: json.dump(report, f, indent=2)\n",
        "        return report\n",
        "\n",
        "    # evaluate attacked set\n",
        "    attacked_preds, attacked_logits, attacked_metrics = evaluate_on_texts(trainer, tokenizer, attacked_texts, raw_labels)\n",
        "    attacked_per_class = _per_class_metrics(raw_labels, attacked_preds)\n",
        "\n",
        "    # For TP mode: ASR = % attacked TPs flipped to class 0\n",
        "    asr = None; samples_flipped = None\n",
        "    if attack_mode == 'tp':\n",
        "        attacked_for_targets_preds = [attacked_preds[i] for i in target_indices]\n",
        "        samples_flipped = sum(1 for p in attacked_for_targets_preds if p == 0)\n",
        "        asr = samples_flipped / len(target_indices)\n",
        "\n",
        "    # (Optional) delta F1 omitted since we're not recomputing macro-F1 here\n",
        "    report = {\n",
        "        'attack_name': attack_name,\n",
        "        'attack_mode': attack_mode,\n",
        "        'clean_per_class': clean_per_class,\n",
        "        'attacked_per_class': attacked_per_class,\n",
        "        'attack_changed': attack_count,\n",
        "        'tp_count_targeted': len(target_indices),\n",
        "        'samples_flipped': int(samples_flipped) if samples_flipped is not None else None,\n",
        "        'attack_success_rate': float(asr) if asr is not None else None\n",
        "    }\n",
        "    if save_dir:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        with open(os.path.join(save_dir, f\"{attack_name}_{attack_mode}.json\"), \"w\") as f: json.dump(report, f, indent=2)\n",
        "    return report\n",
        "\n",
        "def run_all_attacks(trainer, tokenizer, raw_test_dataset, tokenized_test_dataset, save_dir=\"attack_reports\", attack_mode='tp', attacks_to_run=None):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    attacks = attacks_to_run or [\n",
        "        (attack_structural_typo, 'structural_typo'),\n",
        "        (attack_structural_insert, 'structural_insert'),\n",
        "        (attack_structural_case, 'structural_case'),\n",
        "        (attack_semantic_synonym, 'semantic_synonym'),\n",
        "        (attack_semantic_coded, 'semantic_coded'),\n",
        "        (lambda t: attack_feature_slur_removal(t, replacement='[removed]'), 'feature_slur_removal'),\n",
        "    ]\n",
        "    suite_report = {'model': str(trainer.model.__class__), 'attack_mode': attack_mode, 'attacks': []}\n",
        "    for fn, name in attacks:\n",
        "        print(f\"Running attack: {name} (mode={attack_mode})\")\n",
        "        rpt = run_attack_and_report(trainer, tokenizer, raw_test_dataset, tokenized_test_dataset, fn, name, attack_mode, save_dir=save_dir)\n",
        "        if rpt is not None:\n",
        "            suite_report['attacks'].append(rpt)\n",
        "    with open(os.path.join(save_dir, f\"suite_report_{trainer.model.__class__.__name__}_{attack_mode}.json\"), 'w') as f:\n",
        "        json.dump(suite_report, f, indent=2)\n",
        "    return suite_report\n",
        "\n",
        "# -----------------------\n",
        "# Build eval-only trainers (auto; gated falls back to custom if needed)\n",
        "# -----------------------\n",
        "eval_args = TrainingArguments(\n",
        "    output_dir=\"./tmp_eval\",\n",
        "    per_device_eval_batch_size=32,\n",
        "    do_train=False, do_eval=True,\n",
        "    report_to=\"none\", logging_strategy=\"no\",\n",
        "    disable_tqdm=True\n",
        ")\n",
        "\n",
        "def build_eval_trainer(checkpoint_path, tokenizer=None):\n",
        "    if not os.path.isdir(checkpoint_path):\n",
        "        raise FileNotFoundError(checkpoint_path)\n",
        "    tok = tokenizer or AutoTokenizer.from_pretrained(checkpoint_path)\n",
        "    try:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n",
        "        model.to(device)\n",
        "        return Trainer(model=model, args=eval_args, tokenizer=tok, compute_metrics=None)\n",
        "    except Exception:\n",
        "        # Try gated fallback\n",
        "        cfg = GFConfig.from_pretrained(checkpoint_path)\n",
        "        model = GatedFusionForSequenceClassification(cfg)\n",
        "        state_path = os.path.join(checkpoint_path, \"pytorch_model.bin\")\n",
        "        if os.path.isfile(state_path):\n",
        "            state_dict = torch.load(state_path, map_location=device)\n",
        "            model.load_state_dict(state_dict, strict=False)\n",
        "        model.to(device)\n",
        "        return Trainer(model=model, args=eval_args, tokenizer=tok, compute_metrics=None)\n",
        "\n",
        "# -----------------------\n",
        "# Run: baseline then gated\n",
        "# -----------------------\n",
        "# Tokenizers (one per checkpoint, so embeddings/normalization match)\n",
        "baseline_tok = AutoTokenizer.from_pretrained(BASELINE_CHECKPOINT if os.path.isdir(BASELINE_CHECKPOINT) else \"bert-base-multilingual-cased\")\n",
        "gated_tok    = AutoTokenizer.from_pretrained(GATED_CHECKPOINT    if os.path.isdir(GATED_CHECKPOINT)    else \"bert-base-multilingual-cased\")\n",
        "\n",
        "print(\"Building baseline trainer...\")\n",
        "trainer_baseline = build_eval_trainer(BASELINE_CHECKPOINT, tokenizer=baseline_tok)\n",
        "print(\"Baseline trainer ready. Running attacks...\")\n",
        "baseline_report = run_all_attacks(\n",
        "    trainer_baseline,\n",
        "    tokenizer=baseline_tok,\n",
        "    raw_test_dataset=raw_datasets['test'],\n",
        "    tokenized_test_dataset=tokenized_datasets['test'],\n",
        "    save_dir=\"attack_reports/baseline\",\n",
        "    attack_mode='tp'\n",
        ")\n",
        "print(\"Baseline attacks finished. Reports -> attack_reports/baseline\")\n",
        "\n",
        "print(\"\\nBuilding gated trainer...\")\n",
        "trainer_gated = build_eval_trainer(GATED_CHECKPOINT, tokenizer=gated_tok)\n",
        "print(\"Gated trainer ready. Running attacks...\")\n",
        "gated_report = run_all_attacks(\n",
        "    trainer_gated,\n",
        "    tokenizer=gated_tok,\n",
        "    raw_test_dataset=raw_datasets['test'],\n",
        "    tokenized_test_dataset=tokenized_datasets['test'],\n",
        "    save_dir=\"attack_reports/gated\",\n",
        "    attack_mode='tp'\n",
        ")\n",
        "print(\"Gated attacks finished. Reports -> attack_reports/gated\")\n",
        "\n",
        "print(\"\\nALL DONE ✓  Check JSONs under attack_reports/ (each includes per-class metrics).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "97a16f9addc74d8da08c077c076a91aa",
            "7da48a629f2f4015b49e6b63ecf9a72b",
            "a1793d283e4544b5ab8b03a8dbedeeac",
            "92acf3eca42c4f5e8880cb19181a895f",
            "ad77fd70b75d43b6a9d5e6944346e950",
            "850b5cfb90ea4582b2caa53c73cfa0ac",
            "77ed0f213ca34cd69dcb6a68fef25680",
            "a211dbb0fff84a359b8cc1e504afa718",
            "8b610bfccd884ca3b9db6faa6883dba9",
            "f61d8138d2374e8fa92fcc83a191fc01",
            "3d62fd30369b49fdbfed5eff84fede13",
            "99f4ca6684694c40add3ac0e88671690",
            "ff4baaf7b2404b9c959da0e25859ee46",
            "7f82c6030f3947faa6d03d6ec947077d",
            "737687709b6c443fa593b08d309ab103",
            "cacbf5dec92b424c9dea3718cee28be1",
            "effed0e8982449daa6fcab8a9aa213a0",
            "8a336180fae64bf4bcbec016b76bb95c",
            "e6fe396f44414ce19baf9818887747c2",
            "f8e7d66fa6cd4a17abd12e3ef1fd226e",
            "7c3e4839acb54b52843e603d9b2c373a",
            "536775d93af1456bb814d5ff7ed017ae",
            "27bc0b1b4be447a384da70b5df52b787",
            "9debc472234043ed84e626203b7cf645",
            "07021ec0c4774a0e925ec2599789d4f7",
            "b3bdac77d99c4b76906570aa4b88ebbf",
            "2401d16d1d374179b7b2b194356a6baa",
            "e61ad21ed6804df4a1f3ff3fbbc3f4e2",
            "9f8368fc293b47a78f27a804c2948c86",
            "ab7c8d8c73e04b82826e2c59c294ed97",
            "03c3890c65f0480da77c38f9aa111280",
            "746fbe62ba9f47ec8d622813dbd13139",
            "1e152d199235483faf9ac7e84e8d3904",
            "82a3c3b4bee4452c8927ad663d25337a",
            "f41dbb982162433582c7cb96ab7fdc64",
            "bd7bf77597e94802ad7ae7dc5799d09c",
            "9bdafc90174045108dad24843a8f89b0",
            "8ecbc8564d944459896a6b9a166cb085",
            "bf5639e4970842b0b82408739827a798",
            "0d10fa7987b94e2a984b775868ae9b56",
            "c9636a38df29406b8910ea3576a4d530",
            "a34c92a3d50848759edd464601a50cc8",
            "3c0ba49a7ae9443f8052aa1217c122a1",
            "4fdf17468ccc406fac9d4c8ca8ccd11a",
            "7c278938dab84f7399894340765d5f20",
            "1b9efb5614e24780aa8d182b73605b55",
            "22bd8d9a39aa42d0937b1676f7e2f78f",
            "6ed97a521fd043b991423dc2a4d8a50f",
            "ca7b49bcd47342e1924e61772917c5d0",
            "59d4fe28421342de8a4ba419a28002da",
            "3922cecd723c47d2887f8f5272a0195a",
            "ce311821ac1e4f9f94e2e9c56f2802e2",
            "73c935a2a9f24a0a857fbc075fcbbe58",
            "f9c75d37fc254b0ca2e859cd7b1a7738",
            "4ba03d33c6c74b10aaa1afaf6dfc589d",
            "5792058584d84d3788e40a7688896ccb",
            "4224eca29eb04fb4a902efe1a29c9fde",
            "bc68921440b5433ea63afb53ae1cc4f7",
            "1fc88f37d0b440919ab13d33f1b83ed2",
            "7689cbf2cf5044faaa379106d5203764",
            "0dd0faf1f9284a49b8d7a4ffaa582d6d",
            "7125c375a5ef4d73b1ed837f5a720490",
            "f654bba71cf8450ca02778b0fa2fcf98",
            "8c692022b9814a7eb19feae90bd8dfd1",
            "744a63035630426782f7ad4abafc6c49",
            "31f7def20bf74993855f5a7dfdc93e39",
            "ed04f6d2467e4292856ba682eb632628",
            "13cd5baa1d5b4e86a4d8ddaf4df62e4a",
            "6a935f6bbba04852b2f53e422a10faab",
            "78e7acd2d8014e76a5e783d409072447",
            "0c42dd78246746c5aa8eb84b826df1a9",
            "445f9359ce724636be5d475b4c1ef553",
            "6b64f2c0c64a41028e6f2aa2bfe74a14",
            "109541a9790445a389336c540b0d460b",
            "d9cd3e743fe04e578bdb70d9e0ec8954",
            "6d755b8e6a5240de847e793c0a7e17b2",
            "236298b4133a41ce98f472e6abea2b58",
            "ce22140665e947e08301265087974789",
            "e421c4681327420388eea72aca0f819c",
            "48fe72652adc49a299d4c28271e9f8bf",
            "1ad73f04c8c347ed9285ce510d4e7006",
            "c91fb7b9a9054896a80c2e20553a333c",
            "7ab5e30778ee40669c042f3dc676b154",
            "782c9bd4420945ca97b283fbb9672420",
            "56b9a63062134addb7c95f71319ce3aa",
            "5a253b939d864ed4ac8df268c024b88d",
            "73104f6aa62147669fc7741b766d473e",
            "8c11a330cfa242a086720b743ce1290b",
            "27e9ddfbb12d4b5195ab4d94c51c8617",
            "2d8a2383b39849b28119b4dd6ded6ed3",
            "4ae25966565247efa014ff0843e54462",
            "0764b8dbab7a4c9daf48b4165b908709",
            "7c5e12c27bb94af290928bbef7a0881b",
            "4edab488e709437282ff794a9ce1e6ee",
            "2f3951783d3c4766b3a9dbce2f72e338",
            "bce379ba5d1549b3b8e9b13fccc1b1c8",
            "227481091aea48fe9230b896a5d6a03e",
            "b9ad0c0dea0e452982fbc2eb51a9f431",
            "90b3913a0e524294ac1fbcb1ff1388d1",
            "fb4ad2120c534c0da2e198c3883a51f6",
            "c6f277e6ba1749aa9a462c572f8aa782",
            "48a34179311b4109a48b78d574d89123",
            "38012fa5302748a38baf2a82c9bd8346",
            "30e8cbc7e6ee4d07bd36d6d2dc932d09",
            "77d5bca07e6e41bb986d17ce1373ddc8",
            "67f7b5b2c2674234aa4f7e36a2d8d32f",
            "67ec0a58fccc489a8ce6075a796dda09",
            "39c2086f848843bfbfc4f369d5a38109",
            "7922df282607478181f297f035f63255",
            "ae4bca5acf754b0aae58c93bacc451ed",
            "bbfe46f159cf4579bc207d0a434f1494",
            "f0f6eb77390e473abf74513cef4b9873",
            "7982f50eff244632a39103adfbe7d7d4",
            "062cc6f3c2614e5caa92024b0bfd3829",
            "1eb27dda4dcc4ba4a7d33612634f1755",
            "0c23b1fef0e046b9b61ab9413df731fc",
            "474b9d09f15d4f63809346f79eda0946",
            "ccaaffdc7af14fff91017a73fbdb34ce",
            "a0934499b2754b0da0516242c217011d",
            "99923880baf94c8eb026660ac2d803db",
            "fa3975744b1e4cf7ab5f58394d9117ad",
            "a72d1ab0dfd048cc83faf61e50a729bf",
            "4dbd95898c214b19af7f0a0179d2a057",
            "77af48280df14f9e9ebea1c3aaf67e8b",
            "4714746792854773a328f1234392b783",
            "724346869a5c499984360910e4196e99",
            "95c812a0d029456eab9b6d075585cc9d",
            "1f84c1836a534466afa4ea670e2cc215",
            "4cc52028fc0c459b9bc7f9aefbeb9470",
            "0c0879d199bf4a7da731930106b1886d",
            "049637958a38473f9432a569bac1547f",
            "7d821f8916fc403da974b48474effffa",
            "ad7cef0a1e744530973a8cc89d9601f8",
            "759dbbbcfb7842dda1bf34012a365afb",
            "3b8fe6da1b8944e584e57f6342def0c4",
            "19153c92511e4f08af811239641c676f",
            "32396861feb140d08ab9e384991c2550",
            "d1bbb08b70af4a5483d154b961ac85f9",
            "ed768e0186244601a8f6c0376603de6d",
            "812273d09fec44a88ddc3f8bab251609",
            "135b5354e96e476b894ddef3e78f6d75",
            "c5524201022149db8b6383c68a66bd9b",
            "5c668fd7a5714c8bb0944cc85d383771",
            "865514ce16b64d46a4d27e0d726ea067",
            "9b77ca096a17463c967a8198dc7b41cb",
            "2a1d0a90a53f4c9d9c3ba09f1d6b1f24",
            "d7e0db830d584ce087a52bb0ff6774a0",
            "80c45ffe32c74e9fac7d5122ba2b3f7a",
            "43591a8a49444b1f9ecc784d1860febb",
            "b56fa61398e840c48263d308d03a58a6",
            "5e388a2190744e52939c19739637e351",
            "58a088f932af451f82a916b116c88369",
            "353fac709b81466f9194f9fafc4cfd54",
            "6b4d52d9ab034a6082e2067360cec9ce",
            "1ee0b9fc9d2f4b4587970052a2d99551",
            "c7a173336ea6450dabc293de35232fe6",
            "a2effc89569b4a37b59f1de4c2d3dd09",
            "cd4d08492c6f452d8d04a7fee0291b57",
            "e28727a2561f4166b293fbfe5d452ad7",
            "d70439ae36234bebaf291b95acd7c75f",
            "116dd84a05f5411ab4a401684c86dc1f",
            "d6d1ed7856304f48877821a8b1ac4129",
            "8b02c3402cf3481fb0ca9abb767726a5",
            "9f7dfda72cde48628f945cb008d35468",
            "1245d4adc5ef424da355397e68c61bb7"
          ]
        },
        "collapsed": true,
        "id": "-mKuSQhpJzkw",
        "outputId": "115c4b8c-dc73-4402-da28-0b553a51cbf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/15383 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97a16f9addc74d8da08c077c076a91aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1922 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99f4ca6684694c40add3ac0e88671690"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1924 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27bc0b1b4be447a384da70b5df52b787"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building baseline trainer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1329518424.py:357: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  return Trainer(model=model, args=eval_args, tokenizer=tok, compute_metrics=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline trainer ready. Running attacks...\n",
            "Running attack: structural_typo (mode=tp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "structural_typo:   0%|          | 0/928 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82a3c3b4bee4452c8927ad663d25337a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack: structural_insert (mode=tp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "structural_insert:   0%|          | 0/928 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c278938dab84f7399894340765d5f20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack: structural_case (mode=tp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "structural_case:   0%|          | 0/928 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5792058584d84d3788e40a7688896ccb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack: semantic_synonym (mode=tp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "semantic_synonym:   0%|          | 0/928 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed04f6d2467e4292856ba682eb632628"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack: semantic_coded (mode=tp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "semantic_coded:   0%|          | 0/928 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce22140665e947e08301265087974789"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack: feature_slur_removal (mode=tp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "feature_slur_removal:   0%|          | 0/928 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27e9ddfbb12d4b5195ab4d94c51c8617"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline attacks finished. Reports -> attack_reports/baseline\n",
            "\n",
            "Building gated trainer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1329518424.py:367: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  return Trainer(model=model, args=eval_args, tokenizer=tok, compute_metrics=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gated trainer ready. Running attacks...\n",
            "Running attack: structural_typo (mode=tp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "structural_typo:   0%|          | 0/22 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb4ad2120c534c0da2e198c3883a51f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack: structural_insert (mode=tp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "structural_insert:   0%|          | 0/22 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbfe46f159cf4579bc207d0a434f1494"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack: structural_case (mode=tp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "structural_case:   0%|          | 0/22 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a72d1ab0dfd048cc83faf61e50a729bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack: semantic_synonym (mode=tp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "semantic_synonym:   0%|          | 0/22 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad7cef0a1e744530973a8cc89d9601f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack: semantic_coded (mode=tp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "semantic_coded:   0%|          | 0/22 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "865514ce16b64d46a4d27e0d726ea067"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack: feature_slur_removal (mode=tp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "feature_slur_removal:   0%|          | 0/22 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ee0b9fc9d2f4b4587970052a2d99551"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gated attacks finished. Reports -> attack_reports/gated\n",
            "\n",
            "ALL DONE ✓  Check JSONs under attack_reports/ (each includes per-class metrics).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Sentinel Architecture + Robust Training (FGM + Consistency)\n",
        "# ===========================\n",
        "!pip -q install transformers datasets scikit-learn\n",
        "\n",
        "import os, math, re, json, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Dict, Any, List\n",
        "\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModel, AutoConfig,\n",
        "    PretrainedConfig, PreTrainedModel,\n",
        "    Trainer, TrainingArguments\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -------------------------\n",
        "# Config (EDIT THESE PATHS)\n",
        "# -------------------------\n",
        "class Config:\n",
        "    DRIVE = \"/content/drive/MyDrive/hate\"\n",
        "    TRAIN = os.path.join(DRIVE, \"train.csv\")\n",
        "    VAL   = os.path.join(DRIVE, \"val.csv\")\n",
        "    TEST  = os.path.join(DRIVE, \"test.csv\")\n",
        "\n",
        "    BASE_MODEL = \"xlm-roberta-base\"  # multilingual & strong; swap to roberta-large for EN-only\n",
        "    MAX_LEN    = 128\n",
        "    BATCH      = 16\n",
        "    EPOCHS     = 5\n",
        "    LR         = 2e-5\n",
        "    NUM_LABELS = 2\n",
        "\n",
        "    # Sentinel toggles\n",
        "    USE_SENTINEL       = True     # set False to run plain encoder classifier (baseline)\n",
        "    HEURISTIC_DIM      = 32\n",
        "    HEURISTIC_HIDDEN   = 256\n",
        "    CAUSAL_HIDDEN      = 256\n",
        "    ATTENTION_HEADS    = 8\n",
        "    AUX_CASUAL_LOSS_W  = 0.2\n",
        "\n",
        "    # Robustness additions\n",
        "    ALPHA_ADV       = 0.5     # weight for adversarial loss (FGM)\n",
        "    BETA_CONS       = 0.2     # weight for consistency loss\n",
        "    FGM_EPS         = 1e-3    # magnitude of FGM perturbation on embeddings\n",
        "    CONS_TOK_MASK_P = 0.08    # probability to mask tokens for consistency\n",
        "\n",
        "    SAVE_DIR = os.path.join(DRIVE, \"models\", \"sentinel_xlmr\")\n",
        "\n",
        "# -------------------------\n",
        "# Heuristic feature builder\n",
        "# -------------------------\n",
        "SLUR_REGEXES = [\n",
        "    r\"\\bmongol(s)?\\b\", r\"\\bretard(s|ed)?\\b\", r\"\\btolol\\b\", r\"\\bkontol\\b\",\n",
        "    r\"\\bbajingan\\b\", r\"\\bbabi\\b\", r\"\\bbhen ?chod\\b\", r\"\\bmadar ?chod\\b\",\n",
        "    r\"\\brandi\\b\", r\"\\bperra\\b\", r\"\\bzorra\\b\", r\"\\bputa\\b\"\n",
        "]\n",
        "SLUR_PATTERNS = [re.compile(p, re.IGNORECASE) for p in SLUR_REGEXES]\n",
        "\n",
        "def build_heuristic_features(text: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Minimal, fast features; replace/extend with LIWC, sentiment, dependency, etc.\n",
        "    Size must equal Config.HEURISTIC_DIM (we'll pad/truncate).\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        text = \"\" if text is None else str(text)\n",
        "\n",
        "    length = len(text)\n",
        "    words  = text.split()\n",
        "    n_words = max(1, len(words))\n",
        "\n",
        "    upper = sum(1 for c in text if c.isalpha() and c.isupper())\n",
        "    digits = sum(1 for c in text if c.isdigit())\n",
        "    punct = sum(1 for c in text if c in \".,;:!?\")\n",
        "\n",
        "    # crude ratios\n",
        "    upper_ratio = upper / max(1, sum(c.isalpha() for c in text))\n",
        "    digit_ratio = digits / max(1, len(text))\n",
        "    punct_ratio = punct / max(1, len(text))\n",
        "\n",
        "    # slur density\n",
        "    slur_hits = 0\n",
        "    for pat in SLUR_PATTERNS:\n",
        "        slur_hits += len(pat.findall(text))\n",
        "    slur_density = slur_hits / n_words\n",
        "\n",
        "    # simplistic aggression cue count\n",
        "    cues = sum(text.lower().count(k) for k in [\"kill\", \"die\", \"trash\", \"dirty\", \"dog\", \"pig\", \"scum\", \"hate\"])\n",
        "    cue_density = cues / n_words\n",
        "\n",
        "    base_feats = np.array([\n",
        "        length, n_words, upper, digits, punct,\n",
        "        upper_ratio, digit_ratio, punct_ratio,\n",
        "        slur_hits, slur_density, cues, cue_density\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    # Normalize some scale-sensitive feats (very rough)\n",
        "    base_feats[0] = math.log1p(base_feats[0])   # length\n",
        "    base_feats[1] = math.log1p(base_feats[1])   # n_words\n",
        "\n",
        "    # Pad/truncate to HEURISTIC_DIM\n",
        "    H = Config.HEURISTIC_DIM\n",
        "    if base_feats.shape[0] < H:\n",
        "        pad = np.zeros(H - base_feats.shape[0], dtype=np.float32)\n",
        "        feats = np.concatenate([base_feats, pad])\n",
        "    else:\n",
        "        feats = base_feats[:H]\n",
        "    return feats\n",
        "\n",
        "# -------------------------\n",
        "# Dataset + Tokenization\n",
        "# -------------------------\n",
        "assert os.path.isfile(Config.TRAIN) and os.path.isfile(Config.VAL) and os.path.isfile(Config.TEST), \\\n",
        "    \"Train/Val/Test CSVs not found. Update Config paths.\"\n",
        "\n",
        "data_files = {\"train\": Config.TRAIN, \"validation\": Config.VAL, \"test\": Config.TEST}\n",
        "raw = load_dataset(\"csv\", data_files=data_files)\n",
        "tok = AutoTokenizer.from_pretrained(Config.BASE_MODEL)\n",
        "\n",
        "def tok_map(batch):\n",
        "    enc = tok(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=Config.MAX_LEN)\n",
        "    # Heuristic features per example\n",
        "    feats = [build_heuristic_features(t) for t in batch[\"text\"]]\n",
        "    enc[\"heuristic_feats\"] = feats\n",
        "    # Optional auxiliary causal targets:\n",
        "    if \"causal_target\" in batch:\n",
        "        enc[\"causal_target\"] = batch[\"causal_target\"]\n",
        "    return enc\n",
        "\n",
        "tokenized = raw.map(tok_map, batched=True, remove_columns=[c for c in raw[\"train\"].column_names if c not in (\"text\",\"label\",\"causal_target\")])\n",
        "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
        "tokenized.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\",\"heuristic_feats\"] + ([\"causal_target\"] if \"causal_target\" in tokenized[\"train\"].column_names else []))\n",
        "\n",
        "# -------------------------\n",
        "# Data collator (to tensorize heuristic feats)\n",
        "# -------------------------\n",
        "@dataclass\n",
        "class SentinelCollator:\n",
        "    def __call__(self, batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        out = {}\n",
        "        for k in (\"input_ids\", \"attention_mask\", \"labels\"):\n",
        "            out[k] = torch.stack([b[k] for b in batch])\n",
        "        feats = [torch.tensor(b[\"heuristic_feats\"], dtype=torch.float32) if not isinstance(b[\"heuristic_feats\"], torch.Tensor)\n",
        "                 else b[\"heuristic_feats\"].to(torch.float32)\n",
        "                 for b in batch]\n",
        "        out[\"heuristic_feats\"] = torch.stack(feats)\n",
        "        if \"causal_target\" in batch[0]:\n",
        "            out[\"causal_target\"] = torch.stack([b[\"causal_target\"] for b in batch]).long()\n",
        "        return out\n",
        "\n",
        "collator = SentinelCollator()\n",
        "\n",
        "# -------------------------\n",
        "# Sentinel Config + Model\n",
        "# -------------------------\n",
        "class SentinelConfig(PretrainedConfig):\n",
        "    model_type = \"sentinel_fusion\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_model_name: str = \"xlm-roberta-base\",\n",
        "        num_labels: int = 2,\n",
        "        heuristic_dim: int = 32,\n",
        "        heuristic_hidden: int = 256,\n",
        "        causal_hidden: int = 256,\n",
        "        attn_heads: int = 8,\n",
        "        aux_causal_loss_weight: float = 0.2,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.base_model_name = base_model_name\n",
        "        self.num_labels = num_labels\n",
        "        self.heuristic_dim = heuristic_dim\n",
        "        self.heuristic_hidden = heuristic_hidden\n",
        "        self.causal_hidden = causal_hidden\n",
        "        self.attn_heads = attn_heads\n",
        "        self.aux_causal_loss_weight = aux_causal_loss_weight\n",
        "\n",
        "class SentinelModel(PreTrainedModel):\n",
        "    config_class = SentinelConfig\n",
        "    def __init__(self, config: SentinelConfig):\n",
        "        super().__init__(config)\n",
        "        self.base_cfg = AutoConfig.from_pretrained(config.base_model_name)\n",
        "        self.encoder = AutoModel.from_pretrained(config.base_model_name, config=self.base_cfg)\n",
        "        hidden = self.base_cfg.hidden_size\n",
        "\n",
        "        # Heuristic projector\n",
        "        self.heuristic_proj = nn.Sequential(\n",
        "            nn.Linear(config.heuristic_dim, config.heuristic_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.heuristic_hidden, hidden),\n",
        "            nn.LayerNorm(hidden)\n",
        "        )\n",
        "\n",
        "        # Causal pathway\n",
        "        self.causal_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden, config.causal_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.causal_hidden, hidden),\n",
        "            nn.LayerNorm(hidden)\n",
        "        )\n",
        "        self.causal_aux_head = nn.Linear(hidden, 2)\n",
        "\n",
        "        # Cross-attention: Query = [CLS], KV = [heuristic, causal]\n",
        "        self.xattn = nn.MultiheadAttention(embed_dim=hidden, num_heads=config.attn_heads, batch_first=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(getattr(self.base_cfg, \"hidden_dropout_prob\", 0.1))\n",
        "        self.classifier = nn.Linear(hidden, config.num_labels)\n",
        "        self.post_init()\n",
        "\n",
        "    @staticmethod\n",
        "    def masked_mean(last_hidden_state, attention_mask):\n",
        "        mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n",
        "        summed = (last_hidden_state * mask).sum(dim=1)\n",
        "        denom = mask.sum(dim=1).clamp(min=1e-6)\n",
        "        return summed / denom\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        heuristic_feats=None,\n",
        "        labels=None,\n",
        "        causal_target: Optional[torch.Tensor] = None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        enc = self.encoder(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        last_hidden = enc.last_hidden_state                  # [B, L, H]\n",
        "        h_cls = last_hidden[:, 0, :]                         # [B, H] (semantic query)\n",
        "\n",
        "        h_heu = self.heuristic_proj(heuristic_feats)         # [B, H]\n",
        "        h_cau = self.causal_mlp(h_cls)                       # [B, H]\n",
        "\n",
        "        Q = h_cls.unsqueeze(1)                               # [B, 1, H]\n",
        "        KV = torch.stack([h_heu, h_cau], dim=1)              # [B, 2, H]\n",
        "        fused, _ = self.xattn(Q, KV, KV)                     # [B, 1, H]\n",
        "        fused = fused.squeeze(1)                             # [B, H]\n",
        "        fused = self.dropout(fused)\n",
        "        logits = self.classifier(fused)                      # [B, C]\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "        if causal_target is not None:\n",
        "            cau_logits = self.causal_aux_head(h_cau)         # [B, 2]\n",
        "            aux_loss = nn.CrossEntropyLoss()(cau_logits, causal_target)\n",
        "            if loss is None:\n",
        "                loss = self.config.aux_causal_loss_weight * aux_loss\n",
        "            else:\n",
        "                loss = loss + self.config.aux_causal_loss_weight * aux_loss\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "# -------------------------\n",
        "# Baseline Model (no fusion)\n",
        "# -------------------------\n",
        "class BaselineClassifier(PreTrainedModel):\n",
        "    config_class = SentinelConfig\n",
        "    def __init__(self, config: SentinelConfig):\n",
        "        super().__init__(config)\n",
        "        self.base_cfg = AutoConfig.from_pretrained(config.base_model_name)\n",
        "        self.encoder = AutoModel.from_pretrained(config.base_model_name, config=self.base_cfg)\n",
        "        hidden = self.base_cfg.hidden_size\n",
        "        self.dropout = nn.Dropout(getattr(self.base_cfg, \"hidden_dropout_prob\", 0.1))\n",
        "        self.classifier = nn.Linear(hidden, config.num_labels)\n",
        "        self.post_init()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
        "        enc = self.encoder(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        h_cls = enc.last_hidden_state[:, 0, :]\n",
        "        logits = self.classifier(self.dropout(h_cls))\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "# -------------------------\n",
        "# Metrics (macro)\n",
        "# -------------------------\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\":  accuracy_score(labels, preds),\n",
        "        \"precision\": precision_score(labels, preds, average=\"macro\", zero_division=0),\n",
        "        \"recall\":    recall_score(labels, preds, average=\"macro\", zero_division=0),\n",
        "        \"f1\":        f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
        "    }\n",
        "\n",
        "# -------------------------\n",
        "# Robustness additions\n",
        "# -------------------------\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def symmetric_kl(logits_p, logits_q, temperature=1.0):\n",
        "    p = F.log_softmax(logits_p/temperature, dim=-1)\n",
        "    q = F.log_softmax(logits_q/temperature, dim=-1)\n",
        "    p_soft = p.exp()\n",
        "    q_soft = q.exp()\n",
        "    return 0.5 * (F.kl_div(p, q_soft, reduction='batchmean') +\n",
        "                  F.kl_div(q, p_soft, reduction='batchmean'))\n",
        "\n",
        "@torch.no_grad()\n",
        "def corrupt_inputs_for_consistency(input_ids, attention_mask, mask_token_id, p=0.08):\n",
        "    x = input_ids.clone()\n",
        "    B, L = x.size()\n",
        "    rand = torch.rand_like(x.float())\n",
        "    corrupt_mask = (attention_mask == 1) & (rand < p)\n",
        "    corrupt_mask[:, 0] = False  # keep CLS intact\n",
        "    x[corrupt_mask] = mask_token_id\n",
        "    return x\n",
        "\n",
        "class FGM:\n",
        "    def __init__(self, model, epsilon=1e-3):\n",
        "        self.model = model\n",
        "        self.epsilon = epsilon\n",
        "        self.backup = None\n",
        "    def _emb(self):\n",
        "        return self.model.encoder.get_input_embeddings().weight\n",
        "    def attack(self):\n",
        "        emb = self._emb()\n",
        "        if emb.grad is None:\n",
        "            return False\n",
        "        grad = emb.grad\n",
        "        norm = torch.norm(grad)\n",
        "        if torch.isnan(norm) or torch.isinf(norm) or norm.item() == 0:\n",
        "            return False\n",
        "        self.backup = emb.data.clone()\n",
        "        r_adv = self.epsilon * grad / (norm + 1e-12)\n",
        "        emb.data.add_(r_adv)\n",
        "        return True\n",
        "    def restore(self):\n",
        "        if self.backup is not None:\n",
        "            self._emb().data = self.backup\n",
        "            self.backup = None\n",
        "\n",
        "from transformers import Trainer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RobustTrainer(Trainer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.fgm = FGM(self.model, epsilon=getattr(Config, \"FGM_EPS\", 1e-3))\n",
        "        self.alpha = getattr(Config, \"ALPHA_ADV\", 0.0)\n",
        "        self.beta  = getattr(Config, \"BETA_CONS\", 0.0)\n",
        "        # resolve mask token id\n",
        "        self.mask_token_id = None\n",
        "        if getattr(self, \"processing_class\", None) is not None and getattr(self.processing_class, \"mask_token_id\", None) is not None:\n",
        "            self.mask_token_id = self.processing_class.mask_token_id\n",
        "        elif getattr(self, \"tokenizer\", None) is not None and getattr(self.tokenizer, \"mask_token_id\", None) is not None:\n",
        "            self.mask_token_id = self.tokenizer.mask_token_id\n",
        "        else:\n",
        "            try:\n",
        "                self.mask_token_id = self.model.encoder.config.mask_token_id\n",
        "            except Exception:\n",
        "                self.mask_token_id = None\n",
        "\n",
        "    # NOTE: accept the new arg `num_items_in_batch`\n",
        "    def training_step(self, model, inputs, num_items_in_batch=None):\n",
        "        model.train()\n",
        "        inputs = self._prepare_inputs(inputs)\n",
        "\n",
        "        # ---- main forward (CE ± aux) ----\n",
        "        outputs = model(**inputs)\n",
        "        loss_main = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
        "        total_loss = loss_main\n",
        "\n",
        "        # ---- consistency loss (noisy masked inputs) ----\n",
        "        if self.beta > 0 and self.mask_token_id is not None and \"input_ids\" in inputs and \"attention_mask\" in inputs:\n",
        "            with torch.no_grad():\n",
        "                noisy_inputs = {k: v for k, v in inputs.items()}\n",
        "                noisy_inputs[\"input_ids\"] = corrupt_inputs_for_consistency(\n",
        "                    inputs[\"input_ids\"], inputs[\"attention_mask\"],\n",
        "                    mask_token_id=self.mask_token_id,\n",
        "                    p=getattr(Config, \"CONS_TOK_MASK_P\", 0.08)\n",
        "                )\n",
        "            logits_clean = outputs[\"logits\"] if isinstance(outputs, dict) else outputs[1]\n",
        "            outputs_noisy = model(**noisy_inputs)\n",
        "            logits_noisy = outputs_noisy[\"logits\"] if isinstance(outputs_noisy, dict) else outputs_noisy[1]\n",
        "            loss_cons = symmetric_kl(logits_clean.detach(), logits_noisy)\n",
        "            total_loss = total_loss + self.beta * loss_cons\n",
        "\n",
        "        # backprop main+consistency\n",
        "        total_loss.backward()\n",
        "\n",
        "        # ---- FGM adversarial step ----\n",
        "        if self.alpha > 0:\n",
        "            if self.fgm.attack():\n",
        "                adv_outputs = model(**inputs)\n",
        "                loss_adv = adv_outputs[\"loss\"] if isinstance(adv_outputs, dict) else adv_outputs[0]\n",
        "                (self.alpha * loss_adv).backward()\n",
        "                self.fgm.restore()\n",
        "\n",
        "        self.optimizer.step()\n",
        "        self.lr_scheduler.step()\n",
        "        self.optimizer.zero_grad()\n",
        "        return total_loss.detach()\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Build model + trainer\n",
        "# -------------------------\n",
        "cfg = SentinelConfig(\n",
        "    base_model_name=Config.BASE_MODEL,\n",
        "    num_labels=Config.NUM_LABELS,\n",
        "    heuristic_dim=Config.HEURISTIC_DIM,\n",
        "    heuristic_hidden=Config.HEURISTIC_HIDDEN,\n",
        "    causal_hidden=Config.CAUSAL_HIDDEN,\n",
        "    attn_heads=Config.ATTENTION_HEADS,\n",
        "    aux_causal_loss_weight=Config.AUX_CASUAL_LOSS_W\n",
        ")\n",
        "\n",
        "model = (SentinelModel(cfg) if Config.USE_SENTINEL else BaselineClassifier(cfg)).to(device)\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=Config.SAVE_DIR,\n",
        "    num_train_epochs=Config.EPOCHS,\n",
        "    learning_rate=Config.LR,\n",
        "    per_device_train_batch_size=Config.BATCH,\n",
        "    per_device_eval_batch_size=Config.BATCH * 2,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.06,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        "    logging_strategy=\"no\",\n",
        "    disable_tqdm=False\n",
        ")\n",
        "\n",
        "trainer = RobustTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    data_collator=collator,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    processing_class=tok,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Train & Evaluate\n",
        "# -------------------------\n",
        "print(f\"Training {'Sentinel' if Config.USE_SENTINEL else 'Baseline'} model with robustness losses...\")\n",
        "trainer.train()\n",
        "print(\"Evaluating on test...\")\n",
        "test_metrics = trainer.evaluate(tokenized[\"test\"])\n",
        "print({k: round(v, 4) for k, v in test_metrics.items()})\n",
        "\n",
        "# Save final model\n",
        "trainer.save_model(Config.SAVE_DIR)\n",
        "print(f\"Saved to: {Config.SAVE_DIR}\")\n"
      ],
      "metadata": {
        "id": "Oc6QLH6raoS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === SINGLE CELL: Sentinel-only Adversarial Suite (with per-class metrics) ===\n",
        "# 1) Paths (edit as needed)\n",
        "DRIVE_BASE           = \"/content/drive/MyDrive/hate\"\n",
        "TRAIN_FILE           = f\"{DRIVE_BASE}/train.csv\"\n",
        "VAL_FILE             = f\"{DRIVE_BASE}/val.csv\"\n",
        "TEST_FILE            = f\"{DRIVE_BASE}/test.csv\"\n",
        "SENTINEL_CHECKPOINT  = f\"{DRIVE_BASE}/models/sentinel_xlmr\"  # <--- set to your saved Sentinel folder\n",
        "\n",
        "# 2) Deps\n",
        "!pip -q install nlpaug nltk transformers datasets scikit-learn\n",
        "\n",
        "# 3) Imports\n",
        "import os, re, json, math, random\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import nlpaug.augmenter.char as nac\n",
        "from nlpaug.augmenter.word import SynonymAug\n",
        "import nltk\n",
        "nltk.download('wordnet', quiet=True)\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Any, List, Optional\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoConfig, AutoModel,\n",
        "    PretrainedConfig, PreTrainedModel,\n",
        "    TrainingArguments, Trainer\n",
        ")\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -------------------------\n",
        "# Sentinel config (must match training)\n",
        "# -------------------------\n",
        "class SentinelConfig(PretrainedConfig):\n",
        "    model_type = \"sentinel_fusion\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_model_name: str = \"xlm-roberta-base\",\n",
        "        num_labels: int = 2,\n",
        "        heuristic_dim: int = 32,         # <--- MUST match training\n",
        "        heuristic_hidden: int = 256,\n",
        "        causal_hidden: int = 256,\n",
        "        attn_heads: int = 8,\n",
        "        aux_causal_loss_weight: float = 0.2,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.base_model_name = base_model_name\n",
        "        self.num_labels = num_labels\n",
        "        self.heuristic_dim = heuristic_dim\n",
        "        self.heuristic_hidden = heuristic_hidden\n",
        "        self.causal_hidden = causal_hidden\n",
        "        self.attn_heads = attn_heads\n",
        "        self.aux_causal_loss_weight = aux_causal_loss_weight\n",
        "\n",
        "# -------------------------\n",
        "# Sentinel model (same as training-time)\n",
        "# -------------------------\n",
        "class SentinelModel(PreTrainedModel):\n",
        "    config_class = SentinelConfig\n",
        "    def __init__(self, config: SentinelConfig):\n",
        "        super().__init__(config)\n",
        "        self.base_cfg = AutoConfig.from_pretrained(config.base_model_name)\n",
        "        self.encoder = AutoModel.from_pretrained(config.base_model_name, config=self.base_cfg)\n",
        "        hidden = self.base_cfg.hidden_size\n",
        "\n",
        "        # Heuristic projector\n",
        "        self.heuristic_proj = nn.Sequential(\n",
        "            nn.Linear(config.heuristic_dim, config.heuristic_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.heuristic_hidden, hidden),\n",
        "            nn.LayerNorm(hidden)\n",
        "        )\n",
        "\n",
        "        # Causal pathway (from CLS)\n",
        "        self.causal_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden, config.causal_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.causal_hidden, hidden),\n",
        "            nn.LayerNorm(hidden)\n",
        "        )\n",
        "        self.causal_aux_head = nn.Linear(hidden, 2)  # (unused in eval)\n",
        "\n",
        "        # Cross-attention: Q = CLS; K,V = [heuristic, causal]\n",
        "        self.xattn = nn.MultiheadAttention(embed_dim=hidden, num_heads=config.attn_heads, batch_first=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(getattr(self.base_cfg, \"hidden_dropout_prob\", 0.1))\n",
        "        self.classifier = nn.Linear(hidden, config.num_labels)\n",
        "        self.post_init()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        heuristic_feats=None,\n",
        "        labels=None,\n",
        "        causal_target: Optional[torch.Tensor] = None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        enc = self.encoder(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        last_hidden = enc.last_hidden_state              # [B, L, H]\n",
        "        h_cls = last_hidden[:, 0, :]                     # [B, H]\n",
        "        h_heu = self.heuristic_proj(heuristic_feats)     # [B, H]\n",
        "        h_cau = self.causal_mlp(h_cls)                   # [B, H]\n",
        "\n",
        "        Q = h_cls.unsqueeze(1)                           # [B, 1, H]\n",
        "        KV = torch.stack([h_heu, h_cau], dim=1)          # [B, 2, H]\n",
        "        fused, _ = self.xattn(Q, KV, KV)                 # [B, 1, H]\n",
        "        fused = fused.squeeze(1)\n",
        "        logits = self.classifier(self.dropout(fused))\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "# -------------------------\n",
        "# Heuristic features (must match training logic & HEURISTIC_DIM)\n",
        "# -------------------------\n",
        "SLUR_REGEXES = [\n",
        "    r\"\\bmongol(s)?\\b\", r\"\\bretard(s|ed)?\\b\", r\"\\btolol\\b\", r\"\\bkontol\\b\",\n",
        "    r\"\\bbajingan\\b\", r\"\\bbabi\\b\", r\"\\bbhen ?chod\\b\", r\"\\bmadar ?chod\\b\",\n",
        "    r\"\\brandi\\b\", r\"\\bperra\\b\", r\"\\bzorra\\b\", r\"\\bputa\\b\"\n",
        "]\n",
        "SLUR_PATTERNS = [re.compile(p, re.IGNORECASE) for p in SLUR_REGEXES]\n",
        "\n",
        "HEURISTIC_DIM = 32  # <--- set to the same value you trained with\n",
        "\n",
        "def build_heuristic_features(text: str) -> np.ndarray:\n",
        "    if not isinstance(text, str):\n",
        "        text = \"\" if text is None else str(text)\n",
        "\n",
        "    length = len(text)\n",
        "    words  = text.split()\n",
        "    n_words = max(1, len(words))\n",
        "\n",
        "    upper  = sum(1 for c in text if c.isalpha() and c.isupper())\n",
        "    digits = sum(1 for c in text if c.isdigit())\n",
        "    punct  = sum(1 for c in text if c in \".,;:!?\")\n",
        "\n",
        "    alpha_count = max(1, sum(c.isalpha() for c in text))\n",
        "    upper_ratio = upper / alpha_count\n",
        "    digit_ratio = digits / max(1, len(text))\n",
        "    punct_ratio = punct / max(1, len(text))\n",
        "\n",
        "    slur_hits = 0\n",
        "    for pat in SLUR_PATTERNS:\n",
        "        slur_hits += len(pat.findall(text))\n",
        "    slur_density = slur_hits / n_words\n",
        "\n",
        "    cues = sum(text.lower().count(k) for k in [\"kill\", \"die\", \"trash\", \"dirty\", \"dog\", \"pig\", \"scum\", \"hate\"])\n",
        "    cue_density = cues / n_words\n",
        "\n",
        "    base_feats = np.array([\n",
        "        math.log1p(length), math.log1p(n_words), upper, digits, punct,\n",
        "        upper_ratio, digit_ratio, punct_ratio,\n",
        "        slur_hits, slur_density, cues, cue_density\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    if base_feats.shape[0] < HEURISTIC_DIM:\n",
        "        pad = np.zeros(HEURISTIC_DIM - base_feats.shape[0], dtype=np.float32)\n",
        "        feats = np.concatenate([base_feats, pad])\n",
        "    else:\n",
        "        feats = base_feats[:HEURISTIC_DIM]\n",
        "    return feats\n",
        "\n",
        "# -------------------------\n",
        "# Data collator (stacks heuristic feats)\n",
        "# -------------------------\n",
        "@dataclass\n",
        "class SentinelCollator:\n",
        "    def __call__(self, batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        out = {}\n",
        "        for k in (\"input_ids\", \"attention_mask\", \"labels\"):\n",
        "            out[k] = torch.stack([b[k] for b in batch])\n",
        "        feats = [\n",
        "            b[\"heuristic_feats\"] if isinstance(b[\"heuristic_feats\"], torch.Tensor)\n",
        "            else torch.tensor(b[\"heuristic_feats\"], dtype=torch.float32)\n",
        "            for b in batch\n",
        "        ]\n",
        "        out[\"heuristic_feats\"] = torch.stack(feats).to(torch.float32)\n",
        "        return out\n",
        "\n",
        "collator = SentinelCollator()\n",
        "\n",
        "# -------------------------\n",
        "# Load data (raw + tokenized with heuristic feats)\n",
        "# -------------------------\n",
        "def _load_data():\n",
        "    assert os.path.isfile(TEST_FILE), \"Test CSV not found.\"\n",
        "    data_files = {}\n",
        "    if os.path.isfile(TRAIN_FILE): data_files['train'] = TRAIN_FILE\n",
        "    if os.path.isfile(VAL_FILE):   data_files['validation'] = VAL_FILE\n",
        "    data_files['test'] = TEST_FILE\n",
        "    raw = load_dataset(\"csv\", data_files=data_files)\n",
        "\n",
        "    # try to read base model name from sentinel checkpoint config\n",
        "    try:\n",
        "        cfg_on_disk = SentinelConfig.from_pretrained(SENTINEL_CHECKPOINT)\n",
        "        base_model = cfg_on_disk.base_model_name\n",
        "        num_labels = cfg_on_disk.num_labels\n",
        "        h_dim = cfg_on_disk.heuristic_dim\n",
        "        global HEURISTIC_DIM\n",
        "        HEURISTIC_DIM = h_dim  # sync to saved config\n",
        "    except Exception:\n",
        "        base_model = \"xlm-roberta-base\"\n",
        "        num_labels = 2\n",
        "\n",
        "    tok = AutoTokenizer.from_pretrained(base_model)\n",
        "    def tok_map(batch):\n",
        "        enc = tok(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "        enc[\"heuristic_feats\"] = [build_heuristic_features(t) for t in batch[\"text\"]]\n",
        "        return enc\n",
        "\n",
        "    tokenized = raw.map(tok_map, batched=True)\n",
        "    if \"label\" in tokenized[\"test\"].column_names:\n",
        "        tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
        "    tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"heuristic_feats\"])\n",
        "    return raw, tokenized, tok, base_model, num_labels\n",
        "\n",
        "raw_datasets, tokenized_datasets, tokenizer, BASE_MODEL_NAME, NUM_LABELS = _load_data()\n",
        "\n",
        "# -------------------------\n",
        "# Load Sentinel model from checkpoint\n",
        "# -------------------------\n",
        "def load_sentinel_for_eval(checkpoint_dir: str):\n",
        "    cfg = SentinelConfig.from_pretrained(checkpoint_dir)\n",
        "    model = SentinelModel.from_pretrained(checkpoint_dir, config=cfg)  # will load weights if saved with Trainer\n",
        "    model.to(device)\n",
        "    return model, cfg\n",
        "\n",
        "model, cfg_loaded = load_sentinel_for_eval(SENTINEL_CHECKPOINT)\n",
        "\n",
        "eval_args = TrainingArguments(\n",
        "    output_dir=\"./tmp_eval_sentinel\",\n",
        "    per_device_eval_batch_size=32,\n",
        "    do_train=False, do_eval=True,\n",
        "    report_to=\"none\",\n",
        "    logging_strategy=\"no\",\n",
        "    disable_tqdm=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=eval_args,\n",
        "    data_collator=collator,\n",
        "    tokenizer=tokenizer,  # fine for eval\n",
        "    compute_metrics=None\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Attack tools (structural / semantic / feature-targeted)\n",
        "# -------------------------\n",
        "structural_typo   = nac.KeyboardAug()\n",
        "structural_insert = nac.RandomCharAug(action=\"insert\")\n",
        "\n",
        "def attack_structural_typo(text):\n",
        "    try: return structural_typo.augment(text)[0]\n",
        "    except Exception: return text\n",
        "\n",
        "def attack_structural_insert(text):\n",
        "    try: return structural_insert.augment(text)[0]\n",
        "    except Exception: return text\n",
        "\n",
        "def attack_structural_case(text, p_char=0.15):\n",
        "    if not isinstance(text, str): return text\n",
        "    out = []\n",
        "    for ch in text:\n",
        "        if ch.isalpha() and random.random() < p_char:\n",
        "            out.append(ch.upper() if ch.islower() else ch.lower())\n",
        "        else:\n",
        "            out.append(ch)\n",
        "    return \"\".join(out)\n",
        "\n",
        "synonym_aug = SynonymAug(aug_src=\"wordnet\", aug_p=0.15)\n",
        "def attack_semantic_synonym(text):\n",
        "    try:\n",
        "        out = synonym_aug.augment(text)\n",
        "        return out[0] if isinstance(out, list) and len(out) > 0 else out\n",
        "    except Exception:\n",
        "        if not isinstance(text, str): return text\n",
        "        toks = text.split()\n",
        "        idxs = list(range(len(toks))); random.shuffle(idxs)\n",
        "        for i in idxs:\n",
        "            tok = toks[i]\n",
        "            synsets = wn.synsets(tok)\n",
        "            if not synsets: continue\n",
        "            lemmas = []\n",
        "            for syn in synsets[:3]:\n",
        "                for l in syn.lemmas():\n",
        "                    cand = l.name().replace('_', ' ')\n",
        "                    if cand.lower() != tok.lower():\n",
        "                        lemmas.append(cand)\n",
        "            if lemmas:\n",
        "                toks[i] = random.choice(lemmas); break\n",
        "        return \" \".join(toks)\n",
        "\n",
        "CODED_LEXICON = {\n",
        "    r'\\bmuslims?\\b': 'skittles',\n",
        "    r'\\bblack( people)?\\b': 'googles',\n",
        "    r'\\bjews?\\b': 'skypes',\n",
        "    r'\\bmexicans?\\b': 'bings',\n",
        "}\n",
        "CODED_PATTERNS = [(re.compile(k, flags=re.IGNORECASE), v) for k, v in CODED_LEXICON.items()]\n",
        "def attack_semantic_coded(text):\n",
        "    if not isinstance(text, str): return text\n",
        "    out = text\n",
        "    for pat, repl in CODED_PATTERNS:\n",
        "        out = pat.sub(repl, out)\n",
        "    return out\n",
        "\n",
        "SLUR_LEXICON = [\n",
        "    r\"\\bmongol(s)?\\b\", r\"\\bretard(s|ed)?\\b\", r\"\\btolol\\b\", r\"\\bkontol\\b\",\n",
        "    r\"\\bbajingan\\b\", r\"\\bbabi\\b\", r\"\\bbhen ?chod\\b\", r\"\\bmadar ?chod\\b\",\n",
        "    r\"\\brandi\\b\", r\"\\bperra\\b\", r\"\\bzorra\\b\", r\"\\bputa\\b\"\n",
        "]\n",
        "SLUR_PATTERNS = [re.compile(p, flags=re.IGNORECASE) for p in SLUR_LEXICON]\n",
        "def attack_feature_slur_removal(text, replacement='[removed]'):\n",
        "    if not isinstance(text, str): return text\n",
        "    out = text\n",
        "    for pat in SLUR_PATTERNS:\n",
        "        out = pat.sub(replacement, out)\n",
        "    return out\n",
        "\n",
        "def apply_attack_texts(texts, attack_fn, desc=\"Attacking\"):\n",
        "    return [attack_fn(t) for t in tqdm(texts, desc=desc, leave=False)]\n",
        "\n",
        "# -------------------------\n",
        "# Per-class metrics helper\n",
        "# -------------------------\n",
        "def _per_class_metrics(y_true, y_pred, labels=(0, 1)):\n",
        "    p, r, f1, sup = precision_recall_fscore_support(y_true, y_pred, labels=list(labels), zero_division=0)\n",
        "    return [\n",
        "        {\"label\": int(lbl), \"precision\": float(p[i]), \"recall\": float(r[i]), \"f1\": float(f1[i]), \"support\": int(sup[i])}\n",
        "        for i, lbl in enumerate(labels)\n",
        "    ]\n",
        "\n",
        "# -------------------------\n",
        "# Eval helpers\n",
        "# -------------------------\n",
        "def evaluate_on_texts(trainer, tokenizer, texts, labels, max_length=128):\n",
        "    # Re-tokenize and rebuild heuristic feats for the (possibly) attacked texts\n",
        "    enc = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length)\n",
        "    feats = [build_heuristic_features(t) for t in texts]\n",
        "    ds = Dataset.from_dict({\n",
        "        \"input_ids\": enc[\"input_ids\"],\n",
        "        \"attention_mask\": enc[\"attention_mask\"],\n",
        "        \"heuristic_feats\": feats,\n",
        "        \"label\": labels\n",
        "    })\n",
        "    ds = ds.rename_column(\"label\", \"labels\")\n",
        "    ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\",\"heuristic_feats\"])\n",
        "    preds_out = trainer.predict(ds)\n",
        "    logits = preds_out.predictions\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return preds, logits\n",
        "\n",
        "# -------------------------\n",
        "# Attack runner (Sentinel only)\n",
        "# -------------------------\n",
        "def run_attack_and_report(\n",
        "    trainer,\n",
        "    tokenizer,\n",
        "    raw_test_dataset,\n",
        "    tokenized_test_dataset,\n",
        "    attack_fn,\n",
        "    attack_name,\n",
        "    attack_mode='tp',           # 'tp' (True positives only) or 'full'\n",
        "    save_dir=\"attack_reports/sentinel\"\n",
        "):\n",
        "    # Clean predictions (fast) on pre-tokenized test set\n",
        "    clean_out = trainer.predict(tokenized_test_dataset)\n",
        "    clean_logits = clean_out.predictions\n",
        "    clean_preds  = np.argmax(clean_logits, axis=-1)\n",
        "    clean_labels = clean_out.label_ids\n",
        "\n",
        "    # Per-class on clean\n",
        "    clean_per_class = _per_class_metrics(clean_labels, clean_preds)\n",
        "\n",
        "    # Raw texts/labels\n",
        "    raw_texts  = list(raw_test_dataset['text'])\n",
        "    raw_labels = list(raw_test_dataset['label'])\n",
        "    n = len(raw_texts)\n",
        "    assert n == len(clean_preds) == len(clean_labels)\n",
        "\n",
        "    # Target indices\n",
        "    if attack_mode == 'tp':\n",
        "        target_indices = [i for i, (lab, pred) in enumerate(zip(clean_labels, clean_preds)) if lab == 1 and pred == 1]\n",
        "    elif attack_mode == 'full':\n",
        "        target_indices = list(range(n))\n",
        "    else:\n",
        "        raise ValueError(\"attack_mode must be 'tp' or 'full'\")\n",
        "\n",
        "    if len(target_indices) == 0:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        report = {\n",
        "            \"attack_name\": attack_name, \"attack_mode\": attack_mode,\n",
        "            \"clean_per_class\": clean_per_class,\n",
        "            \"attacked_per_class\": None,\n",
        "            \"attack_changed\": 0,\n",
        "            \"tp_count_targeted\": 0,\n",
        "            \"samples_flipped\": None,\n",
        "            \"attack_success_rate\": None,\n",
        "            \"note\": \"no targets\"\n",
        "        }\n",
        "        with open(os.path.join(save_dir, f\"{attack_name}_{attack_mode}.json\"), \"w\") as f:\n",
        "            json.dump(report, f, indent=2)\n",
        "        return report\n",
        "\n",
        "    # Apply attack to targeted subset\n",
        "    attacked_texts = raw_texts.copy()\n",
        "    to_attack = [raw_texts[i] for i in target_indices]\n",
        "    attacked_outs = apply_attack_texts(to_attack, attack_fn, desc=attack_name)\n",
        "    attack_count = 0\n",
        "    for idx, new_text in zip(target_indices, attacked_outs):\n",
        "        if new_text != raw_texts[idx]:\n",
        "            attacked_texts[idx] = new_text\n",
        "            attack_count += 1\n",
        "\n",
        "    if attack_count == 0:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        report = {\n",
        "            \"attack_name\": attack_name, \"attack_mode\": attack_mode,\n",
        "            \"clean_per_class\": clean_per_class,\n",
        "            \"attacked_per_class\": None,\n",
        "            \"attack_changed\": 0,\n",
        "            \"tp_count_targeted\": len(target_indices),\n",
        "            \"samples_flipped\": None,\n",
        "            \"attack_success_rate\": None,\n",
        "            \"note\": \"no modification made by attack_fn\"\n",
        "        }\n",
        "        with open(os.path.join(save_dir, f\"{attack_name}_{attack_mode}.json\"), \"w\") as f:\n",
        "            json.dump(report, f, indent=2)\n",
        "        return report\n",
        "\n",
        "    # Evaluate attacked set (re-tokenize + rebuild heuristic feats)\n",
        "    attacked_preds, attacked_logits = evaluate_on_texts(trainer, tokenizer, attacked_texts, raw_labels)\n",
        "    attacked_per_class = _per_class_metrics(raw_labels, attacked_preds)\n",
        "\n",
        "    # ASR for TP mode\n",
        "    asr = None; samples_flipped = None\n",
        "    if attack_mode == 'tp':\n",
        "        attacked_for_targets_preds = [attacked_preds[i] for i in target_indices]\n",
        "        samples_flipped = sum(1 for p in attacked_for_targets_preds if p == 0)\n",
        "        asr = samples_flipped / len(target_indices)\n",
        "\n",
        "    report = {\n",
        "        \"attack_name\": attack_name,\n",
        "        \"attack_mode\": attack_mode,\n",
        "        \"clean_per_class\": clean_per_class,\n",
        "        \"attacked_per_class\": attacked_per_class,\n",
        "        \"attack_changed\": attack_count,\n",
        "        \"tp_count_targeted\": len(target_indices),\n",
        "        \"samples_flipped\": int(samples_flipped) if samples_flipped is not None else None,\n",
        "        \"attack_success_rate\": float(asr) if asr is not None else None\n",
        "    }\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    with open(os.path.join(save_dir, f\"{attack_name}_{attack_mode}.json\"), \"w\") as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "    return report\n",
        "\n",
        "def run_all_attacks_sentinel(\n",
        "    trainer,\n",
        "    tokenizer,\n",
        "    raw_test_dataset,\n",
        "    tokenized_test_dataset,\n",
        "    save_dir=\"attack_reports/sentinel\",\n",
        "    attack_mode='tp',\n",
        "    attacks_to_run=None\n",
        "):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    attacks = attacks_to_run or [\n",
        "        (attack_structural_typo,          \"structural_typo\"),\n",
        "        (attack_structural_insert,        \"structural_insert\"),\n",
        "        (attack_structural_case,          \"structural_case\"),\n",
        "        (attack_semantic_synonym,         \"semantic_synonym\"),\n",
        "        (attack_semantic_coded,           \"semantic_coded\"),\n",
        "        (lambda t: attack_feature_slur_removal(t, \"[removed]\"), \"feature_slur_removal\"),\n",
        "    ]\n",
        "    suite_report = {\n",
        "        \"model\": \"SentinelModel\",\n",
        "        \"checkpoint\": SENTINEL_CHECKPOINT,\n",
        "        \"attack_mode\": attack_mode,\n",
        "        \"attacks\": []\n",
        "    }\n",
        "    for fn, name in attacks:\n",
        "        print(f\"Running attack: {name} (mode={attack_mode})\")\n",
        "        rpt = run_attack_and_report(trainer, tokenizer, raw_test_dataset, tokenized_test_dataset, fn, name, attack_mode, save_dir)\n",
        "        if rpt is not None:\n",
        "            suite_report[\"attacks\"].append(rpt)\n",
        "    with open(os.path.join(save_dir, f\"suite_report_sentinel_{attack_mode}.json\"), \"w\") as f:\n",
        "        json.dump(suite_report, f, indent=2)\n",
        "    return suite_report\n",
        "\n",
        "# -------------------------\n",
        "# RUN (Sentinel only)\n",
        "# -------------------------\n",
        "print(\"Sentinel eval trainer ready. Running attacks...\")\n",
        "sentinel_report = run_all_attacks_sentinel(\n",
        "    trainer=trainer,\n",
        "    tokenizer=tokenizer,\n",
        "    raw_test_dataset=raw_datasets[\"test\"],\n",
        "    tokenized_test_dataset=tokenized_datasets[\"test\"],\n",
        "    save_dir=\"attack_reports/sentinel\",\n",
        "    attack_mode=\"tp\"   # change to \"full\" to attack all test texts\n",
        ")\n",
        "print(\"✓ Sentinel attacks finished. Reports -> attack_reports/sentinel\")\n"
      ],
      "metadata": {
        "id": "zLNhIHppoTDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "src = \"/content/attack_reports\"                     # where your reports live in Colab\n",
        "dst = \"/content/drive/MyDrive/hate/attack_reports\"  # destination in Drive\n",
        "\n",
        "if not os.path.exists(src):\n",
        "    raise FileNotFoundError(f\"Source folder not found: {src}\")\n",
        "\n",
        "os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "shutil.copytree(src, dst, dirs_exist_ok=True)  # dirs_exist_ok needs Python 3.8+\n",
        "\n",
        "print(f\"✓ Copied '{src}' → '{dst}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6ab1dnQo0KL",
        "outputId": "92dc468a-d694-4c8e-951b-b6aea7ab94ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Copied '/content/attack_reports' → '/content/drive/MyDrive/hate/attack_reports'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 3-Model ROC & PR Curves (600 dpi, saves PNG/PDF) ===\n",
        "# Paths\n",
        "DRIVE_BASE           = \"/content/drive/MyDrive/hate\"\n",
        "TRAIN_FILE           = f\"{DRIVE_BASE}/train.csv\"\n",
        "VAL_FILE             = f\"{DRIVE_BASE}/val.csv\"\n",
        "TEST_FILE            = f\"{DRIVE_BASE}/test.csv\"\n",
        "\n",
        "BASELINE_CKPT        = f\"{DRIVE_BASE}/models/step1_bert_baseline\"\n",
        "GATED_CKPT           = f\"{DRIVE_BASE}/models/step1_gated_fusion\"\n",
        "SENTINEL_CKPT        = f\"{DRIVE_BASE}/models/sentinel_xlmr\"\n",
        "\n",
        "FIG_DIR              = f\"{DRIVE_BASE}/fig\"\n",
        "\n",
        "# Deps\n",
        "!pip -q install transformers datasets scikit-learn matplotlib\n",
        "\n",
        "import os, re, math, json, numpy as np, torch, torch.nn as nn\n",
        "from typing import Dict, Any, List, Optional\n",
        "from dataclasses import dataclass\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModel, AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    PretrainedConfig, PreTrainedModel,\n",
        "    TrainingArguments, Trainer\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# Load test data\n",
        "# -------------------------\n",
        "assert os.path.isfile(TEST_FILE), \"TEST_FILE not found.\"\n",
        "raw = load_dataset(\"csv\", data_files={\"test\": TEST_FILE})\n",
        "assert \"text\" in raw[\"test\"].column_names and \"label\" in raw[\"test\"].column_names, \"CSV must have 'text' and 'label' columns.\"\n",
        "\n",
        "texts  = list(raw[\"test\"][\"text\"])\n",
        "y_true = np.array(list(raw[\"test\"][\"label\"]), dtype=int)\n",
        "\n",
        "# -------------------------\n",
        "# Sentinel model/types (must match training)\n",
        "# -------------------------\n",
        "class SentinelConfig(PretrainedConfig):\n",
        "    model_type = \"sentinel_fusion\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_model_name: str = \"xlm-roberta-base\",\n",
        "        num_labels: int = 2,\n",
        "        heuristic_dim: int = 32,\n",
        "        heuristic_hidden: int = 256,\n",
        "        causal_hidden: int = 256,\n",
        "        attn_heads: int = 8,\n",
        "        aux_causal_loss_weight: float = 0.2,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.base_model_name = base_model_name\n",
        "        self.num_labels = num_labels\n",
        "        self.heuristic_dim = heuristic_dim\n",
        "        self.heuristic_hidden = heuristic_hidden\n",
        "        self.causal_hidden = causal_hidden\n",
        "        self.attn_heads = attn_heads\n",
        "        self.aux_causal_loss_weight = aux_causal_loss_weight\n",
        "\n",
        "class SentinelModel(PreTrainedModel):\n",
        "    config_class = SentinelConfig\n",
        "    def __init__(self, config: SentinelConfig):\n",
        "        super().__init__(config)\n",
        "        self.base_cfg = AutoConfig.from_pretrained(config.base_model_name)\n",
        "        self.encoder = AutoModel.from_pretrained(config.base_model_name, config=self.base_cfg)\n",
        "        hidden = self.base_cfg.hidden_size\n",
        "\n",
        "        self.heuristic_proj = nn.Sequential(\n",
        "            nn.Linear(config.heuristic_dim, config.heuristic_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.heuristic_hidden, hidden),\n",
        "            nn.LayerNorm(hidden)\n",
        "        )\n",
        "        self.causal_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden, config.causal_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.causal_hidden, hidden),\n",
        "            nn.LayerNorm(hidden)\n",
        "        )\n",
        "        self.causal_aux_head = nn.Linear(hidden, 2)\n",
        "        self.xattn = nn.MultiheadAttention(embed_dim=hidden, num_heads=config.attn_heads, batch_first=True)\n",
        "        self.dropout = nn.Dropout(getattr(self.base_cfg, \"hidden_dropout_prob\", 0.1))\n",
        "        self.classifier = nn.Linear(hidden, config.num_labels)\n",
        "        self.post_init()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        heuristic_feats=None,\n",
        "        labels=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        enc = self.encoder(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        last_hidden = enc.last_hidden_state\n",
        "        h_cls = last_hidden[:, 0, :]\n",
        "        h_heu = self.heuristic_proj(heuristic_feats)\n",
        "        h_cau = self.causal_mlp(h_cls)\n",
        "        Q  = h_cls.unsqueeze(1)\n",
        "        KV = torch.stack([h_heu, h_cau], dim=1)\n",
        "        fused, _ = self.xattn(Q, KV, KV)\n",
        "        fused = fused.squeeze(1)\n",
        "        logits = self.classifier(self.dropout(fused))\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "# -------------------------\n",
        "# Gated fusion model/types (from earlier)\n",
        "# -------------------------\n",
        "class GFConfig(PretrainedConfig):\n",
        "    model_type = \"gated_fusion_wrapper\"\n",
        "    def __init__(self, base_model_name: str = \"bert-base-multilingual-cased\", num_labels: int = 2, gate_hidden: int = 256, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.base_model_name = base_model_name\n",
        "        self.num_labels = num_labels\n",
        "        self.gate_hidden = gate_hidden\n",
        "\n",
        "class GatedFusionForSequenceClassification(PreTrainedModel):\n",
        "    config_class = GFConfig\n",
        "    def __init__(self, config: GFConfig):\n",
        "        super().__init__(config)\n",
        "        self.base_cfg = AutoConfig.from_pretrained(config.base_model_name)\n",
        "        self.encoder = AutoModel.from_pretrained(config.base_model_name, config=self.base_cfg)\n",
        "        hidden = self.base_cfg.hidden_size\n",
        "        self.gate_mlp = nn.Sequential(\n",
        "            nn.Linear(2 * hidden, config.gate_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.gate_hidden, hidden),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.dropout = nn.Dropout(getattr(self.base_cfg, \"hidden_dropout_prob\", 0.1))\n",
        "        self.classifier = nn.Linear(hidden, config.num_labels)\n",
        "        self.post_init()\n",
        "\n",
        "    @staticmethod\n",
        "    def masked_mean(last_hidden_state, attention_mask):\n",
        "        mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n",
        "        summed = (last_hidden_state * mask).sum(dim=1)\n",
        "        denom = mask.sum(dim=1).clamp(min=1e-6)\n",
        "        return summed / denom\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
        "        allowed = {\"position_ids\",\"head_mask\",\"inputs_embeds\",\"output_attentions\",\"output_hidden_states\",\"return_dict\",\"past_key_values\",\"encoder_hidden_states\",\"encoder_attention_mask\"}\n",
        "        safe_kwargs = {k: v for k, v in kwargs.items() if k in allowed}\n",
        "        safe_kwargs.pop(\"num_items_in_batch\", None)\n",
        "\n",
        "        enc = self.encoder(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **safe_kwargs)\n",
        "        h_cls = enc.last_hidden_state[:, 0, :]\n",
        "        h_mean = self.masked_mean(enc.last_hidden_state, attention_mask)\n",
        "        gate_inp = torch.cat([h_cls, h_mean], dim=-1)\n",
        "        g = self.gate_mlp(gate_inp)\n",
        "        fused = g * h_cls + (1.0 - g) * h_mean\n",
        "        logits = self.classifier(self.dropout(fused))\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "# -------------------------\n",
        "# Heuristic features (Sentinel) — keep in sync with training\n",
        "# -------------------------\n",
        "_SLUR_REGEXES = [\n",
        "    r\"\\bmongol(s)?\\b\", r\"\\bretard(s|ed)?\\b\", r\"\\btolol\\b\", r\"\\bkontol\\b\",\n",
        "    r\"\\bbajingan\\b\", r\"\\bbabi\\b\", r\"\\bbhen ?chod\\b\", r\"\\bmadar ?chod\\b\",\n",
        "    r\"\\brandi\\b\", r\"\\bperra\\b\", r\"\\bzorra\\b\", r\"\\bputa\\b\"\n",
        "]\n",
        "_SLUR_PATTERNS = [re.compile(p, re.IGNORECASE) for p in _SLUR_REGEXES]\n",
        "\n",
        "def _build_heuristic_features(text: str, H: int) -> np.ndarray:\n",
        "    if not isinstance(text, str):\n",
        "        text = \"\" if text is None else str(text)\n",
        "    length = len(text)\n",
        "    words  = text.split()\n",
        "    n_words = max(1, len(words))\n",
        "    upper  = sum(1 for c in text if c.isalpha() and c.isupper())\n",
        "    digits = sum(1 for c in text if c.isdigit())\n",
        "    punct  = sum(1 for c in text if c in \".,;:!?\")\n",
        "    alpha_count = max(1, sum(c.isalpha() for c in text))\n",
        "    upper_ratio = upper / alpha_count\n",
        "    digit_ratio = digits / max(1, len(text))\n",
        "    punct_ratio = punct / max(1, len(text))\n",
        "    slur_hits = 0\n",
        "    for pat in _SLUR_PATTERNS:\n",
        "        slur_hits += len(pat.findall(text))\n",
        "    slur_density = slur_hits / n_words\n",
        "    cues = sum(text.lower().count(k) for k in [\"kill\", \"die\", \"trash\", \"dirty\", \"dog\", \"pig\", \"scum\", \"hate\"])\n",
        "    cue_density = cues / n_words\n",
        "    base_feats = np.array([\n",
        "        math.log1p(length), math.log1p(n_words), upper, digits, punct,\n",
        "        upper_ratio, digit_ratio, punct_ratio,\n",
        "        slur_hits, slur_density, cues, cue_density\n",
        "    ], dtype=np.float32)\n",
        "    if base_feats.shape[0] < H:\n",
        "        pad = np.zeros(H - base_feats.shape[0], dtype=np.float32)\n",
        "        feats = np.concatenate([base_feats, pad])\n",
        "    else:\n",
        "        feats = base_feats[:H]\n",
        "    return feats\n",
        "\n",
        "@dataclass\n",
        "class SentinelCollator:\n",
        "    def __call__(self, batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        out = {\n",
        "            \"input_ids\": torch.stack([b[\"input_ids\"] for b in batch]),\n",
        "            \"attention_mask\": torch.stack([b[\"attention_mask\"] for b in batch]),\n",
        "            \"labels\": torch.stack([b[\"labels\"] for b in batch])\n",
        "        }\n",
        "        feats = [\n",
        "            (b[\"heuristic_feats\"] if isinstance(b[\"heuristic_feats\"], torch.Tensor)\n",
        "             else torch.tensor(b[\"heuristic_feats\"], dtype=torch.float32))\n",
        "            for b in batch\n",
        "        ]\n",
        "        out[\"heuristic_feats\"] = torch.stack(feats).to(torch.float32)\n",
        "        return out\n",
        "\n",
        "# -------------------------\n",
        "# Utility: get probabilities for positive class (label=1)\n",
        "# -------------------------\n",
        "def _softmax_np(logits: np.ndarray) -> np.ndarray:\n",
        "    z = logits - logits.max(axis=1, keepdims=True)\n",
        "    e = np.exp(z)\n",
        "    p = e / e.sum(axis=1, keepdims=True)\n",
        "    return p\n",
        "\n",
        "def predict_probs_baseline_or_gated(ckpt: str, texts: list) -> np.ndarray:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(ckpt)\n",
        "    # Try plain classifier first; fall back to custom gated head if needed\n",
        "    try:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(ckpt)\n",
        "    except Exception:\n",
        "        cfg = GFConfig.from_pretrained(ckpt)\n",
        "        model = GatedFusionForSequenceClassification.from_pretrained(ckpt, config=cfg)\n",
        "    model.to(device).eval()\n",
        "\n",
        "    # Return lists (not tensors) for Dataset.from_dict\n",
        "    enc = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
        "    ds = Dataset.from_dict({\n",
        "        \"input_ids\": enc[\"input_ids\"],\n",
        "        \"attention_mask\": enc[\"attention_mask\"],\n",
        "        \"labels\": y_true.tolist(),   # already named 'labels' -> no rename\n",
        "    })\n",
        "    ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=\"./tmp_eval_generic\",\n",
        "        per_device_eval_batch_size=64,\n",
        "        report_to=\"none\", logging_strategy=\"no\", disable_tqdm=True\n",
        "    )\n",
        "    tr = Trainer(model=model, args=args, compute_metrics=None, tokenizer=tokenizer)\n",
        "    out = tr.predict(ds)\n",
        "    probs = _softmax_np(out.predictions)[:, 1]\n",
        "    return probs\n",
        "\n",
        "\n",
        "def predict_probs_sentinel(ckpt: str, texts: list) -> np.ndarray:\n",
        "    cfg = SentinelConfig.from_pretrained(ckpt)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(cfg.base_model_name)\n",
        "    model = SentinelModel.from_pretrained(ckpt, config=cfg).to(device).eval()\n",
        "\n",
        "    enc = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
        "    feats = [_build_heuristic_features(t, cfg.heuristic_dim) for t in texts]\n",
        "    ds = Dataset.from_dict({\n",
        "        \"input_ids\": enc[\"input_ids\"],\n",
        "        \"attention_mask\": enc[\"attention_mask\"],\n",
        "        \"heuristic_feats\": feats,\n",
        "        \"labels\": y_true.tolist(),   # already 'labels'\n",
        "    })\n",
        "    ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"heuristic_feats\"])\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=\"./tmp_eval_sentinel\",\n",
        "        per_device_eval_batch_size=64,\n",
        "        report_to=\"none\", logging_strategy=\"no\", disable_tqdm=True\n",
        "    )\n",
        "    tr = Trainer(\n",
        "        model=model, args=args, compute_metrics=None,\n",
        "        data_collator=SentinelCollator(), tokenizer=tokenizer\n",
        "    )\n",
        "    out = tr.predict(ds)\n",
        "    probs = _softmax_np(out.predictions)[:, 1]\n",
        "    return probs\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Get probabilities for each model\n",
        "# -------------------------\n",
        "print(\"Scoring test set with Baseline...\")\n",
        "probs_baseline = predict_probs_baseline_or_gated(BASELINE_CKPT, texts)\n",
        "\n",
        "print(\"Scoring test set with Gated Fusion...\")\n",
        "probs_gated = predict_probs_baseline_or_gated(GATED_CKPT, texts)\n",
        "\n",
        "print(\"Scoring test set with Sentinel...\")\n",
        "probs_sentinel = predict_probs_sentinel(SENTINEL_CKPT, texts)\n",
        "\n",
        "# -------------------------\n",
        "# Compute curves & metrics\n",
        "# -------------------------\n",
        "def compute_roc_pr(y_true, y_score):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_true, y_score)\n",
        "    prec, rec, _ = precision_recall_curve(y_true, y_score, pos_label=1)\n",
        "    ap = average_precision_score(y_true, y_score)  # area under PR (AP)\n",
        "    return (fpr, tpr, roc_auc), (rec, prec, ap)\n",
        "\n",
        "roc_pr = {}\n",
        "roc_pr[\"Baseline\"]  = compute_roc_pr(y_true, probs_baseline)\n",
        "roc_pr[\"Gated\"]     = compute_roc_pr(y_true, probs_gated)\n",
        "roc_pr[\"Sentinel\"]  = compute_roc_pr(y_true, probs_sentinel)\n",
        "\n",
        "# -------------------------\n",
        "# Plot ROC (all 3) — 600 dpi\n",
        "# -------------------------\n",
        "plt.figure(figsize=(6, 6), dpi=600)\n",
        "for name, ((fpr, tpr, aucv), _) in roc_pr.items():\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUC={aucv:.3f})\", linewidth=1.5)\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", linewidth=1.0)\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curves (Test)\")\n",
        "plt.legend(loc=\"lower right\", frameon=False)\n",
        "plt.tight_layout()\n",
        "roc_png = os.path.join(FIG_DIR, \"roc_three_models.png\")\n",
        "roc_pdf = os.path.join(FIG_DIR, \"roc_three_models.pdf\")\n",
        "plt.savefig(roc_png, dpi=600)\n",
        "plt.savefig(roc_pdf, dpi=600)\n",
        "plt.close()\n",
        "\n",
        "# -------------------------\n",
        "# Plot Precision–Recall (all 3) — 600 dpi\n",
        "# -------------------------\n",
        "plt.figure(figsize=(6, 6), dpi=600)\n",
        "for name, (_, (rec, prec, ap)) in roc_pr.items():\n",
        "    plt.plot(rec, prec, label=f\"{name} (AP={ap:.3f})\", linewidth=1.5)\n",
        "# Baseline of PR depends on class prevalence; no trivial diagonal\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision–Recall Curves (Test)\")\n",
        "plt.legend(loc=\"lower left\", frameon=False)\n",
        "plt.tight_layout()\n",
        "pr_png = os.path.join(FIG_DIR, \"pr_three_models.png\")\n",
        "pr_pdf = os.path.join(FIG_DIR, \"pr_three_models.pdf\")\n",
        "plt.savefig(pr_png, dpi=600)\n",
        "plt.savefig(pr_pdf, dpi=600)\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved figures:\")\n",
        "print(\" -\", roc_png)\n",
        "print(\" -\", roc_pdf)\n",
        "print(\" -\", pr_png)\n",
        "print(\" -\", pr_pdf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531,
          "referenced_widgets": [
            "a3bda7b4f18549ecb50fff79af98c236",
            "1a17a1e5feb04ed2bda70b44bcb4d60c",
            "ec9a8b560c0f447db8a7c97d5702d6be",
            "d8887528199a4e1a9ff1c0488aab63b5",
            "f61c6e29aa6c4d49949f51a395c8e889",
            "7ff7b382e1104fd583d48cd4ec3201e3",
            "be5aa5f71bb84181a16b4ab3f99b534d",
            "7e4b9fbc6e4b4badb1ba92b009636225",
            "13ed1ed551224643bdaf2f487d8830cc",
            "40c0b0bc9de94928b20353ad2c1b4635",
            "239b0e3569344ce8872048a9e20e1d2e",
            "22880230a7ab4c498c4157193991efe4",
            "be665d7524874e77a866c5e5017a47c8",
            "2c07dad7f8484c55878932b001be4161",
            "ccfe69a8170b4557926a0dc3ed7994fb",
            "9c8d2f4ed1ab4fa69f093dac9dd09a30",
            "264f589bd6bc4afb9b7ea1533f8ad8be",
            "bbcc331048944b90a4d620cc5389c334",
            "8547bf98e4b042e9bfa2432d49f8c283",
            "2a5c239d3b4b4bd9ae4c0a72e0310603",
            "c6804799e35f4df1b0f6833c2fb41aa1",
            "4e5c4ffcf08144aca735dfc4ec2337d2",
            "689640d8a9434534b1d30fd31e039971",
            "aa5bf3fdc85b479ab2af7355e87cf529",
            "c4195fd693c6407f9443cea79a394094",
            "8f2f7f822dce45b8ba0323277c73a554",
            "ffdb1c470a9e4b9db771b2e0d9ed5cb2",
            "8de5f1325cee4613b9150ddd2793b4b3",
            "d5ec4ea32c1040a3af39272917f7fe93",
            "0d75e0fb62fd429e9eb519e72ba34e40",
            "85a3383293184e528322d61d2cfa4b98",
            "337daf0e5e3b41988a37df6d7121ea2f",
            "7472ae1240a7474e98295d40e9d2d1d2",
            "df6ac738edd54a2485a7ab0c6d1769a6",
            "657a9694962744c99ada5af00470b3dd",
            "393aa52cf6214ec79d1118164231652e",
            "ad72e5c4243c432f89c750b7e86be7f0",
            "d4a183a03ae34337bfa6035ced85ab4b",
            "3140fd6dfb9f46d38fb6edc1c172b7b8",
            "9055d956cfd746b28d819800cbdab728",
            "78f8354463dd46eda374722142a6411d",
            "bd0c970444ef498193c0ea37f1cce214",
            "d07765549bbb48f38856b9f6ccf3bff9",
            "bd277eea6ca845edb14a8554fac766de",
            "928af9d495bc40258cc28035d0112c71",
            "e27bc9ae61344291a56f9c2243848ecb",
            "010b60932e5f43eb879554fadbfae1c1",
            "0b6380bba7fa4e168276d8fa670b2ee9",
            "b3429e36508149f9913d8293b416e481",
            "8d0a524505a4452da4020d9f1c3ef7d9",
            "0d9e69ade2714fa48dfea1020bf1e7e2",
            "1c507d8ea3c143be9b98c159d1fe9367",
            "b956f76547114777a5d9636adac71330",
            "9223d748493a49beb7313eabd33e0c31",
            "39e5c69432154f199964ce7c35e199b4",
            "fa2c9cb6984043c49c91e80417712bf7",
            "ab289549c720446482433fef13fd700d",
            "2627aa812bd841aa9052217a959503d1",
            "af059f9721f24303a08d20267b429540",
            "2ea66461bd864709a7d07ae10a9b6387",
            "f36646f41c9b474f822406dd4e150453",
            "aa12d8acb3d9416fba94b5b13c445caf",
            "220f64f7b8be4afbb7c307218424804b",
            "7718d770ed4c411db028675b8ffe84e1",
            "b2afe515d3b24c37a44a60dce28a1b3b",
            "3e50d98382f8452085323ddaf9cedb37",
            "c779d39f3ee54d2a838fef7cf93aa0a4",
            "8970b676b8f04fcdb69ac44ae247b23a",
            "7487ca9f14c046b8a9d1b686021778ff",
            "c8774bc4c3604f76ac7ea63999149cd5",
            "4c72f851c12d4a54820e282c99b24ab3",
            "0b6a8d06a29c416184a61360f8da87c2",
            "1a6d91f5263b4103b6a4aebc2b73a482",
            "b9d32a43d6374d748b9ef9de44826609",
            "440a8f5eefc441a0b2447630494ef6c4",
            "6edbc089e8704acaa220ac2d9a0892ef",
            "98114257003c4b158e1d7159f51e94be",
            "a3e9f44536fe464fa2c0b38a3f881438",
            "caa6a826b9e74ed2869aeb9983633778",
            "d6657e1e9443493584695049324fa564",
            "1fc3d74eefac4e1fb0f2b731b06aa6be",
            "6111a0b3b7b14aabb31ad6489623cf9d",
            "72e8cad1195f4e618871a6abff9e11dc",
            "a0d86574539c489daf617028a569d828",
            "9bd583e102c14279b04d3f517a132da3",
            "be1b9d1a67184e39b117306620f6586f",
            "c3edcf42816042ba98561567512da382",
            "999f91846ef44867a58eef105bf4d326"
          ]
        },
        "collapsed": true,
        "id": "bqZO12o1wjot",
        "outputId": "26f6a114-2c7d-479b-840e-b2944006e8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3bda7b4f18549ecb50fff79af98c236"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring test set with Baseline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3983870063.py:262: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  tr = Trainer(model=model, args=args, compute_metrics=None, tokenizer=tokenizer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring test set with Gated Fusion...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22880230a7ab4c498c4157193991efe4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "689640d8a9434534b1d30fd31e039971"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3983870063.py:262: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  tr = Trainer(model=model, args=args, compute_metrics=None, tokenizer=tokenizer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring test set with Sentinel...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df6ac738edd54a2485a7ab0c6d1769a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "928af9d495bc40258cc28035d0112c71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa2c9cb6984043c49c91e80417712bf7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c779d39f3ee54d2a838fef7cf93aa0a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3e9f44536fe464fa2c0b38a3f881438"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3983870063.py:288: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  tr = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved figures:\n",
            " - /content/drive/MyDrive/hate/fig/roc_three_models.png\n",
            " - /content/drive/MyDrive/hate/fig/roc_three_models.pdf\n",
            " - /content/drive/MyDrive/hate/fig/pr_three_models.png\n",
            " - /content/drive/MyDrive/hate/fig/pr_three_models.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# BAR CHARTS: Clean vs Adv + Attack-wise (ASR)\n",
        "# Saves 600dpi figs to /content/drive/MyDrive/hate/figs\n",
        "# ================================\n",
        "\n",
        "import os, json, math, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 0) Mount Drive (skip if already mounted)\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/hate\"\n",
        "REPORT_ROOT = os.path.join(BASE, \"attack_reports\")\n",
        "FIG_DIR = os.path.join(BASE, \"figs\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "# 1) Discover model report folders (e.g., baseline, gated, sentinel)\n",
        "if not os.path.isdir(REPORT_ROOT):\n",
        "    raise FileNotFoundError(f\"Report root not found: {REPORT_ROOT}\")\n",
        "\n",
        "model_dirs = [d for d in glob.glob(os.path.join(REPORT_ROOT, \"*\")) if os.path.isdir(d)]\n",
        "if not model_dirs:\n",
        "    raise RuntimeError(f\"No model subfolders under {REPORT_ROOT}\")\n",
        "\n",
        "# Friendly labels (optional mapping)\n",
        "label_map = {\n",
        "    \"baseline\": \"Baseline\",\n",
        "    \"gated\": \"Gated Fusion\",\n",
        "    \"sentinel\": \"Sentinel\",\n",
        "}\n",
        "def pretty_model_name(path):\n",
        "    name = os.path.basename(path)\n",
        "    return label_map.get(name.lower(), name)\n",
        "\n",
        "# 2) Parse attack JSONs into a tidy DataFrame\n",
        "rows = []\n",
        "for mdir in model_dirs:\n",
        "    model_name = pretty_model_name(mdir)\n",
        "    for f in glob.glob(os.path.join(mdir, \"*.json\")):\n",
        "        # Skip suite report jsons\n",
        "        base = os.path.basename(f)\n",
        "        if base.startswith(\"suite_report\"):\n",
        "            continue\n",
        "        try:\n",
        "            with open(f, \"r\") as fp:\n",
        "                data = json.load(fp)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        attack_name = data.get(\"attack_name\", os.path.splitext(base)[0])\n",
        "\n",
        "        # Compute macro-F1 from per-class metrics arrays\n",
        "        clean_pc = data.get(\"clean_per_class\", [])\n",
        "        attacked_pc = data.get(\"attacked_per_class\", [])\n",
        "\n",
        "        def macro_f1(pc):\n",
        "            if isinstance(pc, list) and pc and isinstance(pc[0], dict) and \"f1\" in pc[0]:\n",
        "                return float(np.mean([float(x.get(\"f1\", 0.0)) for x in pc]))\n",
        "            return np.nan\n",
        "\n",
        "        clean_f1 = macro_f1(clean_pc)\n",
        "        attacked_f1 = macro_f1(attacked_pc)\n",
        "        delta_f1 = np.nan\n",
        "        if not math.isnan(clean_f1) and not math.isnan(attacked_f1):\n",
        "            delta_f1 = attacked_f1 - clean_f1\n",
        "\n",
        "        asr = data.get(\"attack_success_rate\", None)\n",
        "        if asr is None:\n",
        "            asr = np.nan\n",
        "\n",
        "        rows.append({\n",
        "            \"model\": model_name,\n",
        "            \"attack\": attack_name,\n",
        "            \"clean_macro_f1\": clean_f1,\n",
        "            \"attacked_macro_f1\": attacked_f1,\n",
        "            \"delta_macro_f1\": delta_f1,\n",
        "            \"attack_success_rate\": asr\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "if df.empty:\n",
        "    raise RuntimeError(\"No usable attack JSON files found under attack_reports/*/*.json.\")\n",
        "\n",
        "# Order models nicely if present\n",
        "model_order = [lbl for key, lbl in label_map.items() if lbl in df[\"model\"].unique()]\n",
        "if not model_order:\n",
        "    model_order = sorted(df[\"model\"].unique())\n",
        "\n",
        "# -------------------------------\n",
        "# Figure 1: Mean clean vs attacked F1 per model\n",
        "# -------------------------------\n",
        "agg = df.groupby(\"model\", as_index=False)[[\"clean_macro_f1\", \"attacked_macro_f1\"]].mean(numeric_only=True)\n",
        "agg[\"model\"] = pd.Categorical(agg[\"model\"], categories=model_order, ordered=True)\n",
        "agg = agg.sort_values(\"model\")\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "x = np.arange(len(agg))\n",
        "w = 0.35\n",
        "plt.bar(x - w/2, agg[\"clean_macro_f1\"], width=w, label=\"Clean macro-F1\")\n",
        "plt.bar(x + w/2, agg[\"attacked_macro_f1\"], width=w, label=\"Attacked macro-F1\")\n",
        "plt.xticks(x, agg[\"model\"], rotation=0)\n",
        "plt.ylabel(\"Macro-F1\")\n",
        "plt.title(\"Clean vs. Adversarial (Mean Macro-F1) by Model\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "fig1_path = os.path.join(FIG_DIR, \"clean_vs_adv_f1_by_model.png\")\n",
        "plt.savefig(fig1_path, dpi=600)\n",
        "plt.close()\n",
        "\n",
        "# -------------------------------\n",
        "# Figure 2: Attack-wise comparison across models\n",
        "# Prefer ASR; fallback to normalized -ΔF1 if ASR missing\n",
        "# -------------------------------\n",
        "df_asr = df.copy()\n",
        "\n",
        "# Fallback: if ASR missing, use normalized -delta_f1 (clip to [0,1]) as a rough proxy\n",
        "mask_missing_asr = df_asr[\"attack_success_rate\"].isna()\n",
        "if mask_missing_asr.any():\n",
        "    approx_asr = (-df_asr.loc[mask_missing_asr, \"delta_macro_f1\"]).clip(lower=0.0, upper=1.0)\n",
        "    df_asr.loc[mask_missing_asr, \"attack_success_rate\"] = approx_asr\n",
        "\n",
        "# Keep common attacks across models for fair plotting (or all if none common)\n",
        "common_attacks = sorted(\n",
        "    set.intersection(*[set(df_asr[df_asr[\"model\"] == m][\"attack\"].unique()) for m in df_asr[\"model\"].unique()])\n",
        ") or sorted(df_asr[\"attack\"].unique())\n",
        "\n",
        "plot_df = df_asr[df_asr[\"attack\"].isin(common_attacks)].copy()\n",
        "plot_df[\"model\"] = pd.Categorical(plot_df[\"model\"], categories=model_order, ordered=True)\n",
        "plot_df = plot_df.sort_values([\"attack\", \"model\"])\n",
        "\n",
        "attacks = common_attacks\n",
        "M = len(model_order)\n",
        "N = len(attacks)\n",
        "bar_w = 0.8 / max(1, M)\n",
        "indices = np.arange(N)\n",
        "\n",
        "plt.figure(figsize=(max(8, N * 0.6), 5))\n",
        "for i, m in enumerate(model_order):\n",
        "    vals = []\n",
        "    for a in attacks:\n",
        "        row = plot_df[(plot_df[\"model\"] == m) & (plot_df[\"attack\"] == a)]\n",
        "        vals.append(float(row[\"attack_success_rate\"].iloc[0]) if not row.empty else np.nan)\n",
        "    vals = np.array(vals, dtype=float)\n",
        "    plt.bar(indices + i * bar_w - (M-1)*bar_w/2, vals, width=bar_w, label=m)\n",
        "\n",
        "plt.xticks(indices, attacks, rotation=35, ha=\"right\")\n",
        "plt.ylabel(\"Attack Success Rate (ASR)\")\n",
        "plt.title(\"Attack-wise Comparison by Model\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "fig2_path = os.path.join(FIG_DIR, \"asr_by_attack_and_model.png\")\n",
        "plt.savefig(fig2_path, dpi=600)\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved 600dpi figures to:\")\n",
        "print(\" -\", fig1_path)\n",
        "print(\" -\", fig2_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otBOWOM5qKHs",
        "outputId": "07e7b5ee-f023-4af3-b5e3-1c3f273b1f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 600dpi figures to:\n",
            " - /content/drive/MyDrive/hate/figs/clean_vs_adv_f1_by_model.png\n",
            " - /content/drive/MyDrive/hate/figs/asr_by_attack_and_model.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# TABULAR VIEW: per-attack + grouped (3 categories)\n",
        "# ================================\n",
        "import os, json, glob, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Drive (skip if already mounted)\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/hate\"\n",
        "REPORT_ROOT = os.path.join(BASE, \"attack_reports\")\n",
        "\n",
        "# --- discover model subfolders\n",
        "if not os.path.isdir(REPORT_ROOT):\n",
        "    raise FileNotFoundError(f\"Report root not found: {REPORT_ROOT}\")\n",
        "\n",
        "model_dirs = [d for d in glob.glob(os.path.join(REPORT_ROOT, \"*\")) if os.path.isdir(d)]\n",
        "if not model_dirs:\n",
        "    raise RuntimeError(f\"No model subfolders under {REPORT_ROOT}\")\n",
        "\n",
        "# Pretty names (optional)\n",
        "label_map = {\n",
        "    \"baseline\": \"Baseline\",\n",
        "    \"gated\": \"Gated Fusion\",\n",
        "    \"sentinel\": \"Sentinel\",\n",
        "}\n",
        "def pretty_model_name(path):\n",
        "    name = os.path.basename(path)\n",
        "    return label_map.get(name.lower(), name)\n",
        "\n",
        "# --- attack -> category mapping\n",
        "def attack_category(name: str) -> str:\n",
        "    n = name.lower()\n",
        "    if n in {\"structural_typo\", \"structural_insert\", \"structural_case\"}:\n",
        "        return \"Structural\"\n",
        "    if n in {\"semantic_synonym\", \"semantic_coded\"}:\n",
        "        return \"Semantic/Cue\"\n",
        "    if n in {\"feature_slur_removal\"}:\n",
        "        return \"Feature-Targeted\"\n",
        "    # fallback: guess by keywords\n",
        "    if \"structural\" in n or \"typo\" in n or \"insert\" in n or \"case\" in n:\n",
        "        return \"Structural\"\n",
        "    if \"synonym\" in n or \"coded\" in n or \"semantic\" in n:\n",
        "        return \"Semantic/Cue\"\n",
        "    if \"slur\" in n or \"feature\" in n:\n",
        "        return \"Feature-Targeted\"\n",
        "    return \"Uncategorized\"\n",
        "\n",
        "# --- helpers\n",
        "def macro_f1_from_perclass(per_class_list):\n",
        "    if isinstance(per_class_list, list) and per_class_list and isinstance(per_class_list[0], dict):\n",
        "        vals = [float(x.get(\"f1\", 0.0)) for x in per_class_list]\n",
        "        return float(np.mean(vals)) if len(vals) else np.nan\n",
        "    return np.nan\n",
        "\n",
        "# --- parse all JSONs\n",
        "rows = []\n",
        "for mdir in model_dirs:\n",
        "    model_name = pretty_model_name(mdir)\n",
        "    for f in glob.glob(os.path.join(mdir, \"*.json\")):\n",
        "        base = os.path.basename(f)\n",
        "        if base.startswith(\"suite_report\"):\n",
        "            continue\n",
        "        try:\n",
        "            with open(f, \"r\") as fp:\n",
        "                data = json.load(fp)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        attack_name = data.get(\"attack_name\", os.path.splitext(base)[0])\n",
        "\n",
        "        clean_f1 = macro_f1_from_perclass(data.get(\"clean_per_class\", []))\n",
        "        attacked_f1 = macro_f1_from_perclass(data.get(\"attacked_per_class\", []))\n",
        "        dF1 = np.nan\n",
        "        if not math.isnan(clean_f1) and not math.isnan(attacked_f1):\n",
        "            dF1 = attacked_f1 - clean_f1\n",
        "\n",
        "        asr = data.get(\"attack_success_rate\", np.nan)\n",
        "\n",
        "        rows.append({\n",
        "            \"model\": model_name,\n",
        "            \"attack\": attack_name,\n",
        "            \"category\": attack_category(attack_name),\n",
        "            \"clean_macro_f1\": clean_f1,\n",
        "            \"attacked_macro_f1\": attacked_f1,\n",
        "            \"delta_macro_f1\": dF1,\n",
        "            \"ASR\": asr\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "if df.empty:\n",
        "    raise RuntimeError(\"No usable attack JSON files found.\")\n",
        "\n",
        "# --- tidy ordering\n",
        "model_order = [lbl for lbl in [\"Baseline\", \"Gated Fusion\", \"Sentinel\"] if lbl in df[\"model\"].unique()]\n",
        "if not model_order:\n",
        "    model_order = sorted(df[\"model\"].unique())\n",
        "cat_order = [\"Structural\", \"Semantic/Cue\", \"Feature-Targeted\", \"Uncategorized\"]\n",
        "\n",
        "df[\"model\"] = pd.Categorical(df[\"model\"], categories=model_order, ordered=True)\n",
        "df[\"category\"] = pd.Categorical(df[\"category\"], categories=cat_order, ordered=True)\n",
        "df = df.sort_values([\"model\", \"category\", \"attack\"]).reset_index(drop=True)\n",
        "\n",
        "# --- show per-attack table (rounded)\n",
        "per_attack_cols = [\"model\", \"category\", \"attack\", \"clean_macro_f1\", \"attacked_macro_f1\", \"delta_macro_f1\", \"ASR\"]\n",
        "per_attack_df = df[per_attack_cols].copy()\n",
        "per_attack_df[[\"clean_macro_f1\",\"attacked_macro_f1\",\"delta_macro_f1\",\"ASR\"]] = \\\n",
        "    per_attack_df[[\"clean_macro_f1\",\"attacked_macro_f1\",\"delta_macro_f1\",\"ASR\"]].round(4)\n",
        "\n",
        "print(\"=== Per-attack metrics (Clean vs Attacked, ΔF1, ASR) ===\")\n",
        "display(per_attack_df)\n",
        "\n",
        "# --- grouped summary: mean across attacks per (model, category)\n",
        "grouped = (\n",
        "    df.groupby([\"model\",\"category\"], as_index=False)\n",
        "      .agg(\n",
        "          mean_clean_macro_f1 = (\"clean_macro_f1\", \"mean\"),\n",
        "          mean_attacked_macro_f1 = (\"attacked_macro_f1\", \"mean\"),\n",
        "          mean_delta_macro_f1 = (\"delta_macro_f1\", \"mean\"),\n",
        "          mean_ASR = (\"ASR\", \"mean\"),\n",
        "          n_attacks = (\"attack\", \"nunique\")\n",
        "      )\n",
        ")\n",
        "for c in [\"mean_clean_macro_f1\",\"mean_attacked_macro_f1\",\"mean_delta_macro_f1\",\"mean_ASR\"]:\n",
        "    grouped[c] = grouped[c].round(4)\n",
        "\n",
        "grouped = grouped.sort_values([\"model\",\"category\"])\n",
        "print(\"\\n=== Grouped summary (means over attacks) by Model × Category ===\")\n",
        "display(grouped)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "FsmaOncdsCwc",
        "outputId": "9bf4b2f7-f9e1-498e-9d5b-ace26688e779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Per-attack metrics (Clean vs Attacked, ΔF1, ASR) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           model          category                attack  clean_macro_f1  \\\n",
              "0       Baseline        Structural       structural_case          0.7753   \n",
              "1       Baseline        Structural     structural_insert          0.7753   \n",
              "2       Baseline        Structural       structural_typo          0.7753   \n",
              "3       Baseline      Semantic/Cue        semantic_coded          0.7753   \n",
              "4       Baseline      Semantic/Cue      semantic_synonym          0.7753   \n",
              "5       Baseline  Feature-Targeted  feature_slur_removal          0.7753   \n",
              "6   Gated Fusion        Structural       structural_case          0.3040   \n",
              "7   Gated Fusion        Structural     structural_insert          0.3040   \n",
              "8   Gated Fusion        Structural       structural_typo          0.3040   \n",
              "9   Gated Fusion      Semantic/Cue        semantic_coded          0.3040   \n",
              "10  Gated Fusion      Semantic/Cue      semantic_synonym          0.3040   \n",
              "11  Gated Fusion  Feature-Targeted  feature_slur_removal          0.3040   \n",
              "12      Sentinel        Structural       structural_case          0.7777   \n",
              "13      Sentinel        Structural     structural_insert          0.7777   \n",
              "14      Sentinel        Structural       structural_typo          0.7777   \n",
              "15      Sentinel      Semantic/Cue        semantic_coded          0.7777   \n",
              "16      Sentinel      Semantic/Cue      semantic_synonym          0.7777   \n",
              "17      Sentinel  Feature-Targeted  feature_slur_removal          0.7777   \n",
              "\n",
              "    attacked_macro_f1  delta_macro_f1     ASR  \n",
              "0              0.5579         -0.2174  0.4644  \n",
              "1              0.5333         -0.2420  0.5129  \n",
              "2              0.5525         -0.2228  0.4752  \n",
              "3              0.7625         -0.0128  0.0280  \n",
              "4              0.7541         -0.0212  0.0463  \n",
              "5              0.7419         -0.0335  0.0733  \n",
              "6              0.2918         -0.0123  0.5909  \n",
              "7              0.2946         -0.0094  0.4545  \n",
              "8              0.2937         -0.0104  0.5000  \n",
              "9              0.3031         -0.0009  0.0455  \n",
              "10             0.2946         -0.0094  0.4545  \n",
              "11             0.3040          0.0000  0.0000  \n",
              "12             0.6816         -0.0961  0.2070  \n",
              "13             0.6095         -0.1682  0.3590  \n",
              "14             0.6074         -0.1702  0.3633  \n",
              "15             0.7619         -0.0157  0.0338  \n",
              "16             0.7619         -0.0157  0.0338  \n",
              "17             0.7457         -0.0319  0.0686  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17506f76-778c-46b0-8dc2-d01b6dedf92c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>category</th>\n",
              "      <th>attack</th>\n",
              "      <th>clean_macro_f1</th>\n",
              "      <th>attacked_macro_f1</th>\n",
              "      <th>delta_macro_f1</th>\n",
              "      <th>ASR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>Structural</td>\n",
              "      <td>structural_case</td>\n",
              "      <td>0.7753</td>\n",
              "      <td>0.5579</td>\n",
              "      <td>-0.2174</td>\n",
              "      <td>0.4644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>Structural</td>\n",
              "      <td>structural_insert</td>\n",
              "      <td>0.7753</td>\n",
              "      <td>0.5333</td>\n",
              "      <td>-0.2420</td>\n",
              "      <td>0.5129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>Structural</td>\n",
              "      <td>structural_typo</td>\n",
              "      <td>0.7753</td>\n",
              "      <td>0.5525</td>\n",
              "      <td>-0.2228</td>\n",
              "      <td>0.4752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>Semantic/Cue</td>\n",
              "      <td>semantic_coded</td>\n",
              "      <td>0.7753</td>\n",
              "      <td>0.7625</td>\n",
              "      <td>-0.0128</td>\n",
              "      <td>0.0280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>Semantic/Cue</td>\n",
              "      <td>semantic_synonym</td>\n",
              "      <td>0.7753</td>\n",
              "      <td>0.7541</td>\n",
              "      <td>-0.0212</td>\n",
              "      <td>0.0463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>Feature-Targeted</td>\n",
              "      <td>feature_slur_removal</td>\n",
              "      <td>0.7753</td>\n",
              "      <td>0.7419</td>\n",
              "      <td>-0.0335</td>\n",
              "      <td>0.0733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gated Fusion</td>\n",
              "      <td>Structural</td>\n",
              "      <td>structural_case</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.2918</td>\n",
              "      <td>-0.0123</td>\n",
              "      <td>0.5909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Gated Fusion</td>\n",
              "      <td>Structural</td>\n",
              "      <td>structural_insert</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.2946</td>\n",
              "      <td>-0.0094</td>\n",
              "      <td>0.4545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Gated Fusion</td>\n",
              "      <td>Structural</td>\n",
              "      <td>structural_typo</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.2937</td>\n",
              "      <td>-0.0104</td>\n",
              "      <td>0.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Gated Fusion</td>\n",
              "      <td>Semantic/Cue</td>\n",
              "      <td>semantic_coded</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.3031</td>\n",
              "      <td>-0.0009</td>\n",
              "      <td>0.0455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Gated Fusion</td>\n",
              "      <td>Semantic/Cue</td>\n",
              "      <td>semantic_synonym</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.2946</td>\n",
              "      <td>-0.0094</td>\n",
              "      <td>0.4545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Gated Fusion</td>\n",
              "      <td>Feature-Targeted</td>\n",
              "      <td>feature_slur_removal</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Sentinel</td>\n",
              "      <td>Structural</td>\n",
              "      <td>structural_case</td>\n",
              "      <td>0.7777</td>\n",
              "      <td>0.6816</td>\n",
              "      <td>-0.0961</td>\n",
              "      <td>0.2070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Sentinel</td>\n",
              "      <td>Structural</td>\n",
              "      <td>structural_insert</td>\n",
              "      <td>0.7777</td>\n",
              "      <td>0.6095</td>\n",
              "      <td>-0.1682</td>\n",
              "      <td>0.3590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Sentinel</td>\n",
              "      <td>Structural</td>\n",
              "      <td>structural_typo</td>\n",
              "      <td>0.7777</td>\n",
              "      <td>0.6074</td>\n",
              "      <td>-0.1702</td>\n",
              "      <td>0.3633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Sentinel</td>\n",
              "      <td>Semantic/Cue</td>\n",
              "      <td>semantic_coded</td>\n",
              "      <td>0.7777</td>\n",
              "      <td>0.7619</td>\n",
              "      <td>-0.0157</td>\n",
              "      <td>0.0338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Sentinel</td>\n",
              "      <td>Semantic/Cue</td>\n",
              "      <td>semantic_synonym</td>\n",
              "      <td>0.7777</td>\n",
              "      <td>0.7619</td>\n",
              "      <td>-0.0157</td>\n",
              "      <td>0.0338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Sentinel</td>\n",
              "      <td>Feature-Targeted</td>\n",
              "      <td>feature_slur_removal</td>\n",
              "      <td>0.7777</td>\n",
              "      <td>0.7457</td>\n",
              "      <td>-0.0319</td>\n",
              "      <td>0.0686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17506f76-778c-46b0-8dc2-d01b6dedf92c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17506f76-778c-46b0-8dc2-d01b6dedf92c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17506f76-778c-46b0-8dc2-d01b6dedf92c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6c1dcde8-b905-402e-af19-20fbd80ee35a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c1dcde8-b905-402e-af19-20fbd80ee35a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6c1dcde8-b905-402e-af19-20fbd80ee35a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_81977dea-ae79-427e-a589-ab017a9cbced\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('per_attack_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_81977dea-ae79-427e-a589-ab017a9cbced button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('per_attack_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "per_attack_df",
              "summary": "{\n  \"name\": \"per_attack_df\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Baseline\",\n          \"Gated Fusion\",\n          \"Sentinel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Structural\",\n          \"Semantic/Cue\",\n          \"Feature-Targeted\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attack\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"structural_case\",\n          \"structural_insert\",\n          \"feature_slur_removal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22919838311717958,\n        \"min\": 0.304,\n        \"max\": 0.7777,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7753,\n          0.304,\n          0.7777\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attacked_macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19709722294877127,\n        \"min\": 0.2918,\n        \"max\": 0.7625,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.5579,\n          0.5333,\n          0.7419\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta_macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0885200285670782,\n        \"min\": -0.242,\n        \"max\": 0.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          -0.2174,\n          -0.242,\n          -0.0335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21760153696352627,\n        \"min\": 0.0,\n        \"max\": 0.5909,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.4644,\n          0.5129,\n          0.0733\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-758183081.py:117: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  df.groupby([\"model\",\"category\"], as_index=False)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length of values (9) does not match length of index (12)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-758183081.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m grouped = (\n\u001b[1;32m    117\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m       .agg(\n\u001b[0m\u001b[1;32m    119\u001b[0m           \u001b[0mmean_clean_macro_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"clean_macro_f1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m           \u001b[0mmean_attacked_macro_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"attacked_macro_f1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_inaxis_grouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_insert_inaxis_grouper\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0min_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m                     msg = (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5169\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5171\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5266\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5267\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5268\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \"\"\"\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (9) does not match length of index (12)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FIXED grouped summary (robust to pandas versions) ---\n",
        "# Recompute from `df` you already built\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure numeric dtypes\n",
        "for c in [\"clean_macro_f1\",\"attacked_macro_f1\",\"delta_macro_f1\",\"ASR\"]:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "grouped = (\n",
        "    df.groupby([\"model\",\"category\"], observed=False)\n",
        "      .agg({\n",
        "          \"clean_macro_f1\": \"mean\",\n",
        "          \"attacked_macro_f1\": \"mean\",\n",
        "          \"delta_macro_f1\": \"mean\",\n",
        "          \"ASR\": \"mean\",\n",
        "          \"attack\": \"nunique\"\n",
        "      })\n",
        "      .rename(columns={\n",
        "          \"clean_macro_f1\": \"mean_clean_macro_f1\",\n",
        "          \"attacked_macro_f1\": \"mean_attacked_macro_f1\",\n",
        "          \"delta_macro_f1\": \"mean_delta_macro_f1\",\n",
        "          \"ASR\": \"mean_ASR\",\n",
        "          \"attack\": \"n_attacks\"\n",
        "      })\n",
        "      .reset_index()\n",
        "      .sort_values([\"model\",\"category\"])\n",
        ")\n",
        "\n",
        "# Round for display\n",
        "for c in [\"mean_clean_macro_f1\",\"mean_attacked_macro_f1\",\"mean_delta_macro_f1\",\"mean_ASR\"]:\n",
        "    grouped[c] = grouped[c].round(4)\n",
        "\n",
        "print(\"\\n=== Grouped summary (means over attacks) by Model × Category ===\")\n",
        "display(grouped)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "collapsed": true,
        "id": "8yE8CFsqsvu1",
        "outputId": "0912226f-d2cf-4c8e-a729-426d51f546cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Grouped summary (means over attacks) by Model × Category ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           model          category  mean_clean_macro_f1  \\\n",
              "0       Baseline        Structural               0.7753   \n",
              "1       Baseline      Semantic/Cue               0.7753   \n",
              "2       Baseline  Feature-Targeted               0.7753   \n",
              "3       Baseline     Uncategorized                  NaN   \n",
              "4   Gated Fusion        Structural               0.3040   \n",
              "5   Gated Fusion      Semantic/Cue               0.3040   \n",
              "6   Gated Fusion  Feature-Targeted               0.3040   \n",
              "7   Gated Fusion     Uncategorized                  NaN   \n",
              "8       Sentinel        Structural               0.7777   \n",
              "9       Sentinel      Semantic/Cue               0.7777   \n",
              "10      Sentinel  Feature-Targeted               0.7777   \n",
              "11      Sentinel     Uncategorized                  NaN   \n",
              "\n",
              "    mean_attacked_macro_f1  mean_delta_macro_f1  mean_ASR  n_attacks  \n",
              "0                   0.5479              -0.2274    0.4842          3  \n",
              "1                   0.7583              -0.0170    0.0372          2  \n",
              "2                   0.7419              -0.0335    0.0733          1  \n",
              "3                      NaN                  NaN       NaN          0  \n",
              "4                   0.2934              -0.0107    0.5152          3  \n",
              "5                   0.2989              -0.0052    0.2500          2  \n",
              "6                   0.3040               0.0000    0.0000          1  \n",
              "7                      NaN                  NaN       NaN          0  \n",
              "8                   0.6328              -0.1448    0.3098          3  \n",
              "9                   0.7619              -0.0157    0.0338          2  \n",
              "10                  0.7457              -0.0319    0.0686          1  \n",
              "11                     NaN                  NaN       NaN          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e9deca6-4f98-4835-bb8e-b84097d72add\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>category</th>\n",
              "      <th>mean_clean_macro_f1</th>\n",
              "      <th>mean_attacked_macro_f1</th>\n",
              "      <th>mean_delta_macro_f1</th>\n",
              "      <th>mean_ASR</th>\n",
              "      <th>n_attacks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>Structural</td>\n",
              "      <td>0.7753</td>\n",
              "      <td>0.5479</td>\n",
              "      <td>-0.2274</td>\n",
              "      <td>0.4842</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>Semantic/Cue</td>\n",
              "      <td>0.7753</td>\n",
              "      <td>0.7583</td>\n",
              "      <td>-0.0170</td>\n",
              "      <td>0.0372</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>Feature-Targeted</td>\n",
              "      <td>0.7753</td>\n",
              "      <td>0.7419</td>\n",
              "      <td>-0.0335</td>\n",
              "      <td>0.0733</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>Uncategorized</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gated Fusion</td>\n",
              "      <td>Structural</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.2934</td>\n",
              "      <td>-0.0107</td>\n",
              "      <td>0.5152</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Gated Fusion</td>\n",
              "      <td>Semantic/Cue</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.2989</td>\n",
              "      <td>-0.0052</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gated Fusion</td>\n",
              "      <td>Feature-Targeted</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Gated Fusion</td>\n",
              "      <td>Uncategorized</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sentinel</td>\n",
              "      <td>Structural</td>\n",
              "      <td>0.7777</td>\n",
              "      <td>0.6328</td>\n",
              "      <td>-0.1448</td>\n",
              "      <td>0.3098</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sentinel</td>\n",
              "      <td>Semantic/Cue</td>\n",
              "      <td>0.7777</td>\n",
              "      <td>0.7619</td>\n",
              "      <td>-0.0157</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Sentinel</td>\n",
              "      <td>Feature-Targeted</td>\n",
              "      <td>0.7777</td>\n",
              "      <td>0.7457</td>\n",
              "      <td>-0.0319</td>\n",
              "      <td>0.0686</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Sentinel</td>\n",
              "      <td>Uncategorized</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e9deca6-4f98-4835-bb8e-b84097d72add')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e9deca6-4f98-4835-bb8e-b84097d72add button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e9deca6-4f98-4835-bb8e-b84097d72add');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-144c282a-3c64-497d-a0d8-d8188190e89c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-144c282a-3c64-497d-a0d8-d8188190e89c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-144c282a-3c64-497d-a0d8-d8188190e89c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_82a047ea-cc71-4329-a330-a52752ad0078\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('grouped')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_82a047ea-cc71-4329-a330-a52752ad0078 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('grouped');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "grouped",
              "summary": "{\n  \"name\": \"grouped\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Baseline\",\n          \"Gated Fusion\",\n          \"Sentinel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Semantic/Cue\",\n          \"Uncategorized\",\n          \"Structural\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_clean_macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23625228570322868,\n        \"min\": 0.304,\n        \"max\": 0.7777,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7753,\n          0.304,\n          0.7777\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_attacked_macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21144343674951097,\n        \"min\": 0.2934,\n        \"max\": 0.7619,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.7619,\n          0.7583,\n          0.304\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_delta_macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07844510465570458,\n        \"min\": -0.2274,\n        \"max\": 0.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          -0.0157,\n          -0.017,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_ASR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2006350418047655,\n        \"min\": 0.0,\n        \"max\": 0.5152,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.0338,\n          0.0372,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_attacks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# HateEval labeled evaluation (3 models): Baseline, Gated, Sentinel\n",
        "# Saves predictions + metrics; prints tidy DataFrames\n",
        "# ================================\n",
        "!pip -q install transformers datasets pandas scikit-learn\n",
        "\n",
        "import os, re, math, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import List, Dict, Any\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support,\n",
        "    classification_report, roc_auc_score, confusion_matrix\n",
        ")\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification,\n",
        "    PretrainedConfig, PreTrainedModel, TrainingArguments, Trainer\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -------- Paths (edit if different) --------\n",
        "BASE = \"/content/drive/MyDrive/hate\"\n",
        "TEST_CSV = f\"{BASE}/hateEval_test.csv\"     # must have: id,text,label (label in {0,1})\n",
        "CKPT_BASELINE = f\"{BASE}/models/step1_bert_baseline\"\n",
        "CKPT_GATED    = f\"{BASE}/models/step1_gated_fusion\"\n",
        "CKPT_SENTINEL = f\"{BASE}/models/sentinel_xlmr\"\n",
        "OUT_DIR       = f\"{BASE}/predictions\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# -------- Load HateEval test ----------\n",
        "df = pd.read_csv(TEST_CSV)\n",
        "assert {\"id\",\"text\",\"label\"}.issubset(df.columns), \"hateEval_test.csv must have columns: id,text,label\"\n",
        "# Coerce labels to {0,1}\n",
        "if df[\"label\"].dtype != int and df[\"label\"].dtype != np.int64:\n",
        "    df[\"label\"] = df[\"label\"].astype(str).str.strip().map({\"0\":0,\"1\":1,\"non-hate\":0,\"hate\":1}).astype(int)\n",
        "\n",
        "texts = df[\"text\"].astype(str).tolist()\n",
        "ids   = df[\"id\"].tolist()\n",
        "y_true = df[\"label\"].astype(int).values\n",
        "\n",
        "# =======================\n",
        "# Gated-fusion definition\n",
        "# =======================\n",
        "class GFConfig(PretrainedConfig):\n",
        "    model_type = \"gated_fusion_wrapper\"\n",
        "    def __init__(self, base_model_name=\"bert-base-multilingual-cased\", num_labels=2, gate_hidden=256, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.base_model_name = base_model_name\n",
        "        self.num_labels = num_labels\n",
        "        self.gate_hidden = gate_hidden\n",
        "\n",
        "class GatedFusionForSequenceClassification(PreTrainedModel):\n",
        "    config_class = GFConfig\n",
        "    def __init__(self, config: GFConfig):\n",
        "        super().__init__(config)\n",
        "        self.base_cfg = AutoConfig.from_pretrained(config.base_model_name)\n",
        "        self.encoder = AutoModel.from_pretrained(config.base_model_name, config=self.base_cfg)\n",
        "        hidden = self.base_cfg.hidden_size\n",
        "        self.gate_mlp = nn.Sequential(\n",
        "            nn.Linear(2 * hidden, config.gate_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.gate_hidden, hidden),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.dropout = nn.Dropout(getattr(self.base_cfg, \"hidden_dropout_prob\", 0.1))\n",
        "        self.classifier = nn.Linear(hidden, config.num_labels)\n",
        "        self.post_init()\n",
        "\n",
        "    @staticmethod\n",
        "    def masked_mean(last_hidden_state, attention_mask):\n",
        "        mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n",
        "        summed = (last_hidden_state * mask).sum(dim=1)\n",
        "        denom = mask.sum(dim=1).clamp(min=1e-6)\n",
        "        return summed / denom\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
        "        allowed = {\"position_ids\",\"head_mask\",\"inputs_embeds\",\"output_attentions\",\n",
        "                   \"output_hidden_states\",\"return_dict\",\"past_key_values\",\n",
        "                   \"encoder_hidden_states\",\"encoder_attention_mask\"}\n",
        "        safe_kwargs = {k:v for k,v in kwargs.items() if k in allowed}\n",
        "        safe_kwargs.pop(\"num_items_in_batch\", None)\n",
        "\n",
        "        enc = self.encoder(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **safe_kwargs)\n",
        "        h_cls = enc.last_hidden_state[:, 0, :]\n",
        "        h_mean = self.masked_mean(enc.last_hidden_state, attention_mask)\n",
        "        g = self.gate_mlp(torch.cat([h_cls, h_mean], dim=-1))\n",
        "        fused = g * h_cls + (1.0 - g) * h_mean\n",
        "        logits = self.classifier(self.dropout(fused))\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.CrossEntropyLoss()(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "# ===================\n",
        "# Sentinel definition\n",
        "# ===================\n",
        "SLUR_REGEXES = [\n",
        "    r\"\\bmongol(s)?\\b\", r\"\\bretard(s|ed)?\\b\", r\"\\btolol\\b\", r\"\\bkontol\\b\",\n",
        "    r\"\\bbajingan\\b\", r\"\\bbabi\\b\", r\"\\bbhen ?chod\\b\", r\"\\bmadar ?chod\\b\",\n",
        "    r\"\\brandi\\b\", r\"\\bperra\\b\", r\"\\bzorra\\b\", r\"\\bputa\\b\"\n",
        "]\n",
        "SLUR_PATTERNS = [re.compile(p, re.IGNORECASE) for p in SLUR_REGEXES]\n",
        "\n",
        "def build_heuristic_features(text: str, H=32) -> np.ndarray:\n",
        "    length = len(text)\n",
        "    words  = text.split()\n",
        "    n_words = max(1, len(words))\n",
        "    upper = sum(1 for c in text if c.isalpha() and c.isupper())\n",
        "    digits = sum(1 for c in text if c.isdigit())\n",
        "    punct = sum(1 for c in text if c in \".,;:!?\")\n",
        "    upper_ratio = upper / max(1, sum(c.isalpha() for c in text))\n",
        "    digit_ratio = digits / max(1, len(text))\n",
        "    punct_ratio = punct / max(1, len(text))\n",
        "    slur_hits = sum(len(pat.findall(text)) for pat in SLUR_PATTERNS)\n",
        "    slur_density = slur_hits / n_words\n",
        "    cues = sum(text.lower().count(k) for k in [\"kill\",\"die\",\"trash\",\"dirty\",\"dog\",\"pig\",\"scum\",\"hate\"])\n",
        "    cue_density = cues / n_words\n",
        "    base_feats = np.array([\n",
        "        length, n_words, upper, digits, punct,\n",
        "        upper_ratio, digit_ratio, punct_ratio,\n",
        "        slur_hits, slur_density, cues, cue_density\n",
        "    ], dtype=np.float32)\n",
        "    base_feats[0] = math.log1p(base_feats[0])\n",
        "    base_feats[1] = math.log1p(base_feats[1])\n",
        "    if base_feats.shape[0] < H:\n",
        "        pad = np.zeros(H - base_feats.shape[0], dtype=np.float32)\n",
        "        feats = np.concatenate([base_feats, pad])\n",
        "    else:\n",
        "        feats = base_feats[:H]\n",
        "    return feats\n",
        "\n",
        "class SentinelConfig(PretrainedConfig):\n",
        "    model_type = \"sentinel_fusion\"\n",
        "    def __init__(self,\n",
        "        base_model_name=\"xlm-roberta-base\",\n",
        "        num_labels=2,\n",
        "        heuristic_dim=32,\n",
        "        heuristic_hidden=256,\n",
        "        causal_hidden=256,\n",
        "        attn_heads=8,\n",
        "        aux_causal_loss_weight=0.0,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.base_model_name = base_model_name\n",
        "        self.num_labels = num_labels\n",
        "        self.heuristic_dim = heuristic_dim\n",
        "        self.heuristic_hidden = heuristic_hidden\n",
        "        self.causal_hidden = causal_hidden\n",
        "        self.attn_heads = attn_heads\n",
        "        self.aux_causal_loss_weight = aux_causal_loss_weight\n",
        "\n",
        "class SentinelModel(PreTrainedModel):\n",
        "    config_class = SentinelConfig\n",
        "    def __init__(self, config: SentinelConfig):\n",
        "        super().__init__(config)\n",
        "        self.base_cfg = AutoConfig.from_pretrained(config.base_model_name)\n",
        "        self.encoder = AutoModel.from_pretrained(config.base_model_name, config=self.base_cfg)\n",
        "        hidden = self.base_cfg.hidden_size\n",
        "\n",
        "        self.heuristic_proj = nn.Sequential(\n",
        "            nn.Linear(config.heuristic_dim, config.heuristic_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.heuristic_hidden, hidden),\n",
        "            nn.LayerNorm(hidden)\n",
        "        )\n",
        "        self.causal_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden, config.causal_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.causal_hidden, hidden),\n",
        "            nn.LayerNorm(hidden)\n",
        "        )\n",
        "        self.xattn = nn.MultiheadAttention(embed_dim=hidden, num_heads=config.attn_heads, batch_first=True)\n",
        "        self.dropout = nn.Dropout(getattr(self.base_cfg, \"hidden_dropout_prob\", 0.1))\n",
        "        self.classifier = nn.Linear(hidden, config.num_labels)\n",
        "        self.post_init()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, heuristic_feats=None, labels=None, **kwargs):\n",
        "        enc = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden = enc.last_hidden_state\n",
        "        h_cls = last_hidden[:, 0, :]\n",
        "        h_heu = self.heuristic_proj(heuristic_feats)\n",
        "        h_cau = self.causal_mlp(h_cls)\n",
        "        Q = h_cls.unsqueeze(1)\n",
        "        KV = torch.stack([h_heu, h_cau], dim=1)\n",
        "        fused, _ = self.xattn(Q, KV, KV)\n",
        "        fused = fused.squeeze(1)\n",
        "        logits = self.classifier(self.dropout(fused))\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "# -------------------------\n",
        "# Helper: softmax to probs\n",
        "# -------------------------\n",
        "def to_probs(logits: np.ndarray) -> np.ndarray:\n",
        "    e = np.exp(logits - logits.max(axis=1, keepdims=True))\n",
        "    return e / e.sum(axis=1, keepdims=True)\n",
        "\n",
        "# ----------------------------------\n",
        "# Predictors for each model family\n",
        "# ----------------------------------\n",
        "def predict_probs_baseline(checkpoint_dir: str, texts: List[str], max_length=128) -> np.ndarray:\n",
        "    tok = AutoTokenizer.from_pretrained(checkpoint_dir if os.path.isdir(checkpoint_dir) else \"bert-base-multilingual-cased\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(checkpoint_dir).to(device).eval()\n",
        "    enc = tok(texts, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "    ds = Dataset.from_dict({k: enc[k].tolist() for k in enc})\n",
        "    ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\"])\n",
        "    args = TrainingArguments(output_dir=\"./tmp_eval\", per_device_eval_batch_size=64, report_to=\"none\", logging_strategy=\"no\", disable_tqdm=False)\n",
        "    trainer = Trainer(model=model, args=args, tokenizer=tok)\n",
        "    with torch.no_grad():\n",
        "        out = trainer.predict(ds)\n",
        "    return to_probs(out.predictions)\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
        "from transformers import PretrainedConfig, PreTrainedModel\n",
        "\n",
        "# --- keep your GFConfig and GatedFusionForSequenceClassification definitions as-is ---\n",
        "\n",
        "def _softmax_np(logits: np.ndarray) -> np.ndarray:\n",
        "    e = np.exp(logits - logits.max(axis=1, keepdims=True))\n",
        "    return e / e.sum(axis=1, keepdims=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_probs_gated(checkpoint_dir: str, texts, max_length: int = 128, batch_size: int = 64) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Manual batched inference for the gated model to avoid Trainer/accelerate\n",
        "    touching a dict with loss=None.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    base_name = \"bert-base-multilingual-cased\"\n",
        "\n",
        "    # tokenizer\n",
        "    tok = AutoTokenizer.from_pretrained(checkpoint_dir if os.path.isdir(checkpoint_dir) else base_name)\n",
        "\n",
        "    # config + model\n",
        "    try:\n",
        "        cfg = GFConfig.from_pretrained(checkpoint_dir)\n",
        "    except Exception:\n",
        "        cfg = GFConfig(base_model_name=base_name, num_labels=2, gate_hidden=256)\n",
        "    model = GatedFusionForSequenceClassification(cfg)\n",
        "    state_path = os.path.join(checkpoint_dir, \"pytorch_model.bin\")\n",
        "    if os.path.isfile(state_path):\n",
        "        state = torch.load(state_path, map_location=device)\n",
        "        model.load_state_dict(state, strict=False)\n",
        "    model.to(device).eval()\n",
        "\n",
        "    # batched forward\n",
        "    probs_list = []\n",
        "    N = len(texts)\n",
        "    for i in range(0, N, batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        enc = tok(batch_texts, padding=\"max_length\", truncation=True,\n",
        "                  max_length=max_length, return_tensors=\"pt\")\n",
        "        enc = {k: v.to(device) for k, v in enc.items()}\n",
        "        out = model(**enc)\n",
        "        # out is a dict {\"loss\": None/..., \"logits\": tensor}\n",
        "        logits = out[\"logits\"].detach().cpu().numpy()\n",
        "        probs_list.append(_softmax_np(logits))\n",
        "    return np.vstack(probs_list)\n",
        "\n",
        "# ===== Optional: make Sentinel manual too (more robust and symmetric) =====\n",
        "\n",
        "# keep your SentinelConfig and SentinelModel definitions as-is\n",
        "def _build_heuristic_batch(texts, H=32):\n",
        "    arr = np.stack([build_heuristic_features(t, H=H) for t in texts]).astype(np.float32)\n",
        "    return torch.tensor(arr)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_probs_sentinel(checkpoint_dir: str, texts, max_length: int = 128, batch_size: int = 64) -> np.ndarray:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    base_name = \"xlm-roberta-base\"\n",
        "\n",
        "    tok = AutoTokenizer.from_pretrained(checkpoint_dir if os.path.isdir(checkpoint_dir) else base_name)\n",
        "    try:\n",
        "        scfg = SentinelConfig.from_pretrained(checkpoint_dir)\n",
        "    except Exception:\n",
        "        scfg = SentinelConfig(base_model_name=base_name, num_labels=2, heuristic_dim=32)\n",
        "\n",
        "    model = SentinelModel(scfg)\n",
        "    state_path = os.path.join(checkpoint_dir, \"pytorch_model.bin\")\n",
        "    if os.path.isfile(state_path):\n",
        "        state = torch.load(state_path, map_location=device)\n",
        "        model.load_state_dict(state, strict=False)\n",
        "    model.to(device).eval()\n",
        "\n",
        "    probs_list = []\n",
        "    N = len(texts)\n",
        "    for i in range(0, N, batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        enc = tok(batch_texts, padding=\"max_length\", truncation=True,\n",
        "                  max_length=max_length, return_tensors=\"pt\")\n",
        "        heur = _build_heuristic_batch(batch_texts, H=scfg.heuristic_dim)\n",
        "\n",
        "        enc = {k: v.to(device) for k, v in enc.items()}\n",
        "        enc[\"heuristic_feats\"] = heur.to(device)\n",
        "\n",
        "        out = model(**enc)\n",
        "        logits = out[\"logits\"].detach().cpu().numpy()\n",
        "        probs_list.append(_softmax_np(logits))\n",
        "    return np.vstack(probs_list)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Run predictions\n",
        "# -------------------------\n",
        "print(\"Scoring HateEval with Baseline...\")\n",
        "probs_base = predict_probs_baseline(CKPT_BASELINE, texts)\n",
        "print(\"Scoring HateEval with Gated Fusion...\")\n",
        "probs_gated = predict_probs_gated(CKPT_GATED, texts)\n",
        "print(\"Scoring HateEval with Sentinel...\")\n",
        "probs_sent = predict_probs_sentinel(CKPT_SENTINEL, texts)\n",
        "\n",
        "def save_preds(name, probs, y_true):\n",
        "    preds = probs.argmax(axis=1)\n",
        "    out = pd.DataFrame({\n",
        "        \"id\": ids,\n",
        "        \"text\": texts,\n",
        "        \"label\": y_true,\n",
        "        \"prob_nonhate\": probs[:,0],\n",
        "        \"prob_hate\": probs[:,1],\n",
        "        \"pred_label\": preds\n",
        "    })\n",
        "    path = os.path.join(OUT_DIR, f\"hateEval_{name}.csv\")\n",
        "    out.to_csv(path, index=False)\n",
        "    print(f\"Saved predictions: {path}\")\n",
        "    return preds, out\n",
        "\n",
        "pred_base , df_base  = save_preds(\"baseline\", probs_base, y_true)\n",
        "pred_gated, df_gated = save_preds(\"gated\",    probs_gated, y_true)\n",
        "pred_sent , df_sent  = save_preds(\"sentinel\", probs_sent, y_true)\n",
        "\n",
        "# -------------------------\n",
        "# Metrics + Reports\n",
        "# -------------------------\n",
        "def compute_all_metrics(name: str, y_true, probs):\n",
        "    y_pred = probs.argmax(axis=1)\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=\"macro\", zero_division=0\n",
        "    )\n",
        "\n",
        "    # per-class (labels assumed 0=non-hate, 1=hate)\n",
        "    p_c, r_c, f1_c, sup_c = precision_recall_fscore_support(\n",
        "        y_true, y_pred, labels=[0, 1], zero_division=0\n",
        "    )\n",
        "\n",
        "    # ROC-AUC for positive class (handle degenerate cases)\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, probs[:, 1])  # hate=1\n",
        "    except ValueError:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1]).tolist()\n",
        "\n",
        "    rep = {\n",
        "        \"model\": name,\n",
        "        \"accuracy\": float(acc),\n",
        "        \"precision_macro\": float(p_macro),\n",
        "        \"recall_macro\": float(r_macro),\n",
        "        \"f1_macro\": float(f1_macro),\n",
        "        \"auc_roc_hate1\": float(auc) if auc == auc else None,  # NaN -> None for JSON\n",
        "        \"per_class\": [\n",
        "            {\n",
        "                \"label\": 0,\n",
        "                \"precision\": float(p_c[0]),\n",
        "                \"recall\": float(r_c[0]),\n",
        "                \"f1\": float(f1_c[0]),\n",
        "                \"support\": int(sup_c[0]),\n",
        "            },\n",
        "            {\n",
        "                \"label\": 1,\n",
        "                \"precision\": float(p_c[1]),\n",
        "                \"recall\": float(r_c[1]),\n",
        "                \"f1\": float(f1_c[1]),\n",
        "                \"support\": int(sup_c[1]),\n",
        "            },\n",
        "        ],\n",
        "        \"confusion_matrix\": {\"labels\": [0, 1], \"matrix\": cm},\n",
        "    }\n",
        "    return rep\n",
        "\n",
        "rep_base  = compute_all_metrics(\"Baseline\",     y_true, probs_base)\n",
        "rep_gated = compute_all_metrics(\"Gated Fusion\", y_true, probs_gated)\n",
        "rep_sent  = compute_all_metrics(\"Sentinel\",     y_true, probs_sent)\n",
        "\n",
        "# Save JSON reports\n",
        "for rep, nm in [(rep_base, \"baseline\"), (rep_gated, \"gated\"), (rep_sent, \"sentinel\")]:\n",
        "    with open(os.path.join(OUT_DIR, f\"hateEval_metrics_{nm}.json\"), \"w\") as f:\n",
        "        json.dump(rep, f, indent=2)\n",
        "\n",
        "# Tidy summary table (fix: build rows in a simple loop)\n",
        "rows = []\n",
        "for r in (rep_base, rep_gated, rep_sent):\n",
        "    rows.append({k: v for k, v in r.items() if k not in (\"per_class\", \"confusion_matrix\")})\n",
        "summary = pd.DataFrame(rows)\n",
        "\n",
        "# Select and order common columns if present\n",
        "ordered_cols = [\"model\", \"accuracy\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"auc_roc_hate1\"]\n",
        "summary = summary[ordered_cols]\n",
        "\n",
        "# Round numeric columns\n",
        "summary_rounded = summary.copy()\n",
        "for col in ordered_cols:\n",
        "    if col != \"model\":\n",
        "        summary_rounded[col] = summary_rounded[col].apply(lambda x: None if x is None else round(float(x), 4))\n",
        "\n",
        "# Per-class tidy\n",
        "def per_class_rows(rep):\n",
        "    return [\n",
        "        {\n",
        "            \"model\": rep[\"model\"],\n",
        "            \"label\": d[\"label\"],\n",
        "            \"precision\": float(d[\"precision\"]),\n",
        "            \"recall\": float(d[\"recall\"]),\n",
        "            \"f1\": float(d[\"f1\"]),\n",
        "            \"support\": int(d[\"support\"]),\n",
        "        }\n",
        "        for d in rep[\"per_class\"]\n",
        "    ]\n",
        "\n",
        "per_class_df = pd.DataFrame(per_class_rows(rep_base) + per_class_rows(rep_gated) + per_class_rows(rep_sent))\n",
        "per_class_df_rounded = per_class_df.copy()\n",
        "for c in [\"precision\", \"recall\", \"f1\"]:\n",
        "    per_class_df_rounded[c] = per_class_df_rounded[c].map(lambda x: round(float(x), 4))\n",
        "\n",
        "# Save CSVs\n",
        "summary_rounded.to_csv(os.path.join(OUT_DIR, \"hateEval_summary_metrics.csv\"), index=False)\n",
        "per_class_df_rounded.to_csv(os.path.join(OUT_DIR, \"hateEval_per_class_metrics.csv\"), index=False)\n",
        "\n",
        "# -------- Pretty print to notebook --------\n",
        "print(\"\\n=== HateEval: Summary Metrics ===\")\n",
        "print(summary_rounded.to_string(index=False))\n",
        "\n",
        "print(\"\\n=== HateEval: Per-Class Metrics ===\")\n",
        "print(per_class_df_rounded.sort_values([\"label\", \"model\"]).to_string(index=False))\n",
        "\n",
        "print(f\"\\nArtifacts saved under: {OUT_DIR}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "vmoPGePM1O7A",
        "outputId": "2bc8d15d-2ddf-48ea-d0f6-5175e484ff43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring HateEval with Baseline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2272579494.py:215: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(model=model, args=args, tokenizer=tok)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring HateEval with Gated Fusion...\n",
            "Scoring HateEval with Sentinel...\n",
            "Saved predictions: /content/drive/MyDrive/hate/predictions/hateEval_baseline.csv\n",
            "Saved predictions: /content/drive/MyDrive/hate/predictions/hateEval_gated.csv\n",
            "Saved predictions: /content/drive/MyDrive/hate/predictions/hateEval_sentinel.csv\n",
            "\n",
            "=== HateEval: Summary Metrics ===\n",
            "       model  accuracy  precision_macro  recall_macro  f1_macro  auc_roc_hate1\n",
            "    Baseline    0.6356           0.6487        0.5853    0.5615         0.6634\n",
            "Gated Fusion    0.5771           0.5324        0.5068    0.4159         0.5401\n",
            "    Sentinel    0.3917           0.4007        0.4422    0.3512         0.4493\n",
            "\n",
            "=== HateEval: Per-Class Metrics ===\n",
            "       model  label  precision  recall     f1  support\n",
            "    Baseline      0     0.6290  0.9038 0.7417     5790\n",
            "Gated Fusion      0     0.5825  0.9520 0.7227     5790\n",
            "    Sentinel      0     0.4144  0.1225 0.1890     5790\n",
            "    Baseline      1     0.6685  0.2667 0.3813     4210\n",
            "Gated Fusion      1     0.4823  0.0615 0.1091     4210\n",
            "    Sentinel      1     0.3870  0.7620 0.5133     4210\n",
            "\n",
            "Artifacts saved under: /content/drive/MyDrive/hate/predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Dataset composition summary for HateXplain (train/val/test) and HateEval\n",
        "import os\n",
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "\n",
        "# ----- paths (edit if yours differ) -----\n",
        "DRIVE = \"/content/drive/MyDrive/hate\"\n",
        "PATHS = OrderedDict({\n",
        "    \"HateXplain\": {\n",
        "        \"train\": os.path.join(DRIVE, \"train.csv\"),\n",
        "        \"validation\": os.path.join(DRIVE, \"val.csv\"),\n",
        "        \"test\": os.path.join(DRIVE, \"test.csv\"),\n",
        "    },\n",
        "    # We’ll try hateEval_test.csv first; fallback to hateEval.csv if that’s what you saved.\n",
        "    \"HateEval\": {\n",
        "        \"test\": os.path.join(DRIVE, \"hateEval_test.csv\") if os.path.exists(os.path.join(DRIVE, \"hateEval_test.csv\"))\n",
        "                else os.path.join(DRIVE, \"hateEval.csv\")\n",
        "    },\n",
        "})\n",
        "\n",
        "# ----- helpers -----\n",
        "POSSIBLE_LABEL_COLS = [\"label\", \"labels\", \"target\", \"class\", \"y\"]\n",
        "POSSIBLE_TEXT_COLS  = [\"text\", \"tweet\", \"content\", \"document\", \"sentence\"]\n",
        "\n",
        "def load_with_autocols(path):\n",
        "    \"\"\"Load CSV and auto-detect label/text columns; return (df, label_col, text_col).\"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    label_col = next((c for c in POSSIBLE_LABEL_COLS if c in df.columns), None)\n",
        "    text_col  = next((c for c in POSSIBLE_TEXT_COLS  if c in df.columns), None)\n",
        "    if label_col is None:\n",
        "        raise ValueError(f\"No label column found in {path}. \"\n",
        "                         f\"Expected one of {POSSIBLE_LABEL_COLS}, got {list(df.columns)}\")\n",
        "    if text_col is None:\n",
        "        raise ValueError(f\"No text column found in {path}. \"\n",
        "                         f\"Expected one of {POSSIBLE_TEXT_COLS}, got {list(df.columns)}\")\n",
        "    return df, label_col, text_col\n",
        "\n",
        "def summarize_split(df, label_col, dataset_name, split_name):\n",
        "    \"\"\"Return long-form and wide-form summaries for one split.\"\"\"\n",
        "    # Ensure labels are simple (0/1 or strings); don’t coerce to int to avoid crashing on strings.\n",
        "    counts = (\n",
        "        df.groupby(label_col, dropna=False)\n",
        "          .size()\n",
        "          .reset_index(name=\"count\")\n",
        "          .rename(columns={label_col: \"label\"})\n",
        "    )\n",
        "    counts[\"dataset\"] = dataset_name\n",
        "    counts[\"split\"]   = split_name\n",
        "    # Percent within split\n",
        "    total = counts[\"count\"].sum()\n",
        "    counts[\"percent\"] = counts[\"count\"] / max(total, 1) * 100.0\n",
        "\n",
        "    # Wide view: one row per split with columns for each label’s count\n",
        "    wide = counts.pivot_table(index=[\"dataset\", \"split\"], columns=\"label\", values=\"count\", fill_value=0)\n",
        "    wide = wide.reset_index()\n",
        "    wide.columns.name = None\n",
        "    wide[\"total\"] = wide.drop(columns=[\"dataset\", \"split\"]).sum(axis=1)\n",
        "\n",
        "    # If binary {0,1}, add class balance stats\n",
        "    if 0 in counts[\"label\"].unique().tolist() and 1 in counts[\"label\"].unique().tolist():\n",
        "        # Retrieve counts safely (may be missing in some splits)\n",
        "        def _get(w, col):\n",
        "            return w[col] if col in w else 0\n",
        "        wide[\"pos_frac_%\"] = wide.apply(lambda r: ( _get(r, 1) / r[\"total\"] * 100.0 ) if r[\"total\"] > 0 else 0.0, axis=1)\n",
        "        wide[\"neg_frac_%\"] = wide.apply(lambda r: ( _get(r, 0) / r[\"total\"] * 100.0 ) if r[\"total\"] > 0 else 0.0, axis=1)\n",
        "\n",
        "    # Sort label columns (nice ordering)\n",
        "    non_label_cols = [\"dataset\", \"split\", \"total\", \"pos_frac_%\", \"neg_frac_%\"]\n",
        "    non_label_cols = [c for c in non_label_cols if c in wide.columns]\n",
        "    label_cols = [c for c in wide.columns if c not in non_label_cols]\n",
        "    # Keep dataset/split first\n",
        "    wide = wide[[\"dataset\", \"split\"] + label_cols + [c for c in non_label_cols if c not in [\"dataset\",\"split\"]]]\n",
        "\n",
        "    return counts, wide\n",
        "\n",
        "# ----- build summaries -----\n",
        "all_long = []\n",
        "all_wide = []\n",
        "\n",
        "for ds_name, splits in PATHS.items():\n",
        "    for split_name, p in splits.items():\n",
        "        if not os.path.exists(p):\n",
        "            print(f\"[WARN] Missing file for {ds_name}/{split_name}: {p}\")\n",
        "            continue\n",
        "        df, label_col, text_col = load_with_autocols(p)\n",
        "        long_df, wide_df = summarize_split(df, label_col, ds_name, split_name)\n",
        "        all_long.append(long_df)\n",
        "        all_wide.append(wide_df)\n",
        "\n",
        "if not all_long:\n",
        "    raise RuntimeError(\"No datasets were found. Check PATHS.\")\n",
        "\n",
        "long_summary = pd.concat(all_long, ignore_index=True)\n",
        "wide_summary = pd.concat(all_wide, ignore_index=True)\n",
        "\n",
        "# Pretty sort\n",
        "long_summary = long_summary.sort_values([\"dataset\", \"split\", \"label\"]).reset_index(drop=True)\n",
        "wide_summary = wide_summary.sort_values([\"dataset\", \"split\"]).reset_index(drop=True)\n",
        "\n",
        "# Round percents\n",
        "if \"percent\" in long_summary.columns:\n",
        "    long_summary[\"percent\"] = long_summary[\"percent\"].map(lambda x: round(float(x), 2))\n",
        "for col in [\"pos_frac_%\", \"neg_frac_%\"]:\n",
        "    if col in wide_summary.columns:\n",
        "        wide_summary[col] = wide_summary[col].map(lambda x: round(float(x), 2))\n",
        "\n",
        "# ----- display -----\n",
        "print(\"\\n=== CLASS COMPOSITION (long-form: one row per label) ===\")\n",
        "display(long_summary)\n",
        "\n",
        "print(\"\\n=== SPLIT SUMMARY (wide-form: counts by label + totals) ===\")\n",
        "display(wide_summary)\n",
        "\n",
        "# ----- save to Drive for record -----\n",
        "out_dir = os.path.join(DRIVE, \"analysis\")\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "long_summary.to_csv(os.path.join(out_dir, \"dataset_composition_long.csv\"), index=False)\n",
        "wide_summary.to_csv(os.path.join(out_dir, \"dataset_composition_wide.csv\"), index=False)\n",
        "print(f\"\\nSaved CSVs to: {out_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "sgK7oHEifewj",
        "outputId": "6d36dbd7-bd07-4ef6-ccb0-c91381486826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CLASS COMPOSITION (long-form: one row per label) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   label  count     dataset       split  percent\n",
              "0      0   5790    HateEval        test    57.90\n",
              "1      1   4210    HateEval        test    42.10\n",
              "2      0    782  HateXplain        test    40.64\n",
              "3      1   1142  HateXplain        test    59.36\n",
              "4      0   6251  HateXplain       train    40.64\n",
              "5      1   9132  HateXplain       train    59.36\n",
              "6      0    781  HateXplain  validation    40.63\n",
              "7      1   1141  HateXplain  validation    59.37"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79d7a1e6-80e5-4173-837c-1d9d52558978\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>count</th>\n",
              "      <th>dataset</th>\n",
              "      <th>split</th>\n",
              "      <th>percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5790</td>\n",
              "      <td>HateEval</td>\n",
              "      <td>test</td>\n",
              "      <td>57.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4210</td>\n",
              "      <td>HateEval</td>\n",
              "      <td>test</td>\n",
              "      <td>42.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>782</td>\n",
              "      <td>HateXplain</td>\n",
              "      <td>test</td>\n",
              "      <td>40.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1142</td>\n",
              "      <td>HateXplain</td>\n",
              "      <td>test</td>\n",
              "      <td>59.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>6251</td>\n",
              "      <td>HateXplain</td>\n",
              "      <td>train</td>\n",
              "      <td>40.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>9132</td>\n",
              "      <td>HateXplain</td>\n",
              "      <td>train</td>\n",
              "      <td>59.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>781</td>\n",
              "      <td>HateXplain</td>\n",
              "      <td>validation</td>\n",
              "      <td>40.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1141</td>\n",
              "      <td>HateXplain</td>\n",
              "      <td>validation</td>\n",
              "      <td>59.37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79d7a1e6-80e5-4173-837c-1d9d52558978')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79d7a1e6-80e5-4173-837c-1d9d52558978 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79d7a1e6-80e5-4173-837c-1d9d52558978');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1d79d991-0333-4383-9b84-e10c2d8e4837\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1d79d991-0333-4383-9b84-e10c2d8e4837')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1d79d991-0333-4383-9b84-e10c2d8e4837 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5278caa2-48f0-481b-aeae-0b840fe9d61c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('long_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5278caa2-48f0-481b-aeae-0b840fe9d61c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('long_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "long_summary",
              "summary": "{\n  \"name\": \"long_summary\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3179,\n        \"min\": 781,\n        \"max\": 9132,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4210,\n          9132\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"HateXplain\",\n          \"HateEval\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"test\",\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"percent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.642555974132879,\n        \"min\": 40.63,\n        \"max\": 59.37,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          57.9,\n          42.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== SPLIT SUMMARY (wide-form: counts by label + totals) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      dataset       split       0       1    total  pos_frac_%  neg_frac_%\n",
              "0    HateEval        test  5790.0  4210.0  10000.0       42.10       57.90\n",
              "1  HateXplain        test   782.0  1142.0   1924.0       59.36       40.64\n",
              "2  HateXplain       train  6251.0  9132.0  15383.0       59.36       40.64\n",
              "3  HateXplain  validation   781.0  1141.0   1922.0       59.37       40.63"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4502de8b-6678-4a3f-9e15-e5bc7bdb8d28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>split</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>total</th>\n",
              "      <th>pos_frac_%</th>\n",
              "      <th>neg_frac_%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HateEval</td>\n",
              "      <td>test</td>\n",
              "      <td>5790.0</td>\n",
              "      <td>4210.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>42.10</td>\n",
              "      <td>57.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HateXplain</td>\n",
              "      <td>test</td>\n",
              "      <td>782.0</td>\n",
              "      <td>1142.0</td>\n",
              "      <td>1924.0</td>\n",
              "      <td>59.36</td>\n",
              "      <td>40.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HateXplain</td>\n",
              "      <td>train</td>\n",
              "      <td>6251.0</td>\n",
              "      <td>9132.0</td>\n",
              "      <td>15383.0</td>\n",
              "      <td>59.36</td>\n",
              "      <td>40.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HateXplain</td>\n",
              "      <td>validation</td>\n",
              "      <td>781.0</td>\n",
              "      <td>1141.0</td>\n",
              "      <td>1922.0</td>\n",
              "      <td>59.37</td>\n",
              "      <td>40.63</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4502de8b-6678-4a3f-9e15-e5bc7bdb8d28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4502de8b-6678-4a3f-9e15-e5bc7bdb8d28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4502de8b-6678-4a3f-9e15-e5bc7bdb8d28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-57620ec3-fa48-416e-82d6-d4a91f68fdea\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-57620ec3-fa48-416e-82d6-d4a91f68fdea')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-57620ec3-fa48-416e-82d6-d4a91f68fdea button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_701b0f94-63f9-40c3-879b-bc7f7113d78c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('wide_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_701b0f94-63f9-40c3-879b-bc7f7113d78c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('wide_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "wide_summary",
              "summary": "{\n  \"name\": \"wide_summary\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"HateXplain\",\n          \"HateEval\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"test\",\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3030.587511798111,\n        \"min\": 781.0,\n        \"max\": 6251.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          782.0,\n          781.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3772.197094090746,\n        \"min\": 1141.0,\n        \"max\": 9132.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1142.0,\n          1141.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6594.162538437564,\n        \"min\": 1922.0,\n        \"max\": 15383.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1924.0,\n          1922.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_frac_%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.63166795391636,\n        \"min\": 42.1,\n        \"max\": 59.37,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          42.1,\n          59.36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neg_frac_%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.63166795391636,\n        \"min\": 40.63,\n        \"max\": 57.9,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          57.9,\n          40.64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved CSVs to: /content/drive/MyDrive/hate/analysis\n"
          ]
        }
      ]
    }
  ]
}