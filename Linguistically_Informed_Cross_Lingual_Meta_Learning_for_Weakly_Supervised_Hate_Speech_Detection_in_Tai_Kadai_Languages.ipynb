{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stevebankz/Hate_Speech_Detection/blob/main/Linguistically_Informed_Cross_Lingual_Meta_Learning_for_Weakly_Supervised_Hate_Speech_Detection_in_Tai_Kadai_Languages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VavtHRPrvYqi",
        "outputId": "3332158a-1e42-450c-d832-7890e7b80c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting pythainlp\n",
            "  Downloading pythainlp-5.0.4-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2024.8.30)\n",
            "Downloading pythainlp-5.0.4-py3-none-any.whl (17.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pythainlp\n",
            "Successfully installed pythainlp-5.0.4\n"
          ]
        }
      ],
      "source": [
        "# Installing Hugging Face datasets and PyThaiNLP for Thai language processing\n",
        "!pip install datasets\n",
        "!pip install pythainlp\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdZuZsO_ZD9C",
        "outputId": "f712f31c-a5fd-4e10-c699-4a620fe2a1f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608,
          "referenced_widgets": [
            "f2cf7cd1a6cb4291aa1513872980726c",
            "3118c452da7d45c3be8e0b07881d9ed6",
            "52e797caae8a48849d16960c17099781",
            "0ed153b502ec455895d07e0696849b97",
            "a10e2a287f9a4066a9e2e8e642e50935",
            "f6ae568d6a904d2497bc64c7047f5b54",
            "188d2506ea864b5fa171458bbd13b7d2",
            "ea765a2de7af4466891b53a179f83f04",
            "b0a202a25715488fb88ce951d7ae48e0",
            "dd0daeb2de004500b8ec9fda4325554c",
            "08af85cb2afa473b9e059fd2696a21ea",
            "0628f97d1999424c86ed4ba7e02a9629",
            "2e10df31544b446da1fba70cd9193b54",
            "f0e0d7a9c2cf4c54aa712459f7f32378",
            "65c2f3f4bc71453d804820af241eee98",
            "a4a46e3807864bb2b8df48596e0e630b",
            "3b9d804121e94047a49a6fe90d23ff62",
            "cd9e18bc9dc24a149ec9bfb7c069b6aa",
            "94a0c932bad446829b2d226ccccb6774",
            "4b445c0b52e64b17924ea32e3cfaa512",
            "23c4b5e5a2f1431c962ace49bf19ed8c",
            "e11d112b78704b2a882d9df883bbafbd",
            "92ebe4161bb14c2986f5b549984af8a4",
            "9b2c8675071e491a8508fe5143e67abe",
            "4e78879c1b3440a38d24e620cd4be366",
            "efb3e4245ebb4fbeaeed48f7d33a09e0",
            "8dc09c800e72445cb9b97a31af95a002",
            "b580207825974b558aba8657c85ea7ea",
            "cec94597a1744a8483d93c0a23d2f38f",
            "0b0896c34f6c482397242bccd542709a",
            "80506a1fedcf413e8e7bd396dd0938d3",
            "2a45de62ff38461ebf0393cffd9b5516",
            "982251c1782047c2ae898d310dfbc502",
            "eb43c59e931a49299e6ddc5ec0c202e4",
            "1383531a913540539409f5dbcc069320",
            "9deefa74148b413789ccbf7ab98dc55e",
            "65ee7327f61746e19b5ddda4c29ac926",
            "0e2f49d880334798a5bbfd714d56f3ba",
            "f5f1a980483a4a4580e1d5c8ef4e31a5",
            "1d8222f82a0441899dcda7f0931c2f98",
            "b9b8d40494a94156904b84f70bc0e740",
            "e2fdfc120cc944dfba23897a505c266e",
            "72ab34eb123f472e9d97c7501e8c10bb",
            "12e49cab7bdb49a79316591a56ba2c10",
            "f16c58b03ac74c7c9064b608d2442bdd",
            "1120ee0478e14ed6959baa94dcd07dc8",
            "054d76747d3d44c49910467197672b97",
            "35b900134f1c4c89ab49c62736a2224b",
            "806409c4c2c146cea3d6d94316b73463",
            "57f6abce6db24c7fbe58204af6b65043",
            "bcb7026577004223ab4dd97ef79403ce",
            "28762ed72b01497e91493565a18aab52",
            "46432f44830249199059c1a67f195372",
            "7c50075952c246faac381eea8c77c413",
            "06bcd787198f4df2bdf2a7b5e5c65f9e",
            "93599cf2909547d9b5fb75620abb2648",
            "75e65585fbcd4b97ae8e375d01e77a49",
            "c1de5707342345198153098fac4a3fec",
            "a153d192673a410ab587bdabaa0445df",
            "4e5387aede014891b997a2b9ef1f7a4f",
            "36772199650e473e9b16bb3096819e23",
            "36a7dc31b5944daa91eba0909495ac7d",
            "65d222571a9f45ad9021daa3c358031b",
            "e1b82cdd7da44a4eb2cd2bedc18d778a",
            "ee023fdebf364ff999d11b86d1c3966d",
            "42d4c72d60a144d19e1a6a6da7345549",
            "04736a9bfee2489a8d48287034a3c7a6",
            "9203e02da3934a5f84a79c000469fe47",
            "c1d668b7d3d647989618292b69233ba2",
            "2aaa0f66f00f4035add3df4ffe9dd148",
            "7d3538121f62480ea7b69d4368d9d8f3",
            "5c3a416a7d364146b282e66eb80e4f90",
            "c81e80d34dd24920a790e8a74d64bcc1",
            "43876c2aed454349b74378d659203168",
            "be38420a570c46a4bf4b939857aaeb99",
            "fd8342a1b9f24fca9b2c04414e63562a",
            "0a2b24457db8447f811005561bce6af7"
          ]
        },
        "collapsed": true,
        "id": "Yb2wxolHv0hT",
        "outputId": "a1e11b4f-24db-45b2-8b42-d302e08f3bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/12.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2cf7cd1a6cb4291aa1513872980726c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.58M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0628f97d1999424c86ed4ba7e02a9629"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/286k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92ebe4161bb14c2986f5b549984af8a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/327k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb43c59e931a49299e6ddc5ec0c202e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/21628 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f16c58b03ac74c7c9064b608d2442bdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/2404 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93599cf2909547d9b5fb75620abb2648"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2671 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04736a9bfee2489a8d48287034a3c7a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['texts', 'category'],\n",
            "        num_rows: 21628\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['texts', 'category'],\n",
            "        num_rows: 2404\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['texts', 'category'],\n",
            "        num_rows: 2671\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Loading the Wisesight Sentiment dataset\n",
        "dataset = load_dataset(\"pythainlp/wisesight_sentiment\")\n",
        "\n",
        "# Check the available splits (train, validation, test)\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_rwUrTShwAyE",
        "outputId": "39f5b78a-7ec0-4469-9626-f72071f4426c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['texts', 'category'],\n",
            "    num_rows: 5\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# random sample from the train set\n",
        "sample_data = dataset['train'].shuffle(seed=42).select(range(5))  # Show 5 random samples\n",
        "print(sample_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vIFJFwG0wLGX",
        "outputId": "e1f591af-f5c2-4731-a782-3a701303f4fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "category\n",
            "1    11795\n",
            "2     5491\n",
            "0     3866\n",
            "3      476\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Count of occurrences of each label in the train split\n",
        "label_counts = dataset['train'].features['category'].names  # Get label names (pos, neu, neg, q)\n",
        "\n",
        "# Calculate distribution of labels\n",
        "label_distribution = dataset['train'].to_pandas()['category'].value_counts()\n",
        "print(label_distribution)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mQuGA68JwY8o",
        "outputId": "cbc0af60-16c8-4dc9-cf62-e9bea5d6779a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        char_length   word_length\n",
            "count  21628.000000  21628.000000\n",
            "mean      89.818291      6.340300\n",
            "std      149.255596     12.186247\n",
            "min        1.000000      1.000000\n",
            "25%       19.000000      1.000000\n",
            "50%       39.000000      3.000000\n",
            "75%       98.000000      6.000000\n",
            "max     1997.000000    292.000000\n"
          ]
        }
      ],
      "source": [
        "# Analyze the length of the messages (number of characters and words)\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the dataset to a pandas DataFrame\n",
        "df = dataset['train'].to_pandas()\n",
        "\n",
        "# Calculate message lengths\n",
        "df['char_length'] = df['texts'].apply(len)  # Length in characters\n",
        "df['word_length'] = df['texts'].apply(lambda x: len(x.split()))  # Length in words\n",
        "\n",
        "# Display basic statistics about message length\n",
        "print(df[['char_length', 'word_length']].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TNCFeWONwlmY",
        "outputId": "1ad0c2c7-079a-4baf-bbf0-e695fec209d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ไป', 'จอง', 'มา', 'แล้', 'วนา', 'จา', ' ', 'Mitsubishi', ' ', 'Attrage', ' ', 'ได้', 'หลัง', 'สงกรานต์', 'เลย', ' ', 'รอ', 'ขับ', 'อยู่', 'นา', 'จา', ' ', 'กระทัดรัด', ' ', 'เหมาะกับ', 'สาว', 'ๆ', 'ขับรถ', 'คนเดียว', 'แบบ', 'เรา', ' ', 'ราคา', 'สบาย', 'กระเป๋า', ' ', 'ประหยัด', 'น้ำมัน', ' ', 'วิ่ง', 'ไกล', 'แค่', 'ไหน', 'หายห่วง', 'ค่ะ']\n"
          ]
        }
      ],
      "source": [
        "# Install PyThaiNLP tokenizer\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# Tokenizing a Thai sentence\n",
        "sample_text = df['texts'].iloc[0]  # Taking the first text from the dataset\n",
        "tokenized_text = word_tokenize(sample_text, engine='newmm')\n",
        "print(tokenized_text)  # View the tokenized text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OwIo6YxNww9Y",
        "outputId": "52015d15-05f5-4805-e411-b792ee12e1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts  \\\n",
            "0  ไปจองมาแล้วนาจา Mitsubishi Attrage ได้หลังสงกร...   \n",
            "1  เปิดศักราชใหม่! นายกฯ แถลงข่าวก่อนการแข่งขันศึ...   \n",
            "2                           บัตรสมาชิกลดได้อีกไหมคับ   \n",
            "3                                สนใจ new mazda2ครับ   \n",
            "4                                                 😍😍   \n",
            "\n",
            "                                     processed_texts  \n",
            "0  ไป จอง มา แล้ วนา จา   mitsubishi   attrage   ...  \n",
            "1  เปิด ศักราช ใหม่ !   นายกฯ   แถลงข่าว ก่อน การ...  \n",
            "2                      บัตรสมาชิก ลด ได้ อีก ไหม คับ  \n",
            "3                          สนใจ   new   mazda 2 ครับ  \n",
            "4                                                 😍😍  \n"
          ]
        }
      ],
      "source": [
        "# Function to preprocess a single text\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text using PyThaiNLP (newmm is the default tokenizer)\n",
        "    tokens = word_tokenize(text, engine='newmm')\n",
        "\n",
        "    # Lowercase all tokens\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing function to the dataset\n",
        "df['processed_texts'] = df['texts'].apply(preprocess_text)\n",
        "\n",
        "# View the first few rows of the preprocessed dataset\n",
        "print(df[['texts', 'processed_texts']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qyhvnMxzw_Y_"
      },
      "outputs": [],
      "source": [
        "# Save the preprocessed data to a CSV file for further use\n",
        "df[['processed_texts', 'category']].to_csv('preprocessed_wisesight_sentiment.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I-R8KIdRx6Lw",
        "outputId": "bfa6588f-f796-422b-edfb-4bbcb0b69f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ควาย', 'ทุเรศ', 'หมา', 'ตอแหล', 'โง่', 'ต่ำ', 'บ้า', 'เห็บ', 'เลว', 'กะหรี่']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the toxic words from the text file\n",
        "with open('/content/drive/MyDrive/toxic_keywords_1.txt', 'r') as f:\n",
        "    toxic_words = [line.strip() for line in f]\n",
        "\n",
        "# Convert the list to a pandas Series (optional, for consistency)\n",
        "toxic_words_df = pd.DataFrame(toxic_words, columns=['word'])\n",
        "\n",
        "# Preview the toxic word list\n",
        "print(toxic_words[:10])  # Display the first 10 toxic words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k-R0Owcz0jNB",
        "outputId": "aba83fde-b8cb-43ea-cdf5-3f43d777d625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     processed_texts  category  weak_label\n",
            "0  ไป จอง มา แล้ วนา จา   mitsubishi   attrage   ...         1           0\n",
            "1  เปิด ศักราช ใหม่ !   นายกฯ   แถลงข่าว ก่อน การ...         1           0\n",
            "2                      บัตรสมาชิก ลด ได้ อีก ไหม คับ         1           0\n",
            "3                          สนใจ   new   mazda 2 ครับ         1           0\n",
            "4                                                 😍😍         0           0\n"
          ]
        }
      ],
      "source": [
        "# Create a function to check if a text contains any toxic words\n",
        "def contains_toxic_words(text, toxic_words):\n",
        "    # Tokenize the text using the same tokenizer (PyThaiNLP) used in preprocessing\n",
        "    tokens = word_tokenize(text, engine='newmm')\n",
        "    # Check if any token is in the toxic word list\n",
        "    return any(token in toxic_words for token in tokens)\n",
        "\n",
        "# Apply weak labeling based on sentiment and toxic words\n",
        "def weak_labeling(row, toxic_words):\n",
        "    # If the sentiment is negative, we flag it as potential hate speech (weakly labeled as 1)\n",
        "    if row['category'] == 'neg':\n",
        "        return 1\n",
        "    # If the message contains toxic words, we flag it as potential hate speech (weakly labeled as 1)\n",
        "    elif contains_toxic_words(row['processed_texts'], toxic_words):\n",
        "        return 1\n",
        "    # Otherwise, we consider it non-hateful (weakly labeled as 0)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Apply the weak labeling function to the dataset\n",
        "df['weak_label'] = df.apply(weak_labeling, axis=1, toxic_words=toxic_words)\n",
        "\n",
        "# Preview the newly labeled dataset\n",
        "print(df[['processed_texts', 'category', 'weak_label']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n3YAEyFT0wm5",
        "outputId": "d725fcb7-dffe-4db3-e53f-7c04bb205de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weak_label\n",
            "0    20783\n",
            "1      845\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check the distribution of weak labels (0 = non-hateful, 1 = potentially hateful)\n",
        "weak_label_distribution = df['weak_label'].value_counts()\n",
        "print(weak_label_distribution)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xLWfTp1m0_ma"
      },
      "outputs": [],
      "source": [
        "# Save the weakly labeled dataset to a CSV file for further use\n",
        "df[['processed_texts', 'weak_label']].to_csv('weakly_labeled_wisesight_sentiment.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KHiZXUWs2w9o",
        "outputId": "56231c39-83f9-425d-c53e-bbec8db22c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "weak_label\n",
            "0    20783\n",
            "1    20783\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Load the weakly labeled data (assuming it's saved as a CSV)\n",
        "df = pd.read_csv('weakly_labeled_wisesight_sentiment.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "texts = df['processed_texts']\n",
        "labels = df['weak_label']\n",
        "\n",
        "# Reshape data for oversampling\n",
        "texts_reshaped = texts.values.reshape(-1, 1)  # Needs to be 2D for oversampling\n",
        "\n",
        "# Initialize the RandomOverSampler\n",
        "ros = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
        "\n",
        "# Perform oversampling\n",
        "texts_resampled, labels_resampled = ros.fit_resample(texts_reshaped, labels)\n",
        "\n",
        "# Convert resampled data back to a DataFrame\n",
        "balanced_df = pd.DataFrame({\n",
        "    'texts': texts_resampled.flatten(),  # Flatten to 1D\n",
        "    'weak_label': labels_resampled\n",
        "})\n",
        "\n",
        "# Save or use the balanced dataset directly for further steps\n",
        "balanced_df.to_csv('balanced_weakly_labeled_data.csv', index=False)\n",
        "print(balanced_df['weak_label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qOLhpdnjiO9q",
        "outputId": "6baf6762-5365-48e1-e012-3bb3e0f5a24a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install Hugging Face transformers library\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch  # PyTorch for model training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "\n",
        "# Load the tokenizer for a multilingual model (mBERT in this case)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Function to tokenize text\n",
        "def tokenize_data(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# Load the balanced dataset (from the CSV saved after oversampling)\n",
        "balanced_df = pd.read_csv('balanced_weakly_labeled_data.csv')\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "train_val_df, test_df = train_test_split(balanced_df, test_size=0.1, random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize each dataset split and capture both 'input_ids' and 'attention_mask'\n",
        "train_encodings = tokenize_data(train_df['texts'].tolist())\n",
        "val_encodings = tokenize_data(val_df['texts'].tolist())\n",
        "test_encodings = tokenize_data(test_df['texts'].tolist())\n",
        "\n",
        "# Separate 'input_ids' and 'attention_mask' for each split\n",
        "train_texts, train_masks = train_encodings['input_ids'], train_encodings['attention_mask']\n",
        "val_texts, val_masks = val_encodings['input_ids'], val_encodings['attention_mask']\n",
        "test_texts, test_masks = test_encodings['input_ids'], test_encodings['attention_mask']\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['weak_label'].tolist())\n",
        "val_labels = torch.tensor(val_df['weak_label'].tolist())\n",
        "test_labels = torch.tensor(test_df['weak_label'].tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "fda6576012014ec2ad39e1ac1963f9f5",
            "1b38bcc4386b4deeb8036b2f416b5138",
            "0be306bc88974a34ac9ff94c4da978d8",
            "ea80abf491d94e79a705f3a927033e28",
            "ab444298634b4a30b65f1637c0478d1b",
            "465395b4d913421eb35eac1551dbdb9a",
            "5f64be4f7ae541c698155452470434a0",
            "521b4cd838b541aa951ec05a3bd4e86d",
            "bd0932037fa84f5faf0b9ab132fadccd",
            "6995d9fb464248489cbd31495b65a656",
            "4b501fd493cc4bd28c5962510df5a902",
            "a16eadf161c9416aa87af3c325dabb0e",
            "26b736f97dfc4017a01464a5a40d0b16",
            "82883a924fe1467f9f767ba7514dfdc6",
            "1206a6fb486c4839886df3b87735758d",
            "ee9dfd48c1e643be901ce9ce03532ee7",
            "1fdfd52c5a9d4b96b0a3f742cc9d0614",
            "44bbe2021fd44da5aabe73e6b4d93906",
            "c9dcf5edbf2c4080b43d9a4271e885bc",
            "f162912f777649ee999b474a028ec2f8",
            "507f5279b730462c9f40c29964261d63",
            "cbdaadb52d074972a4bd6ca8876a1b1d",
            "2ab6ccb2f287436b9d3bf6ab00ef8bd7",
            "d8241707f7fb47afb7ccf3bc7a7fb4c2",
            "e1acfd456e0a4c83aa054dab75a81a3e",
            "1bca25fdcf174f5ab87401909675129a",
            "9e2a6fac18b5490b9adb6f743bac3d1f",
            "394ed618ac384a8ca4bcc04c5dc7949c",
            "2311402d4dd940d191e761b18874c9a8",
            "db435260964d4c9cb299560c8d5cd9f3",
            "b912e4c274c54e0c9902c9d13e25b948",
            "a6cac576f93c43f88118060e7082a47e",
            "bddcf1bbc1a14be2bcec333ba9e9f42d",
            "b11cd67bb0d44bbfb64ac1a25d670cbf",
            "a39bfa3b79b14e08a6d049fb838666f4",
            "2ea12896d72e4a1d94ff43c7291f74b5",
            "a86f9bd87edc40af87beaa22626c26fe",
            "010ca851fc654ca3aabe653a0b06632c",
            "0418c54db15446259e77c4fc0850163b",
            "7e3e77a5269b41f4aa356d9ad3644d69",
            "4b9c73ec2de347a9b3239373e3c170f8",
            "eae9b2d6a25446b5b5d42a102c926b2e",
            "f98dd2b2b24a402b99baec316055726c",
            "fc2bdc15c8e14e6dada3058b07c4d539",
            "b32053f09293467fb803d3ebd4cf4ca9",
            "cd38724a0e5f41c0bcd6e7c1d79a1e51",
            "ff284cfdf86e4103909f52a33d11dd4d",
            "882742bc71ad4172884fa414aa5584da",
            "181b93166fc54544838c387139a6646d",
            "476d1c84b5eb46bab99966efbf8f835d",
            "0521fdf52b314ce98c83724027f709c7",
            "92edb1a82293467c9dd6459fa098825c",
            "10500a12741d4aff9fc7d7cb304ccd59",
            "9f0ffef357f54ffba8ae830d7da3f38f",
            "3939ebb8eaba4e98a246b950e40dba52"
          ]
        },
        "id": "Nak9dHcp5ySm",
        "outputId": "790cd8fd-3a06-4432-b9b4-19f4b977d7fc",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fda6576012014ec2ad39e1ac1963f9f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a16eadf161c9416aa87af3c325dabb0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ab6ccb2f287436b9d3bf6ab00ef8bd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b11cd67bb0d44bbfb64ac1a25d670cbf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b32053f09293467fb803d3ebd4cf4ca9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset class with attention mask support\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, masks, labels):\n",
        "        self.texts = texts\n",
        "        self.masks = masks\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.texts[idx],\n",
        "            'attention_mask': self.masks[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "# Create train, validation, and test datasets with attention masks\n",
        "train_dataset = TextDataset(train_texts, train_masks, train_labels)\n",
        "val_dataset = TextDataset(val_texts, val_masks, val_labels)\n",
        "test_dataset = TextDataset(test_texts, test_masks, test_labels)\n",
        "\n",
        "# Create DataLoader objects for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)  # No shuffle for test\n"
      ],
      "metadata": {
        "id": "cID08Whz6EUx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885,
          "referenced_widgets": [
            "b7f2b92183774041904327d36043eac4",
            "d4bb23ab0cce45869e00fed05abcfb99",
            "dcd49e678d6d4804938c302492bead73",
            "53845d48d4214abc8b6dcf162921deb0",
            "bcf8271419f84777844977b90c7acb32",
            "2240813d85054fc2b0f46036b4035841",
            "f508b649c1e24248ac4a6f5c30ad2b1e",
            "f0b0234fd0c148ce9028e7358dee9aa4",
            "7de30b43417c49f9970dc814ec30b061",
            "f84974caa4634ca8b8ed4fca81ad5b12",
            "8d87afca569d4a78bf337538229ef27a"
          ]
        },
        "collapsed": true,
        "id": "h3MUGZTNix8V",
        "outputId": "960a50bf-a980-413a-9c2a-68c4c396015c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7f2b92183774041904327d36043eac4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AdamW\n",
        "\n",
        "# Load pre-trained mBERT model for classification (binary classification: hate vs. non-hate)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\",\n",
        "    num_labels=2  # Binary classification (hate vs. non-hate)\n",
        ")\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Define label smoothing cross-entropy loss\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        # Number of classes (e.g., 2 for binary classification)\n",
        "        n_classes = outputs.size(-1)\n",
        "\n",
        "        # Apply log_softmax to outputs\n",
        "        log_probs = torch.nn.functional.log_softmax(outputs, dim=-1)\n",
        "\n",
        "        # Create smooth labels\n",
        "        targets = torch.zeros_like(log_probs).scatter(1, targets.unsqueeze(1), 1)  # One-hot encode targets\n",
        "        targets = (1 - self.smoothing) * targets + self.smoothing / n_classes  # Apply label smoothing\n",
        "\n",
        "        # Compute the smoothed cross-entropy loss\n",
        "        loss = (-targets * log_probs).mean()\n",
        "        return loss\n",
        "\n",
        "# Define optimizer with PyTorch's AdamW to avoid the deprecation warning\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Define a simple training loop with label smoothing\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss, total_val_loss = 0, 0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        # Training phase\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move batch data to GPU if available\n",
        "            input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "            attention_mask = batch['attention_mask'].squeeze(1).to(device)  # Added attention mask\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits  # Include attention_mask\n",
        "            loss = criterion(outputs, labels)  # Use custom criterion with label smoothing\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "                attention_mask = batch['attention_mask'].squeeze(1).to(device)  # Added attention mask\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits  # Include attention_mask\n",
        "                val_loss = criterion(outputs, labels)  # Use custom criterion with label smoothing\n",
        "\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_accuracy = correct / total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}, Val Accuracy: {val_accuracy}\")\n",
        "\n",
        "# Train the model with label smoothing\n",
        "train_model(model, train_loader, val_loader, criterion=LabelSmoothingCrossEntropy(smoothing=0.1), optimizer=optimizer, num_epochs=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nNG3983o4QNA",
        "outputId": "64b5b5b7-fdcf-4c3a-eb6e-eb35f695608e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.5.1-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.8 torchmetrics-1.5.1\n",
            "Epoch 1/3, Train Loss: 0.1474396990246788, Val Loss: 0.11015640469825166, Val Accuracy: 0.9887730553327987\n",
            "Epoch 2/3, Train Loss: 0.10660059831713942, Val Loss: 0.11256408228132969, Val Accuracy: 0.9859663191659984\n",
            "Epoch 3/3, Train Loss: 0.10421657228154463, Val Loss: 0.10319312343485335, Val Accuracy: 0.9965249933172948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sng8hnA5BFlJ",
        "outputId": "7100f695-b583-441a-d696-f9ec2ef931b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.12603263915158236, Test Accuracy: 0.9735386095742121\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Non-hate       0.96      0.99      0.97      2153\n",
            "        Hate       0.99      0.95      0.97      2004\n",
            "\n",
            "    accuracy                           0.97      4157\n",
            "   macro avg       0.98      0.97      0.97      4157\n",
            "weighted avg       0.97      0.97      0.97      4157\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Initialize variables for tracking test loss and correct predictions\n",
        "test_loss = 0\n",
        "correct, total = 0, 0\n",
        "\n",
        "# Store predictions and true labels\n",
        "all_preds = []\n",
        "y_true = []\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:  # Use val_loader if you don't have a separate test set\n",
        "        input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass (no labels argument here)\n",
        "        outputs = model(input_ids=input_ids)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Calculate loss\n",
        "        criterion = LabelSmoothingCrossEntropy(smoothing=0.1)  # Use the same criterion as training\n",
        "        loss = criterion(logits, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Get predictions\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())  # Store predictions\n",
        "        y_true.extend(labels.cpu().numpy())    # Store true labels\n",
        "\n",
        "        # Calculate accuracy\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "# Average test loss\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = correct / total\n",
        "\n",
        "print(f\"Test Loss: {avg_test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Generate classification report\n",
        "y_true = np.array(y_true)  # Convert true labels to numpy array\n",
        "y_pred = np.array(all_preds)  # Convert predictions to numpy array\n",
        "print(classification_report(y_true, y_pred, target_names=['Non-hate', 'Hate']))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of identifying misclassified samples\n",
        "misclassified = [\n",
        "    (input_ids, true, pred)\n",
        "    for input_ids, true, pred in zip(test_texts, y_true, y_pred)  # or val_texts if you're analyzing validation\n",
        "    if true != pred\n",
        "]\n",
        "\n",
        "# Display the first 10 misclassified examples in readable format\n",
        "for input_ids, true, pred in misclassified[:10]:  # First 10 misclassified examples\n",
        "    # Detokenize to retrieve original text\n",
        "    text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "    print(f\"Text: {text}\\nTrue Label: {true}, Predicted: {pred}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1cG2ZHNA9k0t",
        "outputId": "96cce288-bf0e-4b64-d06c-4a6d15367653"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: ฆ่า หั่น ศพ เปรี้ยว หนี ตั้ง หลาย วัน นั่ง คุย กับ ตำรวจ สบายใจ อันนี้ บุหรี่ ไฟฟ้า จับ ลาก ส่ะ\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ฆ่า หั่น ศพ เปรี้ยว หนี ตั้ง หลาย วัน นั่ง คุย กับ ตำรวจ สบายใจ อันนี้ บุหรี่ ไฟฟ้า จับ ลาก ส่ะ\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: แกง กะหรี่ ไข่ ข้น แซบ เวอร์ กด like กัน ไป ยาว ๆ # deliciouslyyours # showdc\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ไฮไลท์ ที่ พลาด ไม่ ได้ ของ สวนสัตว์ ขอนแก่น คือ การ เดิน ชม สัตว อัฟริกา บน ทางเดิน ลอยฟ้า ทั้ง มุมมอง สัตว์ จาก ที่สูง และ จุดชมวิว ที่ งดงาม สุด ประทับใจ\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ทีม นักวิทยาศาสตร์ ค้นพบ เสือดำ หา ยาก ใน เคนยา นับ เป็นครั้งแรก ที่ พบ เสือ ชนิด นี้ ใน แอฟริกา ใน รอบ เกือบ 100 ปี # ข่าว โม โน 29 # เสือดำ # แอฟริกา # สัตว์ หา ยาก # mono29 # mono29news\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ไม่ เจียม ไง เสือก แดก ลีโอ\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ฆ่า คนตาย โทษเบา กว่า ตั้ง เยอะ\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: แสงโสม นี่ พัก เน้อ ตื่น ยาก ฉิบหาย ขำ หัว อี ก.\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ปี 2018 บอ กว่า ดี แต่ ตอน วีออส 2013 เกียร์ 4 สปีด ด่า กัน ฉิบหาย วาย ปวง เอา สิ\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: โห บุหรี่ ไฟฟ้า นึก ว่า ฆ่า คนตาย\n",
            "True Label: 1, Predicted: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9hFtajfCXZx",
        "outputId": "1df20224-ba5d-49d0-dcad-956819476188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to /content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\n"
          ]
        }
      ],
      "source": [
        "# Specify the directory in Google Drive where you want to save the model\n",
        "save_directory = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(save_directory)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {save_directory}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXm6L1GwJJ6_"
      },
      "outputs": [],
      "source": [
        "# Specify destination directory in Google Drive\n",
        "import shutil\n",
        "save_directory = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "\n",
        "# Ensure the destination directory exists\n",
        "!mkdir -p \"{save_directory}\"\n",
        "\n",
        "# Paths to local files\n",
        "files_to_save = {\n",
        "    \"balanced_weakly_labeled_data.csv\": \"/content/balanced_weakly_labeled_data.csv\",\n",
        "    \"preprocessed_wisesight_sentiment.csv\": \"/content/preprocessed_wisesight_sentiment.csv\",\n",
        "    \"toxic_keywords_1.txt\": \"/content/toxic_keywords_1.txt\",\n",
        "    \"weakly_labeled_wisesight_sentiment.csv\": \"/content/weakly_labeled_wisesight_sentiment.csv\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6mFGAJK2BZyA",
        "outputId": "493008cc-a0da-4c7d-fe34-3591f470ae54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load your pre-trained BERT model and tokenizer\n",
        "model_path = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKAmOkkyBsL_",
        "outputId": "05fd0bc9-4e80-43af-f866-a2fea40e5376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized input IDs shape: torch.Size([41566, 128])\n"
          ]
        }
      ],
      "source": [
        "# Load your Thai dataset (replace with your actual file path)\n",
        "data_path = '/content/drive/MyDrive/balanced_weakly_labeled_data.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Clean text function to remove non-Thai characters (optional, depends on dataset)\n",
        "import re\n",
        "def clean_text(text):\n",
        "    return re.sub(r\"[^ก-๙\\s]\", \"\", text)  # Retain only Thai characters and spaces\n",
        "\n",
        "# Apply text cleaning\n",
        "df['cleaned_texts'] = df['texts'].apply(clean_text)\n",
        "\n",
        "# Tokenize the cleaned text using the loaded tokenizer\n",
        "def tokenize_texts(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        padding=True,          # Add padding to ensure equal length sequences\n",
        "        truncation=True,       # Truncate long sequences to max length\n",
        "        max_length=128,        # Adjust max length based on model needs\n",
        "        return_tensors=\"pt\"    # Return as PyTorch tensors\n",
        "    )\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_data = tokenize_texts(df['cleaned_texts'].tolist())\n",
        "print(f\"Tokenized input IDs shape: {tokenized_data['input_ids'].shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "StvnCyIlB6V9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define a custom Dataset class for the tokenized data\n",
        "class ThaiCharacterDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_mask, labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_mask[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "# Convert labels to tensors\n",
        "labels = torch.tensor(df['weak_label'].tolist())\n",
        "\n",
        "# Create Dataset and DataLoader\n",
        "thai_dataset = ThaiCharacterDataset(tokenized_data['input_ids'], tokenized_data['attention_mask'], labels)\n",
        "thai_dataloader = DataLoader(thai_dataset, batch_size=16, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezzGhIMhCAvB",
        "outputId": "40077106-f914-4f2c-ed3b-81ecd693489f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.026647572094142428\n",
            "Epoch 2/3, Loss: 0.01543018503167546\n",
            "Epoch 3/3, Loss: 0.013409500719137747\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "# Set up optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in thai_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(thai_dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jNHW5jQNGfXB",
        "outputId": "54681301-8078-403f-edc6-8c6c0a905f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model and tokenizer saved to /content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Define the directory in Google Drive where you want to save the model\n",
        "save_directory = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "\n",
        "# Save the model\n",
        "model.base_model.save_pretrained(save_directory)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {save_directory}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
        "\n",
        "# Load your fine-tuned BERT model\n",
        "model_path = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "base_model.to(device)\n",
        "\n",
        "# Define a new model with an additional phoneme prediction head\n",
        "class MultiTaskBERT(nn.Module):\n",
        "    def __init__(self, base_model, phoneme_vocab_size):\n",
        "        super(MultiTaskBERT, self).__init__()\n",
        "        self.base_model = base_model  # Main model for hate speech classification\n",
        "        self.phoneme_head = nn.Linear(base_model.config.hidden_size, phoneme_vocab_size)  # Phoneme prediction head\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Get outputs from the BERT model with hidden states\n",
        "        outputs = self.base_model.bert(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "        last_hidden_state = outputs.hidden_states[-1]  # Last hidden layer for phoneme prediction\n",
        "\n",
        "        # Phoneme prediction output (character-level)\n",
        "        phoneme_logits = self.phoneme_head(last_hidden_state)  # Shape: (batch_size, seq_len, phoneme_vocab_size)\n",
        "\n",
        "        # Hate speech classification output\n",
        "        cls_logits = self.base_model.classifier(outputs.pooler_output)  # Shape: (batch_size, num_labels)\n",
        "\n",
        "        return phoneme_logits, cls_logits\n",
        "\n",
        "# Set phoneme vocabulary size (customize based on your data)\n",
        "phoneme_vocab_size = 100  # Adjust based on actual phoneme classes\n",
        "model = MultiTaskBERT(base_model, phoneme_vocab_size).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kWWvjptbG-kj",
        "outputId": "1afee02f-02ef-4850-b4e4-95483227e37f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjkuxICCIfG8",
        "outputId": "47bdd44f-613d-4343-d4fa-85fe34a4d12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phoneme-like labels shape: torch.Size([41566, 128])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pythainlp.tokenize import syllable_tokenize\n",
        "import torch\n",
        "\n",
        "# Load your Thai dataset\n",
        "data_path = '/content/drive/MyDrive/balanced_weakly_labeled_data.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Step 1: Generate syllable tokens as phoneme-like approximations\n",
        "def generate_syllable_tokens(text):\n",
        "    syllables = syllable_tokenize(text, engine='dict')  # Use syllabic segmentation\n",
        "    return syllables\n",
        "\n",
        "df['syllable_tokens'] = df['texts'].apply(generate_syllable_tokens)\n",
        "\n",
        "# Step 2: Create a syllable vocabulary and map syllables to unique IDs\n",
        "syllable_vocab = {}\n",
        "current_id = 0\n",
        "\n",
        "for syllables in df['syllable_tokens']:\n",
        "    for syllable in syllables:\n",
        "        if syllable not in syllable_vocab:\n",
        "            syllable_vocab[syllable] = current_id\n",
        "            current_id += 1\n",
        "\n",
        "# Step 3: Convert syllable sequences to integer sequences\n",
        "def convert_to_ids(sequence):\n",
        "    return [syllable_vocab[syllable] for syllable in sequence]\n",
        "\n",
        "df['syllable_ids'] = df['syllable_tokens'].apply(convert_to_ids)\n",
        "\n",
        "# Step 4: Pad syllable sequences to a fixed length (e.g., 128)\n",
        "max_len = 128\n",
        "def pad_sequence(seq):\n",
        "    if len(seq) < max_len:\n",
        "        return seq + [0] * (max_len - len(seq))  # Pad with 0s for shorter sequences\n",
        "    else:\n",
        "        return seq[:max_len]  # Truncate longer sequences\n",
        "\n",
        "df['syllable_ids_padded'] = df['syllable_ids'].apply(pad_sequence)\n",
        "\n",
        "# Convert to tensor for training\n",
        "phoneme_labels = torch.tensor(df['syllable_ids_padded'].tolist())\n",
        "print(\"Phoneme-like labels shape:\", phoneme_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "67eUN2zwHfev"
      },
      "outputs": [],
      "source": [
        "phoneme_labels = torch.randint(0, phoneme_vocab_size, (len(df), 128))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "# Set up optimizer and loss functions\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "phoneme_loss_fn = CrossEntropyLoss()\n",
        "classification_loss_fn = CrossEntropyLoss()\n",
        "\n",
        "# Training loop with dual losses\n",
        "num_epochs = 3\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_phoneme_loss, total_classification_loss = 0, 0\n",
        "    for batch_idx, batch in enumerate(thai_dataloader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        classification_labels = batch['labels'].to(device)\n",
        "\n",
        "        # Retrieve the corresponding phoneme labels for the current batch\n",
        "        phoneme_label_batch = phoneme_labels[batch_idx * len(input_ids):(batch_idx + 1) * len(input_ids)].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        phoneme_logits, cls_logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Reshape phoneme_logits and phoneme_label_batch to match dimensions\n",
        "        phoneme_logits = phoneme_logits.view(-1, phoneme_vocab_size)  # Shape: (batch_size * seq_len, vocab_size)\n",
        "        phoneme_label_batch = phoneme_label_batch.view(-1)  # Shape: (batch_size * seq_len)\n",
        "\n",
        "        # Calculate phoneme loss\n",
        "        phoneme_loss = phoneme_loss_fn(phoneme_logits, phoneme_label_batch)\n",
        "\n",
        "        # Calculate classification loss\n",
        "        classification_loss = classification_loss_fn(cls_logits, classification_labels)\n",
        "\n",
        "        # Combine losses and optimize\n",
        "        total_loss = phoneme_loss + classification_loss\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_phoneme_loss += phoneme_loss.item()\n",
        "        total_classification_loss += classification_loss.item()\n",
        "\n",
        "    avg_phoneme_loss = total_phoneme_loss / len(thai_dataloader)\n",
        "    avg_classification_loss = total_classification_loss / len(thai_dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Phoneme Loss: {avg_phoneme_loss}, Classification Loss: {avg_classification_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEG5XKROIsnR",
        "outputId": "5b242748-50cc-4015-9c42-9aa4764a9d10"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Phoneme Loss: 4.6098831188137295, Classification Loss: 0.01307484107452516\n",
            "Epoch 2/3, Phoneme Loss: 4.607374034908021, Classification Loss: 0.008522843429922931\n",
            "Epoch 3/3, Phoneme Loss: 4.606879003604069, Classification Loss: 0.01000913630996141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJHzK4NHKO-X",
        "outputId": "7bc30e68-31ff-4afa-f93f-206c20b80a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Phoneme Loss: 3.639465255632687, Classification Loss: 0.024973187675885036\n",
            "Epoch 2/3, Phoneme Loss: 0.1615475686381731, Classification Loss: 0.01320341678564209\n",
            "Epoch 3/3, Phoneme Loss: 0.032623962771285146, Classification Loss: 0.008391529086575604\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "# Set up optimizer and loss functions\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "phoneme_loss_fn = CrossEntropyLoss()\n",
        "classification_loss_fn = CrossEntropyLoss()\n",
        "\n",
        "# Training loop with dual losses\n",
        "num_epochs = 3\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_phoneme_loss, total_classification_loss = 0, 0\n",
        "    for batch in thai_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        classification_labels = batch['labels'].to(device)\n",
        "\n",
        "        # Retrieve the corresponding phoneme labels for the current batch\n",
        "        phoneme_label_batch = phoneme_labels[batch['labels']]  # Ensure this matches batch size\n",
        "        phoneme_label_batch = phoneme_label_batch.to(device)  # Move phoneme labels to device\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        phoneme_logits, cls_logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Reshape phoneme_logits and phoneme_label_batch to match dimensions\n",
        "        phoneme_logits = phoneme_logits.view(-1, phoneme_vocab_size)  # Shape: (batch_size * seq_len, vocab_size)\n",
        "        phoneme_label_batch = phoneme_label_batch.view(-1)  # Shape: (batch_size * seq_len)\n",
        "\n",
        "        # Calculate phoneme loss\n",
        "        phoneme_loss = phoneme_loss_fn(phoneme_logits, phoneme_label_batch)\n",
        "\n",
        "        # Calculate classification loss\n",
        "        classification_loss = classification_loss_fn(cls_logits, classification_labels)\n",
        "\n",
        "        # Combine losses and optimize\n",
        "        total_loss = phoneme_loss + classification_loss\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_phoneme_loss += phoneme_loss.item()\n",
        "        total_classification_loss += classification_loss.item()\n",
        "\n",
        "    avg_phoneme_loss = total_phoneme_loss / len(thai_dataloader)\n",
        "    avg_classification_loss = total_classification_loss / len(thai_dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Phoneme Loss: {avg_phoneme_loss}, Classification Loss: {avg_classification_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jey_QyYRSKan",
        "outputId": "4024e3f8-4997-469a-cfdc-9095d5047971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model state dictionary and tokenizer saved to /content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "\n",
        "# Define the save path in Google Drive\n",
        "save_directory = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "# Save the model's state dictionary\n",
        "model_path = os.path.join(save_directory, \"pytorch_model.bin\")\n",
        "torch.save(model.state_dict(), model_path)\n",
        "\n",
        "# Save the model configuration if applicable (e.g., if you used a Hugging Face configuration object)\n",
        "if hasattr(model, \"config\"):\n",
        "    model.config.save_pretrained(save_directory)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Model state dictionary and tokenizer saved to {save_directory}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vmz3hKneTsI-",
        "outputId": "2a24f5ee-b400-45aa-9360-a9add4d08968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-34-ab372d224baf>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(state_dict_path)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer loaded successfully with partial loading!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Define the save path in Google Drive\n",
        "model_path = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "state_dict_path = f\"{model_path}/pytorch_model.bin\"\n",
        "\n",
        "# Step 1: Initialize the model architecture\n",
        "config_path = \"bert-base-multilingual-cased\"  # Original architecture\n",
        "model = AutoModelForSequenceClassification.from_pretrained(config_path, num_labels=2)  # Adjust labels as needed\n",
        "\n",
        "# Step 2: Load the saved state dictionary with strict=False\n",
        "state_dict = torch.load(state_dict_path)\n",
        "model.load_state_dict(state_dict, strict=False)  # Load only matching parameters\n",
        "\n",
        "# Step 3: Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(config_path)\n",
        "\n",
        "# Move model to the available device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully with partial loading!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6XkFUzHVWcsJ"
      },
      "outputs": [],
      "source": [
        "# Define phoneme prediction layer\n",
        "class MultiTaskBERT(nn.Module):\n",
        "    def __init__(self, base_model, phoneme_vocab_size):\n",
        "        super(MultiTaskBERT, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.phoneme_head = nn.Linear(self.base_model.config.hidden_size, phoneme_vocab_size)  # Phoneme prediction head\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None, phoneme_labels=None):\n",
        "        outputs = self.base_model.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "        phoneme_logits = self.phoneme_head(last_hidden_state)  # Shape: (batch_size, seq_len, phoneme_vocab_size)\n",
        "\n",
        "        return phoneme_logits\n",
        "\n",
        "# Instantiate the MultiTask model\n",
        "phoneme_vocab_size = 30  # Example size (adjust based on phoneme data)\n",
        "multi_task_model = MultiTaskBERT(model, phoneme_vocab_size).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "# Assuming your fine-tuned model is saved in 'model_path'\n",
        "model_path = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "base_model = AutoModel.from_pretrained(model_path, output_hidden_states=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "base_model.to(device)\n",
        "\n",
        "# Define a new model with an additional POS tagging head using the pre-fine-tuned BERT model\n",
        "class MultiTaskBERTWithPOS(nn.Module):\n",
        "    def __init__(self, base_model, pos_vocab_size):\n",
        "        super(MultiTaskBERTWithPOS, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.pos_head = nn.Linear(self.base_model.config.hidden_size, pos_vocab_size)  # POS tagging head\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None, pos_labels=None, output_hidden_states=False):\n",
        "        # Call the base model directly\n",
        "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=output_hidden_states)\n",
        "\n",
        "        # Access last hidden state directly from dictionary output\n",
        "        last_hidden_state = outputs['last_hidden_state']\n",
        "        hidden_states = outputs.get('hidden_states', None)  # Use .get() to avoid KeyError if hidden_states are not present\n",
        "\n",
        "        # POS tagging logits from the last hidden state\n",
        "        pos_logits = self.pos_head(last_hidden_state)  # Shape: (batch_size, seq_len, pos_vocab_size)\n",
        "\n",
        "        # Return dictionary with all relevant outputs\n",
        "        return {\n",
        "            \"last_hidden_state\": last_hidden_state,\n",
        "            \"pos_logits\": pos_logits,\n",
        "            \"hidden_states\": hidden_states\n",
        "        }\n",
        "\n",
        "# Initialize with your model and specified POS vocabulary size\n",
        "pos_vocab_size = 50  # Adjust based on actual POS vocabulary size\n",
        "multi_task_model = MultiTaskBERTWithPOS(base_model=base_model, pos_vocab_size=pos_vocab_size).to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i4hrar0QxWxl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pythainlp.tag import pos_tag\n",
        "from pythainlp import word_tokenize\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\")\n",
        "\n",
        "# Dummy POS vocabulary (expand with actual vocabulary from your dataset)\n",
        "pos_vocab = {\"NOUN\": 0, \"VERB\": 1, \"ADJ\": 2, \"ADV\": 3, \"PRON\": 4, \"DET\": 5, \"CONJ\": 6, \"NUM\": 7, \"PUNCT\": 8}\n",
        "pos_vocab_size = len(pos_vocab)\n",
        "\n",
        "# Function to tokenize and get POS tags\n",
        "def tokenize_and_pos_tag(text):\n",
        "    tokens = word_tokenize(text, engine=\"newmm\")  # Tokenize\n",
        "    pos_tags = [tag for word, tag in pos_tag(tokens, corpus=\"orchid\")]  # POS tagging using PyThaiNLP\n",
        "    return tokens, pos_tags\n",
        "\n",
        "# Function to convert POS tags to indices\n",
        "def pos_to_indices(pos_tags):\n",
        "    return [pos_vocab.get(tag, pos_vocab[\"NOUN\"]) for tag in pos_tags]  # Default to \"NOUN\" if tag is out of vocabulary\n",
        "\n",
        "# Custom Dataset for Multi-Task Learning\n",
        "class ThaiMultiTaskDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and get POS tags\n",
        "        tokens, pos_tags = tokenize_and_pos_tag(self.texts[idx])\n",
        "        pos_indices = pos_to_indices(pos_tags)\n",
        "\n",
        "        # Encode tokens using the tokenizer\n",
        "        encoding = tokenizer(tokens, is_split_into_words=True, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "        # Directly retrieve tensors\n",
        "        input_ids = encoding['input_ids'].squeeze(0)  # Remove batch dimension\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
        "\n",
        "        # Pad or truncate POS tags to match the max length (128)\n",
        "        pos_labels = torch.tensor(pos_indices[:128] + [0] * (128 - len(pos_indices)))\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'pos_labels': pos_labels\n",
        "        }\n",
        "\n",
        "# Prepare DataLoader\n",
        "texts = df['texts'].tolist()  # Assuming your texts are in a DataFrame column named 'texts'\n",
        "thai_dataset = ThaiMultiTaskDataset(texts)\n",
        "thai_dataloader = DataLoader(thai_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "print(\"DataLoader created with POS labels for Thai dataset.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3YXJcGdyYGM",
        "outputId": "21119ac8-e735-43ba-843b-9084e255efd3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoader created with POS labels for Thai dataset.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "# Initialize Multi-Task Model with POS tagging head\n",
        "multi_task_model = MultiTaskBERTWithPOS(base_model=model, pos_vocab_size=pos_vocab_size).to(device)\n",
        "\n",
        "# Define optimizer and loss functions\n",
        "optimizer = AdamW(multi_task_model.parameters(), lr=2e-5)\n",
        "classification_loss_fn = nn.CrossEntropyLoss()\n",
        "pos_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop with dual objectives\n",
        "num_epochs = 3\n",
        "multi_task_model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in thai_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Use tensors directly as they’re already in the right form\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        pos_labels = batch['pos_labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = multi_task_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Access the outputs using the correct keys\n",
        "        last_hidden_state = outputs[\"last_hidden_state\"]\n",
        "        pos_logits = outputs[\"pos_logits\"]\n",
        "\n",
        "        # Calculate POS tagging loss\n",
        "        pos_loss = pos_loss_fn(pos_logits.view(-1, pos_vocab_size), pos_labels.view(-1))\n",
        "\n",
        "        # Total loss for multi-task\n",
        "        loss = pos_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(thai_dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "TEUO_PQSCx7b",
        "outputId": "12f1d27c-de4c-4f12-f6f2-ecbf00c8d916"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'last_hidden_state'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e5f2423d0023>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_task_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Access the outputs using the correct keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-8ba43ba15952>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels, pos_labels, output_hidden_states)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Access last hidden state directly from dictionary output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlast_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_hidden_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hidden_states'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use .get() to avoid KeyError if hidden_states are not present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0minner_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'last_hidden_state'"
          ]
        }
      ]
    },
    {
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "# Assuming your fine-tuned model is saved in 'model_path'\n",
        "model_path = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "base_model = AutoModel.from_pretrained(model_path, output_hidden_states=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "base_model.to(device)\n",
        "\n",
        "# Define a new model with an additional POS tagging head using the pre-fine-tuned BERT model\n",
        "class MultiTaskBERTWithPOS(nn.Module):\n",
        "    def __init__(self, base_model, pos_vocab_size):\n",
        "        super(MultiTaskBERTWithPOS, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.pos_head = nn.Linear(self.base_model.config.hidden_size, pos_vocab_size)  # POS tagging head\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None, pos_labels=None, output_hidden_states=False):\n",
        "        # Call the base model directly\n",
        "        # Changed model to base_model\n",
        "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=output_hidden_states)\n",
        "\n",
        "        # Access last hidden state directly from dictionary output\n",
        "        last_hidden_state = outputs['last_hidden_state']\n",
        "        hidden_states = outputs.get('hidden_states', None)  # Use .get() to avoid KeyError if hidden_states are not present\n",
        "\n",
        "        # POS tagging logits from the last hidden state\n",
        "        pos_logits = self.pos_head(last_hidden_state)  # Shape: (batch_size, seq_len, pos_vocab_size)\n",
        "\n",
        "        # Return dictionary with all relevant outputs\n",
        "        return {\n",
        "            \"last_hidden_state\": last_hidden_state,\n",
        "            \"pos_logits\": pos_logits,\n",
        "            \"hidden_states\": hidden_states\n",
        "        }\n",
        "\n",
        "# Initialize with your model and specified POS vocabulary size\n",
        "pos_vocab_size = 50  # Adjust based on actual POS vocabulary size\n",
        "multi_task_model = MultiTaskBERTWithPOS(base_model=base_model, pos_vocab_size=pos_vocab_size).to(device)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "TSdz8nJu5dE6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "BRgNufBCetOz"
      },
      "outputs": [],
      "source": [
        "class ThaiMultiTaskDataset(Dataset):\n",
        "    def __init__(self, texts, pos_tags, labels):\n",
        "        self.texts = texts\n",
        "        self.pos_tags = pos_tags\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens, pos_tags = tokenize_and_pos_tag(self.texts[idx])\n",
        "        pos_indices = pos_to_indices(pos_tags)\n",
        "\n",
        "        encoding = tokenizer(tokens, is_split_into_words=True, padding=\"max_length\", truncation=True, max_length=128)\n",
        "        input_ids = torch.tensor(encoding['input_ids'])\n",
        "        attention_mask = torch.tensor(encoding['attention_mask'])\n",
        "        pos_labels = torch.tensor(pos_indices[:128] + [0] * (128 - len(pos_indices)))  # Padding to max length\n",
        "        label = torch.tensor(self.labels[idx])  # Ensure labels are included\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'pos_labels': pos_labels,\n",
        "            'labels': label  # Add labels for hate speech classification\n",
        "        }\n",
        "\n",
        "# Example usage\n",
        "texts = df['texts'].tolist()\n",
        "pos_tags = [pos_to_indices(pos_tag(word_tokenize(text))) for text in texts]\n",
        "labels = df['weak_label'].tolist()  # Ensure this is the hate speech label column\n",
        "\n",
        "thai_dataset = ThaiMultiTaskDataset(texts, pos_tags, labels)\n",
        "thai_dataloader = DataLoader(thai_dataset, batch_size=16, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDxE3OiUeNNe",
        "outputId": "5800f19e-d772-4da7-d252-83c35b1f5252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thai prototypes: tensor([[-0.5080,  0.1452, -0.0776,  ..., -0.0991, -0.9618,  0.0271],\n",
            "        [ 0.1716, -0.0416,  0.7509,  ...,  0.2973,  0.7014, -0.3484]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to extract embeddings for a dataset\n",
        "def extract_embeddings(model, dataloader):\n",
        "    model.eval()\n",
        "    embeddings, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            label = batch['labels'].to(device)\n",
        "\n",
        "            # Get the outputs by calling the model directly\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Adjust this to access the last hidden state appropriately\n",
        "            last_hidden_state = outputs[\"last_hidden_state\"][:, 0, :]  # CLS token embedding\n",
        "            embeddings.append(last_hidden_state)\n",
        "            labels.append(label)\n",
        "\n",
        "    embeddings = torch.cat(embeddings)\n",
        "    labels = torch.cat(labels)\n",
        "    return embeddings, labels\n",
        "\n",
        "\n",
        "# Extract embeddings from the Thai dataset\n",
        "thai_embeddings, thai_labels = extract_embeddings(multi_task_model, thai_dataloader)\n",
        "\n",
        "# Calculate prototypes for each class (hate and non-hate)\n",
        "def calculate_prototypes(embeddings, labels, num_classes=2):\n",
        "    prototypes = []\n",
        "    for label in range(num_classes):\n",
        "        class_embeddings = embeddings[labels == label]\n",
        "        prototype = class_embeddings.mean(dim=0)\n",
        "        prototypes.append(prototype)\n",
        "    return torch.stack(prototypes)\n",
        "\n",
        "thai_prototypes = calculate_prototypes(thai_embeddings, thai_labels)\n",
        "print(\"Thai prototypes:\", thai_prototypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iy7cx5Y8lXzU",
        "outputId": "d8844a11-6ac5-462f-bc55-eb554c07e08f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 10/200, Meta-Loss: 0.5\n",
            "Episode 20/200, Meta-Loss: 0.5\n",
            "Episode 30/200, Meta-Loss: 0.5\n",
            "Episode 40/200, Meta-Loss: 0.5\n",
            "Episode 50/200, Meta-Loss: 0.5\n",
            "Episode 60/200, Meta-Loss: 0.5\n",
            "Episode 70/200, Meta-Loss: 0.5\n",
            "Episode 80/200, Meta-Loss: 1.1078805923461914\n",
            "Episode 90/200, Meta-Loss: 0.5\n",
            "Episode 100/200, Meta-Loss: 0.5\n",
            "Episode 110/200, Meta-Loss: 1.103718638420105\n",
            "Episode 120/200, Meta-Loss: 0.5\n",
            "Episode 130/200, Meta-Loss: 0.5\n",
            "Episode 140/200, Meta-Loss: 0.5\n",
            "Episode 150/200, Meta-Loss: 0.5\n",
            "Episode 160/200, Meta-Loss: 0.5\n",
            "Episode 170/200, Meta-Loss: 0.5\n",
            "Episode 180/200, Meta-Loss: 0.5\n",
            "Episode 190/200, Meta-Loss: 0.5\n",
            "Episode 200/200, Meta-Loss: 0.5\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.optim import RMSprop\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# Updated hyperparameters\n",
        "meta_learning_rate = 1e-4\n",
        "support_set_size = 64\n",
        "query_set_size = 32\n",
        "num_episodes = 200\n",
        "temperature = 0.3  # Reduced temperature for sharper separation\n",
        "margin = 0.5  # Reduced margin in contrastive loss\n",
        "\n",
        "# Initialize optimizer\n",
        "meta_optimizer = RMSprop(multi_task_model.parameters(), lr=meta_learning_rate)\n",
        "\n",
        "# Function to compute prototypes\n",
        "def compute_prototypes(embeddings, labels):\n",
        "    unique_labels = torch.unique(labels)\n",
        "    prototypes = []\n",
        "    for label in unique_labels:\n",
        "        class_embeddings = embeddings[labels == label]\n",
        "        class_prototype = class_embeddings.mean(dim=0)\n",
        "        prototypes.append(class_prototype)\n",
        "    return torch.stack(prototypes)\n",
        "\n",
        "# Function for contrastive loss\n",
        "def contrastive_loss(embeddings, prototypes, labels, margin=margin):\n",
        "    positive_distances = torch.norm(embeddings - prototypes[labels], dim=1)\n",
        "    negative_distances = torch.min(torch.norm(embeddings.unsqueeze(1) - prototypes, dim=2), dim=1)[0]\n",
        "    return F.relu(margin + positive_distances - negative_distances).mean()\n",
        "\n",
        "# Token dropout function\n",
        "def add_token_dropout(embeddings, dropout_rate=0.1):\n",
        "    mask = torch.bernoulli(torch.full(embeddings.shape, 1 - dropout_rate)).to(embeddings.device)\n",
        "    return embeddings * mask\n",
        "\n",
        "# Meta-learning loop\n",
        "for episode in range(num_episodes):\n",
        "    support_indices = np.random.choice(len(thai_labels), size=support_set_size, replace=False)\n",
        "    query_indices = np.random.choice(len(thai_labels), size=query_set_size, replace=False)\n",
        "\n",
        "    support_embeddings = thai_embeddings[support_indices].clone().detach().requires_grad_(True)\n",
        "    support_labels = thai_labels[support_indices]\n",
        "    query_embeddings = thai_embeddings[query_indices].clone().detach().requires_grad_(True)\n",
        "    query_labels = thai_labels[query_indices]\n",
        "\n",
        "    # Apply token dropout\n",
        "    support_embeddings = add_token_dropout(support_embeddings, dropout_rate=0.1)\n",
        "\n",
        "    # Compute prototypes\n",
        "    prototypes = compute_prototypes(support_embeddings, support_labels)\n",
        "\n",
        "    # Distance calculation with temperature scaling\n",
        "    distances = 1 - F.cosine_similarity(query_embeddings.unsqueeze(1), prototypes.unsqueeze(0), dim=2) / temperature\n",
        "    logits = -distances\n",
        "\n",
        "    # Calculate loss with adjusted contrastive loss and gradient penalty\n",
        "    contrastive = contrastive_loss(query_embeddings, prototypes, query_labels)\n",
        "    grad = torch.autograd.grad(contrastive, query_embeddings, create_graph=True)[0]\n",
        "    grad_penalty = (grad.norm(2, dim=1) ** 2).mean() * 0.05  # Reduced penalty weight\n",
        "    loss = contrastive + grad_penalty\n",
        "\n",
        "    # Optimization step\n",
        "    meta_optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    meta_optimizer.step()\n",
        "\n",
        "    if (episode + 1) % 10 == 0:\n",
        "        print(f\"Episode {episode + 1}/{num_episodes}, Meta-Loss: {loss.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EVZZI4Cocz7",
        "outputId": "043ed8e6-9fa2-4cc8-ca47-192b69828948",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model and related data saved to /content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the directory to save the model and create it if it doesn't exist\n",
        "save_directory = '/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes'\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "# Save the model state dictionary\n",
        "torch.save(multi_task_model.state_dict(), f\"{save_directory}/cross_lingual_meta_learning_model_state.pth\")\n",
        "\n",
        "# Save additional data (prototypes and other components if needed)\n",
        "torch.save({\n",
        "    'prototypes': prototypes,  # Save the last computed prototypes\n",
        "    'meta_optimizer_state': meta_optimizer.state_dict()  # Save optimizer state if needed for further training\n",
        "}, f\"{save_directory}/cross_lingual_meta_learning_additional_data.pth\")\n",
        "\n",
        "print(f\"Model and related data saved to {save_directory}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTkYaE8rrEM3",
        "outputId": "8ffc1ce0-2698-4a3e-8e60-a045da9fe2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lao Keywords: ['ຄວາຍ', 'ບໍ່ສັດຕະສົງ', 'ຫມາ', 'ຕໍແຫລ', 'ໂງ່', 'ຕ່ໍາ', 'ບ້າ', 'ຫມາຍຕິກ', 'ຊົ່ວ', 'ກະເສີມ', 'ຄວາມຊົ່ວ', 'ປັກຫິນດອນ', 'ໂກງ', 'ສັດ', 'ອອກຄໍາຄິດເຫັນ', 'ລັກຊະນະ', 'ຫອຍfish', 'ລັງແສງ', 'ປວກ', 'ຂີ້ຄ້ານ', 'ຂີ້ເຫຍື້ອ', 'ກັມ', 'ເສັ້ນປະສາດ', 'ດອກ', 'ສົ້ນ', 'ດິນແຮ່', 'ພົນໄພ່', 'ສິ່ງທີ່ ', 'ຫອກ', 'ສາມາດ', 'ຂ້າ', 'ອັດຕາສ່ວນ', 'ຂີ້ຊ່ານ', 'ນ້ໍາເຂີນ', 'ກະຫລີ່', 'ອອກຄໍາຄິດເຫັນ', 'ເວນແຢກ', 'ໄກ່', 'ຂີ້ປິບ', 'ເສຽກໍາ', 'ສັດທີ່', 'ຊັກຊ້າ', 'ແຮດ/ໝາ', 'ຄວາມຊົ່ວ']\n",
            "Khmer Keywords: ['រកបី', 'មិនស្មោះត្រង់', 'ឆ្កេ', 'កាមតេ', 'ផ្លីផ្លើ', 'តាប', 'ឈ្កូ', 'ចៃ', 'អារកក់', 'ការីឈី', 'ដេលក្ផានសីលធ៍ម', 'ផាប', 'ថ្ពាល់', 'សតវ', 'រមាំn', 'ចរិតរបា', 'សែលហ្វី', 'តារុងរឿង', 'កន្ដ្យេវ', 'scurlilog', 'សមនល់បិផ្ទហបាយ', 'វាសនា', 'សរសៃរបសាត', 'ផ្កា', 'កេងចើង', 'ការរបយ័បន៍', 'ការធេវីបេកចិត៍', 'អ្វីដែល heck នេះ!', 'លមបេង', 'អាច', 'សម្លាប់', 'សមាមារត', 'របសផាប', 'ញិរបុត', 'ស្លត់', 'រមាំn', 'កសំណឹក', 'សាកសម', 'កមនិតឥតខ្លឹមសារ', 'ផាបល្អ', 'ចាហតុរ', 'បានថយចុះ', 'សតវរមាស', 'ដេលក្ផានសីលធ៍ម']\n",
            "Shan Keywords: ['ကြှဲ', 'မရိုးမသားဖြစ်လိမ့်မည်', 'ခေှး', 'အဖစ်', 'အလွန်ထိုင်းသော', 'နိမ့်သော', 'စိတ်နောက်သော', 'ရှပိုး', 'ဆိုးသော', 'ဟင်း', 'ဆိုးသော', 'pimp', 'ချမ်းပေြာ', 'တိရစာ္ဆန်', 'သေတာပဲ', 'ရို', 'ခွံ', 'မထိခိုက်သော', 'ခြကောင်', 'ကြီးစွာသော', 'မီးဖိုအမိှုက်', 'ကြမ္မာ', 'အာရုံကေြာ', 'ပန်း', 'ခေြဖနောင့်', 'mincing', 'proletarian အဘိဓါန်မှလှိုက်လှဲစွာကြိုဆိုပါသည်', 'အဘယ်အရာကို heck!', 'လှံတံ', 'နိုင်နိုင်', 'သတ်ဖြတ်', 'အချိုးအစား', 'အတူပင်ခြင်း', 'မိန်းမဂျင်လင်း', 'slut', 'သေတာပဲ', 'ကျန်ရှိသော', 'ကြက်', 'အမှုိက်', 'နာကျင်ခြင်း', 'ကေျာ်ရေှ', 'နောက်ကျ', 'ကြံ့ကောင်', 'ဆိုးသော']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV containing the hate keywords for each language\n",
        "keywords_path = '/content/Toxic_Words_translations.csv'  # Replace with your actual file path\n",
        "keywords_df = pd.read_csv(keywords_path)\n",
        "\n",
        "# Extract keywords for each language as lists, removing any NaN values\n",
        "keywords_lao = keywords_df['Lao'].dropna().tolist()\n",
        "keywords_khmer = keywords_df['Khmer'].dropna().tolist()\n",
        "keywords_shan = keywords_df['Shan'].dropna().tolist()\n",
        "\n",
        "# Verify the keywords were loaded correctly\n",
        "print(\"Lao Keywords:\", keywords_lao)\n",
        "print(\"Khmer Keywords:\", keywords_khmer)\n",
        "print(\"Shan Keywords:\", keywords_shan)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nP4k_U3NrjcA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "# Generating synthetic few-shot datasets using keywords\n",
        "def generate_few_shot_dataset(keywords, num_samples=10, non_hate_text=\"this is a neutral sentence\"):\n",
        "    \"\"\"Generate a few-shot dataset using keywords for hate and a generic non-hate sentence.\"\"\"\n",
        "    dataset = []\n",
        "    # Positive samples using keywords\n",
        "    for _ in range(num_samples // 2):\n",
        "        text = random.choice(keywords)\n",
        "        dataset.append((text, 1))  # Label 1 for hate\n",
        "    # Negative samples\n",
        "    for _ in range(num_samples // 2):\n",
        "        dataset.append((non_hate_text, 0))  # Label 0 for non-hate\n",
        "    return dataset\n",
        "\n",
        "# Generating few-shot datasets for each language\n",
        "few_shot_data_lao = generate_few_shot_dataset(keywords_lao)\n",
        "few_shot_data_khmer = generate_few_shot_dataset(keywords_khmer)\n",
        "few_shot_data_shan = generate_few_shot_dataset(keywords_shan)\n",
        "\n",
        "# Wrap into DataLoader for batch processing\n",
        "class FewShotDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text, label = self.data[idx]\n",
        "        encoding = self.tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", max_length=128, truncation=True)\n",
        "        input_ids = encoding[\"input_ids\"].squeeze()\n",
        "        attention_mask = encoding[\"attention_mask\"].squeeze()\n",
        "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"label\": torch.tensor(label)}\n",
        "\n",
        "\n",
        "# Load the tokenizer (use the name of your pre-trained model)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\")  # Replace with your specific model if different\n",
        "batch_size = 4\n",
        "\n",
        "few_shot_loader_lao = DataLoader(FewShotDataset(few_shot_data_lao, tokenizer), batch_size=batch_size)\n",
        "few_shot_loader_khmer = DataLoader(FewShotDataset(few_shot_data_khmer, tokenizer), batch_size=batch_size)\n",
        "few_shot_loader_shan = DataLoader(FewShotDataset(few_shot_data_shan, tokenizer), batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "YSC3tyJIrv7p"
      },
      "outputs": [],
      "source": [
        "def update_prototypes_with_few_shot(model, dataloader, initial_prototypes, embedding_dim=768):\n",
        "    \"\"\"Refine prototypes using few-shot data.\"\"\"\n",
        "    model.eval()\n",
        "    refined_prototypes = initial_prototypes.clone()\n",
        "\n",
        "    num_classes = initial_prototypes.shape[0]\n",
        "    refined_prototypes = refined_prototypes.to(device)\n",
        "    all_embeddings, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Attempt to use pooled output if available, otherwise use [CLS] token embedding\n",
        "            if 'pooler_output' in outputs and outputs['pooler_output'] is not None:\n",
        "                embeddings = outputs['pooler_output']\n",
        "            elif 'last_hidden_state' in outputs:\n",
        "                # Use [CLS] token (first token) from last hidden state as a fallback\n",
        "                embeddings = outputs['last_hidden_state'][:, 0, :]  # Shape: (batch_size, embedding_dim)\n",
        "            else:\n",
        "                raise ValueError(\"Neither 'pooler_output' nor 'last_hidden_state' found in model outputs\")\n",
        "\n",
        "            if embeddings.shape[1] != embedding_dim:\n",
        "                raise ValueError(f\"Embedding dimension mismatch. Expected {embedding_dim}, got {embeddings.shape[1]}\")\n",
        "\n",
        "            all_embeddings.append(embeddings)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    # Concatenate all embeddings and labels\n",
        "    all_embeddings = torch.cat(all_embeddings)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    # Update prototypes based on embeddings\n",
        "    for label in range(num_classes):\n",
        "        class_embeddings = all_embeddings[all_labels == label]\n",
        "        if class_embeddings.shape[0] > 0:  # Check that there are embeddings for this class\n",
        "            refined_prototypes[label] = class_embeddings.mean(dim=0)\n",
        "\n",
        "    return refined_prototypes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update prototypes for each language\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "embedding_dim = 768  # Expected embedding dimension\n",
        "\n",
        "# Ensure prototypes tensor matches the expected size (e.g., 2 classes for hate/non-hate, 768 embedding size)\n",
        "prototypes = torch.zeros((2, embedding_dim), device=device)\n",
        "\n",
        "updated_prototypes_lao = update_prototypes_with_few_shot(multi_task_model, few_shot_loader_lao, prototypes, embedding_dim)\n",
        "updated_prototypes_khmer = update_prototypes_with_few_shot(multi_task_model, few_shot_loader_khmer, prototypes, embedding_dim)\n",
        "updated_prototypes_shan = update_prototypes_with_few_shot(multi_task_model, few_shot_loader_shan, prototypes, embedding_dim)\n"
      ],
      "metadata": {
        "id": "QVxyN-s9OduC"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmN_Iqkr8opD",
        "outputId": "e4ec6af8-55c9-4d79-a500-7b17a6cc071c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-shot fine-tuning complete and refined prototypes saved.\n"
          ]
        }
      ],
      "source": [
        "# Save updated prototypes\n",
        "torch.save({\n",
        "    'prototypes_lao': updated_prototypes_lao,\n",
        "    'prototypes_khmer': updated_prototypes_khmer,\n",
        "    'prototypes_shan': updated_prototypes_shan\n",
        "}, \"/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes/updated_prototypes_few_shot.pth\")\n",
        "\n",
        "print(\"Few-shot fine-tuning complete and refined prototypes saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XuswlMxq9VI0",
        "outputId": "c78d5e22-b6dd-4c8b-932a-b16ee28a502b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-4aa89a1aaf21>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  multi_task_model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "<ipython-input-49-4aa89a1aaf21>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  updated_prototypes = torch.load(prototype_path)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "\n",
        "# Load the saved model state dictionary\n",
        "model_path = '/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes/cross_lingual_meta_learning_model_state.pth'\n",
        "multi_task_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "multi_task_model.to(device)\n",
        "multi_task_model.eval()\n",
        "\n",
        "# Load updated prototypes\n",
        "prototype_path = '/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes/updated_prototypes_few_shot.pth'\n",
        "updated_prototypes = torch.load(prototype_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YvilE4UpCK_u",
        "outputId": "f675cc30-3a67-4af5-8c18-9db8585226b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Sample:\n",
            "                                                 text  label\n",
            "0  ไป จอง มา แล้ วนา จา   mitsubishi   attrage   ...    NaN\n",
            "1  เปิด ศักราช ใหม่ !   นายกฯ   แถลงข่าว ก่อน การ...    NaN\n",
            "2                      บัตรสมาชิก ลด ได้ อีก ไหม คับ    NaN\n",
            "3                          สนใจ   new   mazda 2 ครับ    NaN\n",
            "4                                                 😍😍    NaN\n",
            "Post-Cleaning Data Sample:\n",
            "                                                 text  label\n",
            "0  ไป จอง มา แล้ วนา จา mitsubishi attrage ได้ หล...    NaN\n",
            "1  เปิด ศักราช ใหม่ ! นายกฯ แถลงข่าว ก่อน การแข่ง...    NaN\n",
            "2                      บัตรสมาชิก ลด ได้ อีก ไหม คับ    NaN\n",
            "3                              สนใจ new mazda 2 ครับ    NaN\n",
            "4                                                 😍😍    NaN\n",
            "Post-Truncating Data Sample:\n",
            "                                                 text  label\n",
            "0  ไป จอง มา แล้ วนา จา mitsubishi attrage ได้ หล...    NaN\n",
            "1  เปิด ศักราช ใหม่ ! นายกฯ แถลงข่าว ก่อน การแข่ง...    NaN\n",
            "2                      บัตรสมาชิก ลด ได้ อีก ไหม คับ    NaN\n",
            "3                              สนใจ new mazda 2 ครับ    NaN\n",
            "4                                                 😍😍    NaN\n",
            "Initial Data Sample:\n",
            "                                                 text  label\n",
            "0                        ຍົນຣົບຣັສເຊັຍບໍ່ມີ  ບໍ່ທ່ານ    NaN\n",
            "1  ຕ້ອງທຳແບບນີ້ລະ ດີທີ່ສຸດ​ ຈະໝົດພວກອັບປີໄປຈາກປະເ...    NaN\n",
            "2                                               ສາທຸ    NaN\n",
            "3                                       ເບິ່ງຫນ້າແດ່    NaN\n",
            "4                               ຈັບໄດ້ຕອ້ງປະຫານຊິວິດ    NaN\n",
            "Post-Cleaning Data Sample:\n",
            "                                                 text  label\n",
            "0                         ຍົນຣົບຣັສເຊັຍບໍ່ມີ ບໍ່ທ່ານ    NaN\n",
            "1  ຕ້ອງທຳແບບນີ້ລະ ດີທີ່ສຸດ​ ຈະໝົດພວກອັບປີໄປຈາກປະເ...    NaN\n",
            "2                                               ສາທຸ    NaN\n",
            "3                                       ເບິ່ງຫນ້າແດ່    NaN\n",
            "4                               ຈັບໄດ້ຕອ້ງປະຫານຊິວິດ    NaN\n",
            "Post-Truncating Data Sample:\n",
            "                                                 text  label\n",
            "0                         ຍົນຣົບຣັສເຊັຍບໍ່ມີ ບໍ່ທ່ານ    NaN\n",
            "1  ຕ້ອງທຳແບບນີ້ລະ ດີທີ່ສຸດ​ ຈະໝົດພວກອັບປີໄປຈາກປະເ...    NaN\n",
            "2                                               ສາທຸ    NaN\n",
            "3                                       ເບິ່ງຫນ້າແດ່    NaN\n",
            "4                               ຈັບໄດ້ຕອ້ງປະຫານຊິວິດ    NaN\n",
            "Initial Data Sample:\n",
            "                                                 text  label\n",
            "0  ထွမ်ႇယဝ်ႉၵိၼ်ၸႂ်​တေႉၵႂၢမ်းႁူဝ်ၼႆႉ ၼမ်ႉတႃယိုင်ႈ...    NaN\n",
            "1                                 လီထွမ်ႇတေႉယဝ်ႉၶႃႈ။    NaN\n",
            "2                                             ၶိုၵ်ႉ    NaN\n",
            "3            လုၵ်ႈလၢၼ်တႆးလုၵ်ႈႁုၼ်ႈမႂ်ႇႁဝ်းမိူဝ်းၼႃႈ    NaN\n",
            "4  မႂ်ႇသုင်ၶႃႈၶႃႈႁဝ်းလႆႈႁၼ်ၸုမ်းၶဝ်ႇၽူႈတွႆႇႁွၵ်ႈမ...    NaN\n",
            "Post-Cleaning Data Sample:\n",
            "                                                 text  label\n",
            "0  ထွမ်ႇယဝ်ႉၵိၼ်ၸႂ်​တေႉၵႂၢမ်းႁူဝ်ၼႆႉ ၼမ်ႉတႃယိုင်ႈ...    NaN\n",
            "1                                 လီထွမ်ႇတေႉယဝ်ႉၶႃႈ။    NaN\n",
            "2                                             ၶိုၵ်ႉ    NaN\n",
            "3            လုၵ်ႈလၢၼ်တႆးလုၵ်ႈႁုၼ်ႈမႂ်ႇႁဝ်းမိူဝ်းၼႃႈ    NaN\n",
            "4  မႂ်ႇသုင်ၶႃႈၶႃႈႁဝ်းလႆႈႁၼ်ၸုမ်းၶဝ်ႇၽူႈတွႆႇႁွၵ်ႈမ...    NaN\n",
            "Post-Truncating Data Sample:\n",
            "                                                 text  label\n",
            "0  ထွမ်ႇယဝ်ႉၵိၼ်ၸႂ်​တေႉၵႂၢမ်းႁူဝ်ၼႆႉ ၼမ်ႉတႃယိုင်ႈ...    NaN\n",
            "1                                 လီထွမ်ႇတေႉယဝ်ႉၶႃႈ။    NaN\n",
            "2                                             ၶိုၵ်ႉ    NaN\n",
            "3            လုၵ်ႈလၢၼ်တႆးလုၵ်ႈႁုၼ်ႈမႂ်ႇႁဝ်းမိူဝ်းၼႃႈ    NaN\n",
            "4  မႂ်ႇသုင်ၶႃႈၶႃႈႁဝ်းလႆႈႁၼ်ၸုမ်းၶဝ်ႇၽူႈတွႆႇႁွၵ်ႈမ...    NaN\n",
            "Final Thai Data Sample:\n",
            "                                                 text  label\n",
            "0  ไป จอง มา แล้ วนา จา mitsubishi attrage ได้ หล...    NaN\n",
            "1  เปิด ศักราช ใหม่ ! นายกฯ แถลงข่าว ก่อน การแข่ง...    NaN\n",
            "2                      บัตรสมาชิก ลด ได้ อีก ไหม คับ    NaN\n",
            "3                              สนใจ new mazda 2 ครับ    NaN\n",
            "4                                                 😍😍    NaN\n",
            "\n",
            "Final Lao Data Sample:\n",
            "                                                 text  label\n",
            "0                         ຍົນຣົບຣັສເຊັຍບໍ່ມີ ບໍ່ທ່ານ    NaN\n",
            "1  ຕ້ອງທຳແບບນີ້ລະ ດີທີ່ສຸດ​ ຈະໝົດພວກອັບປີໄປຈາກປະເ...    NaN\n",
            "2                                               ສາທຸ    NaN\n",
            "3                                       ເບິ່ງຫນ້າແດ່    NaN\n",
            "4                               ຈັບໄດ້ຕອ້ງປະຫານຊິວິດ    NaN\n",
            "\n",
            "Final Shan Data Sample:\n",
            "                                                 text  label\n",
            "0  ထွမ်ႇယဝ်ႉၵိၼ်ၸႂ်​တေႉၵႂၢမ်းႁူဝ်ၼႆႉ ၼမ်ႉတႃယိုင်ႈ...    NaN\n",
            "1                                 လီထွမ်ႇတေႉယဝ်ႉၶႃႈ။    NaN\n",
            "2                                             ၶိုၵ်ႉ    NaN\n",
            "3            လုၵ်ႈလၢၼ်တႆးလုၵ်ႈႁုၼ်ႈမႂ်ႇႁဝ်းမိူဝ်းၼႃႈ    NaN\n",
            "4  မႂ်ႇသုင်ၶႃႈၶႃႈႁဝ်းလႆႈႁၼ်ၸုမ်းၶဝ်ႇၽူႈတွႆႇႁွၵ်ႈမ...    NaN\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Define maximum character length\n",
        "max_length = 200\n",
        "\n",
        "# Load the datasets\n",
        "thai_df = pd.read_csv('/content/thai_test_data.csv')\n",
        "lao_df = pd.read_csv('/content/lao_test_data.csv')\n",
        "shan_df = pd.read_csv('/content/shan_test_data.csv')\n",
        "\n",
        "# Function to remove URLs and special characters, and clean text minimally\n",
        "def basic_clean_text(text):\n",
        "    text = re.sub(r'http\\S+|www.\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "    return text\n",
        "\n",
        "# Function to truncate text to max length\n",
        "def truncate_text(text, max_length):\n",
        "    return text[:max_length] if len(text) > max_length else text\n",
        "\n",
        "# Apply minimal cleaning and truncating to each dataset without dropping NaN labels\n",
        "def preprocess_dataframe_basic(df):\n",
        "    print(\"Initial Data Sample:\\n\", df.head())  # Initial data sample\n",
        "    df['text'] = df['text'].astype(str).apply(basic_clean_text)\n",
        "    print(\"Post-Cleaning Data Sample:\\n\", df.head())  # After cleaning\n",
        "    df['text'] = df['text'].apply(lambda x: truncate_text(x, max_length))\n",
        "    print(\"Post-Truncating Data Sample:\\n\", df.head())  # After truncating\n",
        "    return df\n",
        "\n",
        "# Preprocess each dataframe without filtering out NaN labels\n",
        "thai_df_cleaned = preprocess_dataframe_basic(thai_df)\n",
        "lao_df_cleaned = preprocess_dataframe_basic(lao_df)\n",
        "shan_df_cleaned = preprocess_dataframe_basic(shan_df)\n",
        "\n",
        "# Final samples for verification\n",
        "print(\"Final Thai Data Sample:\\n\", thai_df_cleaned.head())\n",
        "print(\"\\nFinal Lao Data Sample:\\n\", lao_df_cleaned.head())\n",
        "print(\"\\nFinal Shan Data Sample:\\n\", shan_df_cleaned.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load the toxic keywords from the CSV file\n",
        "keywords_df = pd.read_csv('/content/Toxic_Words_translations.csv')\n",
        "\n",
        "# Extract keywords for each language\n",
        "def extract_keywords_for_language(df, language_column):\n",
        "    # Drop NaN values and convert to a list\n",
        "    keywords = df[language_column].dropna().tolist()\n",
        "    # Ensure all keywords are strings\n",
        "    keywords = [str(keyword) for keyword in keywords]\n",
        "    return keywords\n",
        "\n",
        "# Extract keywords for each language\n",
        "thai_toxic_keywords = extract_keywords_for_language(keywords_df, 'Thai')\n",
        "lao_toxic_keywords = extract_keywords_for_language(keywords_df, 'Lao')\n",
        "shan_toxic_keywords = extract_keywords_for_language(keywords_df, 'Shan')\n",
        "\n",
        "# Function to label data based on toxic keywords\n",
        "def label_data_using_keywords(df, toxic_keywords):\n",
        "    # Compile regex pattern for faster matching\n",
        "    pattern = re.compile(r'\\b(' + '|'.join(map(re.escape, toxic_keywords)) + r')\\b', re.IGNORECASE)\n",
        "\n",
        "    # Function to check if text contains any toxic keywords\n",
        "    def check_toxic(text):\n",
        "        if pattern.search(text):\n",
        "            return 1  # Hate\n",
        "        else:\n",
        "            return 0  # Non-hate\n",
        "\n",
        "    # Apply the function to the 'text' column\n",
        "    df['label'] = df['text'].apply(check_toxic)\n",
        "    return df\n",
        "\n",
        "# Apply labeling to each dataset\n",
        "thai_df_labeled = label_data_using_keywords(thai_df_cleaned, thai_toxic_keywords)\n",
        "lao_df_labeled = label_data_using_keywords(lao_df_cleaned, lao_toxic_keywords)\n",
        "shan_df_labeled = label_data_using_keywords(shan_df_cleaned, shan_toxic_keywords)\n",
        "\n",
        "# Verify the new label distribution\n",
        "print(\"Thai Data Label Distribution:\\n\", thai_df_labeled['label'].value_counts())\n",
        "print(\"\\nLao Data Label Distribution:\\n\", lao_df_labeled['label'].value_counts())\n",
        "print(\"\\nShan Data Label Distribution:\\n\", shan_df_labeled['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EQv2DWraNIVi",
        "outputId": "4daf4926-aa1d-426b-c341-890caab0240b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thai Data Label Distribution:\n",
            " label\n",
            "0    23623\n",
            "1    17943\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Lao Data Label Distribution:\n",
            " label\n",
            "0    80\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Shan Data Label Distribution:\n",
            " label\n",
            "0    74\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to balance the dataset using oversampling\n",
        "def oversample_dataset(df):\n",
        "    # Separate minority and majority classes\n",
        "    hate_df = df[df['label'] == 1]\n",
        "    non_hate_df = df[df['label'] == 0]\n",
        "\n",
        "    # Calculate the number of samples in each class\n",
        "    num_hate = len(hate_df)\n",
        "    num_non_hate = len(non_hate_df)\n",
        "\n",
        "    # Check if either class is empty\n",
        "    if num_hate == 0 or num_non_hate == 0:\n",
        "        print(\"Warning: One of the classes is empty. Returning the original dataset.\")\n",
        "        return df.copy()\n",
        "\n",
        "    # Determine the class with the maximum samples\n",
        "    max_samples = max(num_hate, num_non_hate)\n",
        "\n",
        "    # Oversample the minority class\n",
        "    if num_hate < num_non_hate:\n",
        "        hate_df_oversampled = hate_df.sample(n=max_samples, replace=True, random_state=42)\n",
        "        non_hate_df_oversampled = non_hate_df\n",
        "    elif num_non_hate < num_hate:\n",
        "        non_hate_df_oversampled = non_hate_df.sample(n=max_samples, replace=True, random_state=42)\n",
        "        hate_df_oversampled = hate_df\n",
        "    else:\n",
        "        # Classes are already balanced\n",
        "        oversampled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "        return oversampled_df\n",
        "\n",
        "    # Combine and shuffle the dataset\n",
        "    oversampled_df = pd.concat([hate_df_oversampled, non_hate_df_oversampled]).sample(\n",
        "        frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    return oversampled_df\n",
        "\n",
        "# Apply the oversampling function to your datasets\n",
        "thai_df_oversampled = oversample_dataset(thai_df_labeled)\n",
        "lao_df_oversampled = oversample_dataset(lao_df_labeled)\n",
        "shan_df_oversampled = oversample_dataset(shan_df_labeled)\n",
        "\n",
        "# Verify the new label distribution\n",
        "print(\"Thai Data Label Distribution:\\n\", thai_df_oversampled['label'].value_counts())\n",
        "print(\"\\nLao Data Label Distribution:\\n\", lao_df_oversampled['label'].value_counts())\n",
        "print(\"\\nShan Data Label Distribution:\\n\", shan_df_oversampled['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zFWEi7QR-AJ7",
        "outputId": "cee73879-23c4-4426-cef8-3edbe337deb8"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: One of the classes is empty. Returning the original dataset.\n",
            "Thai Data Label Distribution:\n",
            " label\n",
            "0    23623\n",
            "1    23623\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Lao Data Label Distribution:\n",
            " label\n",
            "0    80\n",
            "1    80\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Shan Data Label Distribution:\n",
            " label\n",
            "0    74\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dREltNOnG5Yq",
        "outputId": "d499ce2d-c946-4671-f5b6-6c8d58a571c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders created for Thai, Lao, and Shan datasets.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize tokenizer (ensure it matches the model you fine-tuned)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\")\n",
        "\n",
        "class LanguageTestDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=200):\n",
        "        self.texts = texts\n",
        "        self.labels = labels.fillna(0).astype(int)  # Convert NaN to 0 for non-hate\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Indented block for __getitem__ method\n",
        "        text = self.texts.iloc[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long)  # Changed 'label' to 'labels'\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create dataset and dataloader for each language\n",
        "def create_dataloader(df, tokenizer, batch_size=8):\n",
        "    dataset = LanguageTestDataset(df['text'], df['label'], tokenizer)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "thai_dataloader = create_dataloader(thai_df_cleaned, tokenizer)\n",
        "lao_dataloader = create_dataloader(lao_df_cleaned, tokenizer)\n",
        "shan_dataloader = create_dataloader(shan_df_cleaned, tokenizer)\n",
        "\n",
        "\n",
        "print(\"DataLoaders created for Thai, Lao, and Shan datasets.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "collapsed": true,
        "id": "rMY8gbYIIAGJ",
        "outputId": "a2215932-ba14-41c4-a07a-3b0da5230143"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'load_state_dict'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-4aa89a1aaf21>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the saved model state dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes/cross_lingual_meta_learning_model_state.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmulti_task_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmulti_task_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmulti_task_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'load_state_dict'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "\n",
        "# Load the saved model state dictionary\n",
        "model_path = '/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes/cross_lingual_meta_learning_model_state.pth'\n",
        "multi_task_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "multi_task_model.to(device)\n",
        "multi_task_model.eval()\n",
        "\n",
        "# Load updated prototypes\n",
        "prototype_path = '/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes/updated_prototypes_few_shot.pth'\n",
        "updated_prototypes = torch.load(prototype_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_prototypes_with_weights(embeddings, labels, num_classes=2):\n",
        "    \"\"\"Calculate weighted prototypes for each class to emphasize core samples.\"\"\"\n",
        "    prototypes = []\n",
        "    for label in range(num_classes):\n",
        "        class_embeddings = embeddings[labels == label]\n",
        "        if class_embeddings.shape[0] > 0:\n",
        "            # Center the embeddings and compute distances\n",
        "            center = class_embeddings.mean(dim=0, keepdim=True)\n",
        "            distances = torch.norm(class_embeddings - center, dim=1)\n",
        "\n",
        "            # Calculate weights: closer embeddings have higher weights\n",
        "            weights = 1 / (distances + 1e-6)\n",
        "            weighted_embeddings = class_embeddings * weights.unsqueeze(1)\n",
        "            weighted_prototype = weighted_embeddings.sum(dim=0) / weights.sum()\n",
        "            prototypes.append(weighted_prototype)\n",
        "        else:\n",
        "            prototypes.append(torch.zeros(embeddings.shape[1]))  # Handle empty classes\n",
        "\n",
        "    return torch.stack(prototypes)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q5-thp3gZyd0"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import torch\n",
        "\n",
        "def evaluate_with_cosine_similarity(model, dataloader, prototypes):\n",
        "    \"\"\"Evaluate using cosine similarity to prototypes.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    prototypes = prototypes.to(device)  # Ensure prototypes are on the correct device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            label = batch['labels'].to(device)  # Changed 'label' to 'labels'\n",
        "\n",
        "            # Get embeddings from the model\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Handle different output structures\n",
        "            if hasattr(outputs, 'last_hidden_state'):\n",
        "                last_hidden_state = outputs.last_hidden_state\n",
        "            elif isinstance(outputs, tuple):\n",
        "                last_hidden_state = outputs[0]  # For models that return tuples\n",
        "            else:\n",
        "                raise ValueError(\"Unexpected model output structure.\")\n",
        "\n",
        "            embeddings = last_hidden_state[:, 0, :]  # Use [CLS] token representation\n",
        "\n",
        "            # Calculate cosine similarity to prototypes\n",
        "            similarities = torch.nn.functional.cosine_similarity(\n",
        "                embeddings.unsqueeze(1), prototypes.unsqueeze(0), dim=2\n",
        "            )\n",
        "            preds = torch.argmax(similarities, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(label.cpu().numpy())\n",
        "\n",
        "    # Calculate accuracy and F1-score\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    report = classification_report(all_labels, all_preds, target_names=[\"Non-hate\", \"Hate\"])\n",
        "\n",
        "    return accuracy, macro_f1, report\n"
      ],
      "metadata": {
        "id": "52i9qC6BfkIR"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_embeddings(model, dataloader):\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            batch_labels = batch['labels'].to(device)  # Changed 'label' to 'labels'\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "            # Assuming you use the last hidden state as embeddings\n",
        "            hidden_states = outputs.hidden_states[-1][:, 0, :]  # Use the [CLS] token representation\n",
        "            embeddings.append(hidden_states.cpu())\n",
        "            labels.append(batch_labels.cpu())\n",
        "    embeddings = torch.cat(embeddings)\n",
        "    labels = torch.cat(labels)\n",
        "    return embeddings, labels\n"
      ],
      "metadata": {
        "id": "Tc-8cXRY_It-"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize tokenizer (ensure it matches the model you fine-tuned)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\")\n",
        "\n",
        "# Define the dataset class\n",
        "class LanguageTestDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=200):\n",
        "        self.texts = texts.reset_index(drop=True)\n",
        "        self.labels = labels.fillna(0).astype(int).reset_index(drop=True)  # Convert NaN to 0 for non-hate\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts.iloc[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long)  # Use 'labels' as the key\n",
        "        }\n",
        "\n",
        "# Create dataset and dataloader for each language\n",
        "def create_dataloader(df, tokenizer, batch_size=8):\n",
        "    dataset = LanguageTestDataset(df['text'], df['label'], tokenizer)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Replace these with your actual cleaned DataFrames\n",
        "# thai_df_cleaned = ...\n",
        "# lao_df_cleaned = ...\n",
        "# shan_df_cleaned = ...\n",
        "\n",
        "thai_dataloader = create_dataloader(thai_df_cleaned, tokenizer)\n",
        "lao_dataloader = create_dataloader(lao_df_cleaned, tokenizer)\n",
        "shan_dataloader = create_dataloader(shan_df_cleaned, tokenizer)\n",
        "\n",
        "print(\"DataLoaders created for Thai, Lao, and Shan datasets.\")\n",
        "\n",
        "# Load your trained model\n",
        "# Ensure that the model is configured to output hidden states\n",
        "multi_task_model = AutoModel.from_pretrained(\"/content/drive/MyDrive/Cross_Lingual_Meta_Learning\", output_hidden_states=True)\n",
        "multi_task_model.to(device)\n",
        "\n",
        "# Define the embedding extraction function\n",
        "def extract_embeddings(model, dataloader):\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            batch_labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "            # Access the last hidden state\n",
        "            hidden_states = outputs.hidden_states[-1][:, 0, :]  # Use the [CLS] token representation\n",
        "            embeddings.append(hidden_states.cpu())\n",
        "            labels.append(batch_labels.cpu())\n",
        "    embeddings = torch.cat(embeddings)\n",
        "    labels = torch.cat(labels)\n",
        "    return embeddings, labels\n",
        "\n",
        "# Define the function to calculate weighted prototypes\n",
        "def calculate_prototypes_with_weights(embeddings, labels, num_classes=2):\n",
        "    \"\"\"Calculate weighted prototypes for each class to emphasize core samples.\"\"\"\n",
        "    prototypes = []\n",
        "    for label in range(num_classes):\n",
        "        class_embeddings = embeddings[labels == label]\n",
        "        if class_embeddings.shape[0] > 0:\n",
        "            # Center the embeddings and compute distances\n",
        "            center = class_embeddings.mean(dim=0, keepdim=True)\n",
        "            distances = torch.norm(class_embeddings - center, dim=1)\n",
        "\n",
        "            # Calculate weights: closer embeddings have higher weights\n",
        "            weights = 1 / (distances + 1e-6)\n",
        "            weighted_embeddings = class_embeddings * weights.unsqueeze(1)\n",
        "            weighted_prototype = weighted_embeddings.sum(dim=0) / weights.sum()\n",
        "            prototypes.append(weighted_prototype)\n",
        "        else:\n",
        "            prototypes.append(torch.zeros(embeddings.shape[1]))  # Handle empty classes\n",
        "\n",
        "    return torch.stack(prototypes)\n",
        "\n",
        "# Define the evaluation function\n",
        "def evaluate_with_cosine_similarity(model, dataloader, prototypes):\n",
        "    \"\"\"Evaluate using cosine similarity to prototypes.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    prototypes = prototypes.to(device)  # Ensure prototypes are on the correct device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            batch_labels = batch['labels'].to(device)\n",
        "\n",
        "            # Get embeddings from the model\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "\n",
        "            # Access hidden states\n",
        "            if hasattr(outputs, 'hidden_states'):\n",
        "                hidden_states = outputs.hidden_states[-1]\n",
        "            elif isinstance(outputs, tuple):\n",
        "                hidden_states = outputs[-1]  # For models that return tuples\n",
        "            else:\n",
        "                raise ValueError(\"Unexpected model output structure.\")\n",
        "\n",
        "            embeddings = hidden_states[:, 0, :]  # Use [CLS] token representation\n",
        "\n",
        "            # Calculate cosine similarity to prototypes\n",
        "            similarities = torch.nn.functional.cosine_similarity(\n",
        "                embeddings.unsqueeze(1), prototypes.unsqueeze(0), dim=2\n",
        "            )\n",
        "            preds = torch.argmax(similarities, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "    # Calculate accuracy and F1-score\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    report = classification_report(all_labels, all_preds, target_names=[\"Non-hate\", \"Hate\"])\n",
        "\n",
        "    return accuracy, macro_f1, report\n",
        "\n",
        "# Step 1: Extract embeddings for each language\n",
        "print(\"Extracting embeddings for Thai dataset...\")\n",
        "thai_embeddings, thai_labels = extract_embeddings(multi_task_model, thai_dataloader)\n",
        "print(\"Extracting embeddings for Lao dataset...\")\n",
        "lao_embeddings, lao_labels = extract_embeddings(multi_task_model, lao_dataloader)\n",
        "print(\"Extracting embeddings for Shan dataset...\")\n",
        "shan_embeddings, shan_labels = extract_embeddings(multi_task_model, shan_dataloader)\n",
        "\n",
        "# Step 2: Generate prototypes using the new weighted approach\n",
        "print(\"Calculating weighted prototypes for Thai dataset...\")\n",
        "updated_prototypes_thai = calculate_prototypes_with_weights(thai_embeddings, thai_labels, num_classes=2)\n",
        "print(\"Calculating weighted prototypes for Lao dataset...\")\n",
        "updated_prototypes_lao = calculate_prototypes_with_weights(lao_embeddings, lao_labels, num_classes=2)\n",
        "print(\"Calculating weighted prototypes for Shan dataset...\")\n",
        "updated_prototypes_shan = calculate_prototypes_with_weights(shan_embeddings, shan_labels, num_classes=2)\n",
        "\n",
        "# Step 3: Use the refined prototypes in evaluation\n",
        "print(\"\\nEvaluating Lao Test Set...\")\n",
        "accuracy, macro_f1, report = evaluate_with_cosine_similarity(\n",
        "    multi_task_model, lao_dataloader, updated_prototypes_lao\n",
        ")\n",
        "print(f\"Accuracy: {accuracy}\\nMacro F1: {macro_f1}\\n{report}\")\n",
        "\n",
        "print(\"\\nEvaluating Shan Test Set...\")\n",
        "accuracy, macro_f1, report = evaluate_with_cosine_similarity(\n",
        "    multi_task_model, shan_dataloader, updated_prototypes_shan\n",
        ")\n",
        "print(f\"Accuracy: {accuracy}\\nMacro F1: {macro_f1}\\n{report}\")\n"
      ],
      "metadata": {
        "id": "4Q-ws4UXVo0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5b044b33-3686-4958-98ec-3b0de8f81ab2"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders created for Thai, Lao, and Shan datasets.\n",
            "Extracting embeddings for Thai dataset...\n",
            "Extracting embeddings for Lao dataset...\n",
            "Extracting embeddings for Shan dataset...\n",
            "Calculating weighted prototypes for Thai dataset...\n",
            "Calculating weighted prototypes for Lao dataset...\n",
            "Calculating weighted prototypes for Shan dataset...\n",
            "\n",
            "Evaluating Lao Test Set...\n",
            "Accuracy: 0.7037037037037037\n",
            "Macro F1: 0.5533088235294118\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Non-hate       0.95      0.71      0.81        73\n",
            "        Hate       0.19      0.62      0.29         8\n",
            "\n",
            "    accuracy                           0.70        81\n",
            "   macro avg       0.57      0.67      0.55        81\n",
            "weighted avg       0.87      0.70      0.76        81\n",
            "\n",
            "\n",
            "Evaluating Shan Test Set...\n",
            "Accuracy: 0.5135135135135135\n",
            "Macro F1: 0.4322250639386189\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Non-hate       0.94      0.49      0.65        67\n",
            "        Hate       0.13      0.71      0.22         7\n",
            "\n",
            "    accuracy                           0.51        74\n",
            "   macro avg       0.54      0.60      0.43        74\n",
            "weighted avg       0.87      0.51      0.61        74\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2cf7cd1a6cb4291aa1513872980726c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3118c452da7d45c3be8e0b07881d9ed6",
              "IPY_MODEL_52e797caae8a48849d16960c17099781",
              "IPY_MODEL_0ed153b502ec455895d07e0696849b97"
            ],
            "layout": "IPY_MODEL_a10e2a287f9a4066a9e2e8e642e50935"
          }
        },
        "3118c452da7d45c3be8e0b07881d9ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6ae568d6a904d2497bc64c7047f5b54",
            "placeholder": "​",
            "style": "IPY_MODEL_188d2506ea864b5fa171458bbd13b7d2",
            "value": "README.md: 100%"
          }
        },
        "52e797caae8a48849d16960c17099781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea765a2de7af4466891b53a179f83f04",
            "max": 12125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0a202a25715488fb88ce951d7ae48e0",
            "value": 12125
          }
        },
        "0ed153b502ec455895d07e0696849b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd0daeb2de004500b8ec9fda4325554c",
            "placeholder": "​",
            "style": "IPY_MODEL_08af85cb2afa473b9e059fd2696a21ea",
            "value": " 12.1k/12.1k [00:00&lt;00:00, 830kB/s]"
          }
        },
        "a10e2a287f9a4066a9e2e8e642e50935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ae568d6a904d2497bc64c7047f5b54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "188d2506ea864b5fa171458bbd13b7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea765a2de7af4466891b53a179f83f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a202a25715488fb88ce951d7ae48e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd0daeb2de004500b8ec9fda4325554c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08af85cb2afa473b9e059fd2696a21ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0628f97d1999424c86ed4ba7e02a9629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e10df31544b446da1fba70cd9193b54",
              "IPY_MODEL_f0e0d7a9c2cf4c54aa712459f7f32378",
              "IPY_MODEL_65c2f3f4bc71453d804820af241eee98"
            ],
            "layout": "IPY_MODEL_a4a46e3807864bb2b8df48596e0e630b"
          }
        },
        "2e10df31544b446da1fba70cd9193b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b9d804121e94047a49a6fe90d23ff62",
            "placeholder": "​",
            "style": "IPY_MODEL_cd9e18bc9dc24a149ec9bfb7c069b6aa",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "f0e0d7a9c2cf4c54aa712459f7f32378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94a0c932bad446829b2d226ccccb6774",
            "max": 2582961,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b445c0b52e64b17924ea32e3cfaa512",
            "value": 2582961
          }
        },
        "65c2f3f4bc71453d804820af241eee98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23c4b5e5a2f1431c962ace49bf19ed8c",
            "placeholder": "​",
            "style": "IPY_MODEL_e11d112b78704b2a882d9df883bbafbd",
            "value": " 2.58M/2.58M [00:00&lt;00:00, 42.8MB/s]"
          }
        },
        "a4a46e3807864bb2b8df48596e0e630b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b9d804121e94047a49a6fe90d23ff62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd9e18bc9dc24a149ec9bfb7c069b6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94a0c932bad446829b2d226ccccb6774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b445c0b52e64b17924ea32e3cfaa512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23c4b5e5a2f1431c962ace49bf19ed8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e11d112b78704b2a882d9df883bbafbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92ebe4161bb14c2986f5b549984af8a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b2c8675071e491a8508fe5143e67abe",
              "IPY_MODEL_4e78879c1b3440a38d24e620cd4be366",
              "IPY_MODEL_efb3e4245ebb4fbeaeed48f7d33a09e0"
            ],
            "layout": "IPY_MODEL_8dc09c800e72445cb9b97a31af95a002"
          }
        },
        "9b2c8675071e491a8508fe5143e67abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b580207825974b558aba8657c85ea7ea",
            "placeholder": "​",
            "style": "IPY_MODEL_cec94597a1744a8483d93c0a23d2f38f",
            "value": "validation-00000-of-00001.parquet: 100%"
          }
        },
        "4e78879c1b3440a38d24e620cd4be366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0896c34f6c482397242bccd542709a",
            "max": 286045,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80506a1fedcf413e8e7bd396dd0938d3",
            "value": 286045
          }
        },
        "efb3e4245ebb4fbeaeed48f7d33a09e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a45de62ff38461ebf0393cffd9b5516",
            "placeholder": "​",
            "style": "IPY_MODEL_982251c1782047c2ae898d310dfbc502",
            "value": " 286k/286k [00:00&lt;00:00, 21.3MB/s]"
          }
        },
        "8dc09c800e72445cb9b97a31af95a002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b580207825974b558aba8657c85ea7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cec94597a1744a8483d93c0a23d2f38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b0896c34f6c482397242bccd542709a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80506a1fedcf413e8e7bd396dd0938d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a45de62ff38461ebf0393cffd9b5516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "982251c1782047c2ae898d310dfbc502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb43c59e931a49299e6ddc5ec0c202e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1383531a913540539409f5dbcc069320",
              "IPY_MODEL_9deefa74148b413789ccbf7ab98dc55e",
              "IPY_MODEL_65ee7327f61746e19b5ddda4c29ac926"
            ],
            "layout": "IPY_MODEL_0e2f49d880334798a5bbfd714d56f3ba"
          }
        },
        "1383531a913540539409f5dbcc069320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5f1a980483a4a4580e1d5c8ef4e31a5",
            "placeholder": "​",
            "style": "IPY_MODEL_1d8222f82a0441899dcda7f0931c2f98",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "9deefa74148b413789ccbf7ab98dc55e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9b8d40494a94156904b84f70bc0e740",
            "max": 326621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2fdfc120cc944dfba23897a505c266e",
            "value": 326621
          }
        },
        "65ee7327f61746e19b5ddda4c29ac926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72ab34eb123f472e9d97c7501e8c10bb",
            "placeholder": "​",
            "style": "IPY_MODEL_12e49cab7bdb49a79316591a56ba2c10",
            "value": " 327k/327k [00:00&lt;00:00, 25.3MB/s]"
          }
        },
        "0e2f49d880334798a5bbfd714d56f3ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5f1a980483a4a4580e1d5c8ef4e31a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8222f82a0441899dcda7f0931c2f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9b8d40494a94156904b84f70bc0e740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2fdfc120cc944dfba23897a505c266e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72ab34eb123f472e9d97c7501e8c10bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e49cab7bdb49a79316591a56ba2c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f16c58b03ac74c7c9064b608d2442bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1120ee0478e14ed6959baa94dcd07dc8",
              "IPY_MODEL_054d76747d3d44c49910467197672b97",
              "IPY_MODEL_35b900134f1c4c89ab49c62736a2224b"
            ],
            "layout": "IPY_MODEL_806409c4c2c146cea3d6d94316b73463"
          }
        },
        "1120ee0478e14ed6959baa94dcd07dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57f6abce6db24c7fbe58204af6b65043",
            "placeholder": "​",
            "style": "IPY_MODEL_bcb7026577004223ab4dd97ef79403ce",
            "value": "Generating train split: 100%"
          }
        },
        "054d76747d3d44c49910467197672b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28762ed72b01497e91493565a18aab52",
            "max": 21628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46432f44830249199059c1a67f195372",
            "value": 21628
          }
        },
        "35b900134f1c4c89ab49c62736a2224b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c50075952c246faac381eea8c77c413",
            "placeholder": "​",
            "style": "IPY_MODEL_06bcd787198f4df2bdf2a7b5e5c65f9e",
            "value": " 21628/21628 [00:00&lt;00:00, 307701.52 examples/s]"
          }
        },
        "806409c4c2c146cea3d6d94316b73463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57f6abce6db24c7fbe58204af6b65043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb7026577004223ab4dd97ef79403ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28762ed72b01497e91493565a18aab52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46432f44830249199059c1a67f195372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c50075952c246faac381eea8c77c413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06bcd787198f4df2bdf2a7b5e5c65f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93599cf2909547d9b5fb75620abb2648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75e65585fbcd4b97ae8e375d01e77a49",
              "IPY_MODEL_c1de5707342345198153098fac4a3fec",
              "IPY_MODEL_a153d192673a410ab587bdabaa0445df"
            ],
            "layout": "IPY_MODEL_4e5387aede014891b997a2b9ef1f7a4f"
          }
        },
        "75e65585fbcd4b97ae8e375d01e77a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36772199650e473e9b16bb3096819e23",
            "placeholder": "​",
            "style": "IPY_MODEL_36a7dc31b5944daa91eba0909495ac7d",
            "value": "Generating validation split: 100%"
          }
        },
        "c1de5707342345198153098fac4a3fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65d222571a9f45ad9021daa3c358031b",
            "max": 2404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1b82cdd7da44a4eb2cd2bedc18d778a",
            "value": 2404
          }
        },
        "a153d192673a410ab587bdabaa0445df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee023fdebf364ff999d11b86d1c3966d",
            "placeholder": "​",
            "style": "IPY_MODEL_42d4c72d60a144d19e1a6a6da7345549",
            "value": " 2404/2404 [00:00&lt;00:00, 129067.07 examples/s]"
          }
        },
        "4e5387aede014891b997a2b9ef1f7a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36772199650e473e9b16bb3096819e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a7dc31b5944daa91eba0909495ac7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65d222571a9f45ad9021daa3c358031b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b82cdd7da44a4eb2cd2bedc18d778a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee023fdebf364ff999d11b86d1c3966d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d4c72d60a144d19e1a6a6da7345549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04736a9bfee2489a8d48287034a3c7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9203e02da3934a5f84a79c000469fe47",
              "IPY_MODEL_c1d668b7d3d647989618292b69233ba2",
              "IPY_MODEL_2aaa0f66f00f4035add3df4ffe9dd148"
            ],
            "layout": "IPY_MODEL_7d3538121f62480ea7b69d4368d9d8f3"
          }
        },
        "9203e02da3934a5f84a79c000469fe47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c3a416a7d364146b282e66eb80e4f90",
            "placeholder": "​",
            "style": "IPY_MODEL_c81e80d34dd24920a790e8a74d64bcc1",
            "value": "Generating test split: 100%"
          }
        },
        "c1d668b7d3d647989618292b69233ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43876c2aed454349b74378d659203168",
            "max": 2671,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be38420a570c46a4bf4b939857aaeb99",
            "value": 2671
          }
        },
        "2aaa0f66f00f4035add3df4ffe9dd148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd8342a1b9f24fca9b2c04414e63562a",
            "placeholder": "​",
            "style": "IPY_MODEL_0a2b24457db8447f811005561bce6af7",
            "value": " 2671/2671 [00:00&lt;00:00, 143731.22 examples/s]"
          }
        },
        "7d3538121f62480ea7b69d4368d9d8f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c3a416a7d364146b282e66eb80e4f90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c81e80d34dd24920a790e8a74d64bcc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43876c2aed454349b74378d659203168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be38420a570c46a4bf4b939857aaeb99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd8342a1b9f24fca9b2c04414e63562a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a2b24457db8447f811005561bce6af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fda6576012014ec2ad39e1ac1963f9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b38bcc4386b4deeb8036b2f416b5138",
              "IPY_MODEL_0be306bc88974a34ac9ff94c4da978d8",
              "IPY_MODEL_ea80abf491d94e79a705f3a927033e28"
            ],
            "layout": "IPY_MODEL_ab444298634b4a30b65f1637c0478d1b"
          }
        },
        "1b38bcc4386b4deeb8036b2f416b5138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_465395b4d913421eb35eac1551dbdb9a",
            "placeholder": "​",
            "style": "IPY_MODEL_5f64be4f7ae541c698155452470434a0",
            "value": ""
          }
        },
        "0be306bc88974a34ac9ff94c4da978d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521b4cd838b541aa951ec05a3bd4e86d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd0932037fa84f5faf0b9ab132fadccd",
            "value": 0
          }
        },
        "ea80abf491d94e79a705f3a927033e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6995d9fb464248489cbd31495b65a656",
            "placeholder": "​",
            "style": "IPY_MODEL_4b501fd493cc4bd28c5962510df5a902",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "ab444298634b4a30b65f1637c0478d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "465395b4d913421eb35eac1551dbdb9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f64be4f7ae541c698155452470434a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "521b4cd838b541aa951ec05a3bd4e86d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bd0932037fa84f5faf0b9ab132fadccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6995d9fb464248489cbd31495b65a656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b501fd493cc4bd28c5962510df5a902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a16eadf161c9416aa87af3c325dabb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26b736f97dfc4017a01464a5a40d0b16",
              "IPY_MODEL_82883a924fe1467f9f767ba7514dfdc6",
              "IPY_MODEL_1206a6fb486c4839886df3b87735758d"
            ],
            "layout": "IPY_MODEL_ee9dfd48c1e643be901ce9ce03532ee7"
          }
        },
        "26b736f97dfc4017a01464a5a40d0b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fdfd52c5a9d4b96b0a3f742cc9d0614",
            "placeholder": "​",
            "style": "IPY_MODEL_44bbe2021fd44da5aabe73e6b4d93906",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "82883a924fe1467f9f767ba7514dfdc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9dcf5edbf2c4080b43d9a4271e885bc",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f162912f777649ee999b474a028ec2f8",
            "value": 49
          }
        },
        "1206a6fb486c4839886df3b87735758d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_507f5279b730462c9f40c29964261d63",
            "placeholder": "​",
            "style": "IPY_MODEL_cbdaadb52d074972a4bd6ca8876a1b1d",
            "value": " 49.0/49.0 [00:00&lt;00:00, 3.83kB/s]"
          }
        },
        "ee9dfd48c1e643be901ce9ce03532ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fdfd52c5a9d4b96b0a3f742cc9d0614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44bbe2021fd44da5aabe73e6b4d93906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9dcf5edbf2c4080b43d9a4271e885bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f162912f777649ee999b474a028ec2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "507f5279b730462c9f40c29964261d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbdaadb52d074972a4bd6ca8876a1b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ab6ccb2f287436b9d3bf6ab00ef8bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8241707f7fb47afb7ccf3bc7a7fb4c2",
              "IPY_MODEL_e1acfd456e0a4c83aa054dab75a81a3e",
              "IPY_MODEL_1bca25fdcf174f5ab87401909675129a"
            ],
            "layout": "IPY_MODEL_9e2a6fac18b5490b9adb6f743bac3d1f"
          }
        },
        "d8241707f7fb47afb7ccf3bc7a7fb4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_394ed618ac384a8ca4bcc04c5dc7949c",
            "placeholder": "​",
            "style": "IPY_MODEL_2311402d4dd940d191e761b18874c9a8",
            "value": "config.json: 100%"
          }
        },
        "e1acfd456e0a4c83aa054dab75a81a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db435260964d4c9cb299560c8d5cd9f3",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b912e4c274c54e0c9902c9d13e25b948",
            "value": 625
          }
        },
        "1bca25fdcf174f5ab87401909675129a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6cac576f93c43f88118060e7082a47e",
            "placeholder": "​",
            "style": "IPY_MODEL_bddcf1bbc1a14be2bcec333ba9e9f42d",
            "value": " 625/625 [00:00&lt;00:00, 48.1kB/s]"
          }
        },
        "9e2a6fac18b5490b9adb6f743bac3d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394ed618ac384a8ca4bcc04c5dc7949c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2311402d4dd940d191e761b18874c9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db435260964d4c9cb299560c8d5cd9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b912e4c274c54e0c9902c9d13e25b948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6cac576f93c43f88118060e7082a47e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bddcf1bbc1a14be2bcec333ba9e9f42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b11cd67bb0d44bbfb64ac1a25d670cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a39bfa3b79b14e08a6d049fb838666f4",
              "IPY_MODEL_2ea12896d72e4a1d94ff43c7291f74b5",
              "IPY_MODEL_a86f9bd87edc40af87beaa22626c26fe"
            ],
            "layout": "IPY_MODEL_010ca851fc654ca3aabe653a0b06632c"
          }
        },
        "a39bfa3b79b14e08a6d049fb838666f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0418c54db15446259e77c4fc0850163b",
            "placeholder": "​",
            "style": "IPY_MODEL_7e3e77a5269b41f4aa356d9ad3644d69",
            "value": "vocab.txt: 100%"
          }
        },
        "2ea12896d72e4a1d94ff43c7291f74b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b9c73ec2de347a9b3239373e3c170f8",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eae9b2d6a25446b5b5d42a102c926b2e",
            "value": 995526
          }
        },
        "a86f9bd87edc40af87beaa22626c26fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f98dd2b2b24a402b99baec316055726c",
            "placeholder": "​",
            "style": "IPY_MODEL_fc2bdc15c8e14e6dada3058b07c4d539",
            "value": " 996k/996k [00:00&lt;00:00, 1.53MB/s]"
          }
        },
        "010ca851fc654ca3aabe653a0b06632c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0418c54db15446259e77c4fc0850163b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e3e77a5269b41f4aa356d9ad3644d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b9c73ec2de347a9b3239373e3c170f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eae9b2d6a25446b5b5d42a102c926b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f98dd2b2b24a402b99baec316055726c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc2bdc15c8e14e6dada3058b07c4d539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b32053f09293467fb803d3ebd4cf4ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd38724a0e5f41c0bcd6e7c1d79a1e51",
              "IPY_MODEL_ff284cfdf86e4103909f52a33d11dd4d",
              "IPY_MODEL_882742bc71ad4172884fa414aa5584da"
            ],
            "layout": "IPY_MODEL_181b93166fc54544838c387139a6646d"
          }
        },
        "cd38724a0e5f41c0bcd6e7c1d79a1e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_476d1c84b5eb46bab99966efbf8f835d",
            "placeholder": "​",
            "style": "IPY_MODEL_0521fdf52b314ce98c83724027f709c7",
            "value": "tokenizer.json: 100%"
          }
        },
        "ff284cfdf86e4103909f52a33d11dd4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92edb1a82293467c9dd6459fa098825c",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10500a12741d4aff9fc7d7cb304ccd59",
            "value": 1961828
          }
        },
        "882742bc71ad4172884fa414aa5584da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f0ffef357f54ffba8ae830d7da3f38f",
            "placeholder": "​",
            "style": "IPY_MODEL_3939ebb8eaba4e98a246b950e40dba52",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 8.67MB/s]"
          }
        },
        "181b93166fc54544838c387139a6646d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "476d1c84b5eb46bab99966efbf8f835d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0521fdf52b314ce98c83724027f709c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92edb1a82293467c9dd6459fa098825c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10500a12741d4aff9fc7d7cb304ccd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f0ffef357f54ffba8ae830d7da3f38f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3939ebb8eaba4e98a246b950e40dba52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7f2b92183774041904327d36043eac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4bb23ab0cce45869e00fed05abcfb99",
              "IPY_MODEL_dcd49e678d6d4804938c302492bead73",
              "IPY_MODEL_53845d48d4214abc8b6dcf162921deb0"
            ],
            "layout": "IPY_MODEL_bcf8271419f84777844977b90c7acb32"
          }
        },
        "d4bb23ab0cce45869e00fed05abcfb99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2240813d85054fc2b0f46036b4035841",
            "placeholder": "​",
            "style": "IPY_MODEL_f508b649c1e24248ac4a6f5c30ad2b1e",
            "value": "model.safetensors: 100%"
          }
        },
        "dcd49e678d6d4804938c302492bead73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0b0234fd0c148ce9028e7358dee9aa4",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7de30b43417c49f9970dc814ec30b061",
            "value": 714290682
          }
        },
        "53845d48d4214abc8b6dcf162921deb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f84974caa4634ca8b8ed4fca81ad5b12",
            "placeholder": "​",
            "style": "IPY_MODEL_8d87afca569d4a78bf337538229ef27a",
            "value": " 714M/714M [00:03&lt;00:00, 219MB/s]"
          }
        },
        "bcf8271419f84777844977b90c7acb32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2240813d85054fc2b0f46036b4035841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f508b649c1e24248ac4a6f5c30ad2b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0b0234fd0c148ce9028e7358dee9aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de30b43417c49f9970dc814ec30b061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f84974caa4634ca8b8ed4fca81ad5b12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d87afca569d4a78bf337538229ef27a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}