{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stevebankz/Hate_Speech_Detection/blob/main/Linguistically_Informed_Cross_Lingual_Meta_Learning_for_Weakly_Supervised_Hate_Speech_Detection_in_Tai_Kadai_Languages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VavtHRPrvYqi",
        "outputId": "3332158a-1e42-450c-d832-7890e7b80c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting pythainlp\n",
            "  Downloading pythainlp-5.0.4-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2024.8.30)\n",
            "Downloading pythainlp-5.0.4-py3-none-any.whl (17.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pythainlp\n",
            "Successfully installed pythainlp-5.0.4\n"
          ]
        }
      ],
      "source": [
        "# Installing Hugging Face datasets and PyThaiNLP for Thai language processing\n",
        "!pip install datasets\n",
        "!pip install pythainlp\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdZuZsO_ZD9C",
        "outputId": "f712f31c-a5fd-4e10-c699-4a620fe2a1f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608,
          "referenced_widgets": [
            "f2cf7cd1a6cb4291aa1513872980726c",
            "3118c452da7d45c3be8e0b07881d9ed6",
            "52e797caae8a48849d16960c17099781",
            "0ed153b502ec455895d07e0696849b97",
            "a10e2a287f9a4066a9e2e8e642e50935",
            "f6ae568d6a904d2497bc64c7047f5b54",
            "188d2506ea864b5fa171458bbd13b7d2",
            "ea765a2de7af4466891b53a179f83f04",
            "b0a202a25715488fb88ce951d7ae48e0",
            "dd0daeb2de004500b8ec9fda4325554c",
            "08af85cb2afa473b9e059fd2696a21ea",
            "0628f97d1999424c86ed4ba7e02a9629",
            "2e10df31544b446da1fba70cd9193b54",
            "f0e0d7a9c2cf4c54aa712459f7f32378",
            "65c2f3f4bc71453d804820af241eee98",
            "a4a46e3807864bb2b8df48596e0e630b",
            "3b9d804121e94047a49a6fe90d23ff62",
            "cd9e18bc9dc24a149ec9bfb7c069b6aa",
            "94a0c932bad446829b2d226ccccb6774",
            "4b445c0b52e64b17924ea32e3cfaa512",
            "23c4b5e5a2f1431c962ace49bf19ed8c",
            "e11d112b78704b2a882d9df883bbafbd",
            "92ebe4161bb14c2986f5b549984af8a4",
            "9b2c8675071e491a8508fe5143e67abe",
            "4e78879c1b3440a38d24e620cd4be366",
            "efb3e4245ebb4fbeaeed48f7d33a09e0",
            "8dc09c800e72445cb9b97a31af95a002",
            "b580207825974b558aba8657c85ea7ea",
            "cec94597a1744a8483d93c0a23d2f38f",
            "0b0896c34f6c482397242bccd542709a",
            "80506a1fedcf413e8e7bd396dd0938d3",
            "2a45de62ff38461ebf0393cffd9b5516",
            "982251c1782047c2ae898d310dfbc502",
            "eb43c59e931a49299e6ddc5ec0c202e4",
            "1383531a913540539409f5dbcc069320",
            "9deefa74148b413789ccbf7ab98dc55e",
            "65ee7327f61746e19b5ddda4c29ac926",
            "0e2f49d880334798a5bbfd714d56f3ba",
            "f5f1a980483a4a4580e1d5c8ef4e31a5",
            "1d8222f82a0441899dcda7f0931c2f98",
            "b9b8d40494a94156904b84f70bc0e740",
            "e2fdfc120cc944dfba23897a505c266e",
            "72ab34eb123f472e9d97c7501e8c10bb",
            "12e49cab7bdb49a79316591a56ba2c10",
            "f16c58b03ac74c7c9064b608d2442bdd",
            "1120ee0478e14ed6959baa94dcd07dc8",
            "054d76747d3d44c49910467197672b97",
            "35b900134f1c4c89ab49c62736a2224b",
            "806409c4c2c146cea3d6d94316b73463",
            "57f6abce6db24c7fbe58204af6b65043",
            "bcb7026577004223ab4dd97ef79403ce",
            "28762ed72b01497e91493565a18aab52",
            "46432f44830249199059c1a67f195372",
            "7c50075952c246faac381eea8c77c413",
            "06bcd787198f4df2bdf2a7b5e5c65f9e",
            "93599cf2909547d9b5fb75620abb2648",
            "75e65585fbcd4b97ae8e375d01e77a49",
            "c1de5707342345198153098fac4a3fec",
            "a153d192673a410ab587bdabaa0445df",
            "4e5387aede014891b997a2b9ef1f7a4f",
            "36772199650e473e9b16bb3096819e23",
            "36a7dc31b5944daa91eba0909495ac7d",
            "65d222571a9f45ad9021daa3c358031b",
            "e1b82cdd7da44a4eb2cd2bedc18d778a",
            "ee023fdebf364ff999d11b86d1c3966d",
            "42d4c72d60a144d19e1a6a6da7345549",
            "04736a9bfee2489a8d48287034a3c7a6",
            "9203e02da3934a5f84a79c000469fe47",
            "c1d668b7d3d647989618292b69233ba2",
            "2aaa0f66f00f4035add3df4ffe9dd148",
            "7d3538121f62480ea7b69d4368d9d8f3",
            "5c3a416a7d364146b282e66eb80e4f90",
            "c81e80d34dd24920a790e8a74d64bcc1",
            "43876c2aed454349b74378d659203168",
            "be38420a570c46a4bf4b939857aaeb99",
            "fd8342a1b9f24fca9b2c04414e63562a",
            "0a2b24457db8447f811005561bce6af7"
          ]
        },
        "collapsed": true,
        "id": "Yb2wxolHv0hT",
        "outputId": "a1e11b4f-24db-45b2-8b42-d302e08f3bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/12.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2cf7cd1a6cb4291aa1513872980726c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.58M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0628f97d1999424c86ed4ba7e02a9629"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/286k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92ebe4161bb14c2986f5b549984af8a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/327k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb43c59e931a49299e6ddc5ec0c202e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/21628 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f16c58b03ac74c7c9064b608d2442bdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/2404 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93599cf2909547d9b5fb75620abb2648"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2671 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04736a9bfee2489a8d48287034a3c7a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['texts', 'category'],\n",
            "        num_rows: 21628\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['texts', 'category'],\n",
            "        num_rows: 2404\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['texts', 'category'],\n",
            "        num_rows: 2671\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Loading the Wisesight Sentiment dataset\n",
        "dataset = load_dataset(\"pythainlp/wisesight_sentiment\")\n",
        "\n",
        "# Check the available splits (train, validation, test)\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_rwUrTShwAyE",
        "outputId": "39f5b78a-7ec0-4469-9626-f72071f4426c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['texts', 'category'],\n",
            "    num_rows: 5\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# random sample from the train set\n",
        "sample_data = dataset['train'].shuffle(seed=42).select(range(5))  # Show 5 random samples\n",
        "print(sample_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vIFJFwG0wLGX",
        "outputId": "e1f591af-f5c2-4731-a782-3a701303f4fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "category\n",
            "1    11795\n",
            "2     5491\n",
            "0     3866\n",
            "3      476\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Count of occurrences of each label in the train split\n",
        "label_counts = dataset['train'].features['category'].names  # Get label names (pos, neu, neg, q)\n",
        "\n",
        "# Calculate distribution of labels\n",
        "label_distribution = dataset['train'].to_pandas()['category'].value_counts()\n",
        "print(label_distribution)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mQuGA68JwY8o",
        "outputId": "cbc0af60-16c8-4dc9-cf62-e9bea5d6779a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        char_length   word_length\n",
            "count  21628.000000  21628.000000\n",
            "mean      89.818291      6.340300\n",
            "std      149.255596     12.186247\n",
            "min        1.000000      1.000000\n",
            "25%       19.000000      1.000000\n",
            "50%       39.000000      3.000000\n",
            "75%       98.000000      6.000000\n",
            "max     1997.000000    292.000000\n"
          ]
        }
      ],
      "source": [
        "# Analyze the length of the messages (number of characters and words)\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the dataset to a pandas DataFrame\n",
        "df = dataset['train'].to_pandas()\n",
        "\n",
        "# Calculate message lengths\n",
        "df['char_length'] = df['texts'].apply(len)  # Length in characters\n",
        "df['word_length'] = df['texts'].apply(lambda x: len(x.split()))  # Length in words\n",
        "\n",
        "# Display basic statistics about message length\n",
        "print(df[['char_length', 'word_length']].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TNCFeWONwlmY",
        "outputId": "1ad0c2c7-079a-4baf-bbf0-e695fec209d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['‡πÑ‡∏õ', '‡∏à‡∏≠‡∏á', '‡∏°‡∏≤', '‡πÅ‡∏•‡πâ', '‡∏ß‡∏ô‡∏≤', '‡∏à‡∏≤', ' ', 'Mitsubishi', ' ', 'Attrage', ' ', '‡πÑ‡∏î‡πâ', '‡∏´‡∏•‡∏±‡∏á', '‡∏™‡∏á‡∏Å‡∏£‡∏≤‡∏ô‡∏ï‡πå', '‡πÄ‡∏•‡∏¢', ' ', '‡∏£‡∏≠', '‡∏Ç‡∏±‡∏ö', '‡∏≠‡∏¢‡∏π‡πà', '‡∏ô‡∏≤', '‡∏à‡∏≤', ' ', '‡∏Å‡∏£‡∏∞‡∏ó‡∏±‡∏î‡∏£‡∏±‡∏î', ' ', '‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö', '‡∏™‡∏≤‡∏ß', '‡πÜ', '‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ', '‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß', '‡πÅ‡∏ö‡∏ö', '‡πÄ‡∏£‡∏≤', ' ', '‡∏£‡∏≤‡∏Ñ‡∏≤', '‡∏™‡∏ö‡∏≤‡∏¢', '‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤', ' ', '‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î', '‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô', ' ', '‡∏ß‡∏¥‡πà‡∏á', '‡πÑ‡∏Å‡∏•', '‡πÅ‡∏Ñ‡πà', '‡πÑ‡∏´‡∏ô', '‡∏´‡∏≤‡∏¢‡∏´‡πà‡∏ß‡∏á', '‡∏Ñ‡πà‡∏∞']\n"
          ]
        }
      ],
      "source": [
        "# Install PyThaiNLP tokenizer\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# Tokenizing a Thai sentence\n",
        "sample_text = df['texts'].iloc[0]  # Taking the first text from the dataset\n",
        "tokenized_text = word_tokenize(sample_text, engine='newmm')\n",
        "print(tokenized_text)  # View the tokenized text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OwIo6YxNww9Y",
        "outputId": "52015d15-05f5-4805-e411-b792ee12e1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts  \\\n",
            "0  ‡πÑ‡∏õ‡∏à‡∏≠‡∏á‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡∏≤‡∏à‡∏≤ Mitsubishi Attrage ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏±‡∏á‡∏™‡∏á‡∏Å‡∏£...   \n",
            "1  ‡πÄ‡∏õ‡∏¥‡∏î‡∏®‡∏±‡∏Å‡∏£‡∏≤‡∏ä‡πÉ‡∏´‡∏°‡πà! ‡∏ô‡∏≤‡∏¢‡∏Å‡∏Ø ‡πÅ‡∏ñ‡∏•‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡∏®‡∏∂...   \n",
            "2                           ‡∏ö‡∏±‡∏ï‡∏£‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏≠‡∏µ‡∏Å‡πÑ‡∏´‡∏°‡∏Ñ‡∏±‡∏ö   \n",
            "3                                ‡∏™‡∏ô‡πÉ‡∏à new mazda2‡∏Ñ‡∏£‡∏±‡∏ö   \n",
            "4                                                 üòçüòç   \n",
            "\n",
            "                                     processed_texts  \n",
            "0  ‡πÑ‡∏õ ‡∏à‡∏≠‡∏á ‡∏°‡∏≤ ‡πÅ‡∏•‡πâ ‡∏ß‡∏ô‡∏≤ ‡∏à‡∏≤   mitsubishi   attrage   ...  \n",
            "1  ‡πÄ‡∏õ‡∏¥‡∏î ‡∏®‡∏±‡∏Å‡∏£‡∏≤‡∏ä ‡πÉ‡∏´‡∏°‡πà !   ‡∏ô‡∏≤‡∏¢‡∏Å‡∏Ø   ‡πÅ‡∏ñ‡∏•‡∏á‡∏Ç‡πà‡∏≤‡∏ß ‡∏Å‡πà‡∏≠‡∏ô ‡∏Å‡∏≤‡∏£...  \n",
            "2                      ‡∏ö‡∏±‡∏ï‡∏£‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å ‡∏•‡∏î ‡πÑ‡∏î‡πâ ‡∏≠‡∏µ‡∏Å ‡πÑ‡∏´‡∏° ‡∏Ñ‡∏±‡∏ö  \n",
            "3                          ‡∏™‡∏ô‡πÉ‡∏à   new   mazda 2 ‡∏Ñ‡∏£‡∏±‡∏ö  \n",
            "4                                                 üòçüòç  \n"
          ]
        }
      ],
      "source": [
        "# Function to preprocess a single text\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text using PyThaiNLP (newmm is the default tokenizer)\n",
        "    tokens = word_tokenize(text, engine='newmm')\n",
        "\n",
        "    # Lowercase all tokens\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing function to the dataset\n",
        "df['processed_texts'] = df['texts'].apply(preprocess_text)\n",
        "\n",
        "# View the first few rows of the preprocessed dataset\n",
        "print(df[['texts', 'processed_texts']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qyhvnMxzw_Y_"
      },
      "outputs": [],
      "source": [
        "# Save the preprocessed data to a CSV file for further use\n",
        "df[['processed_texts', 'category']].to_csv('preprocessed_wisesight_sentiment.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I-R8KIdRx6Lw",
        "outputId": "bfa6588f-f796-422b-edfb-4bbcb0b69f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['‡∏Ñ‡∏ß‡∏≤‡∏¢', '‡∏ó‡∏∏‡πÄ‡∏£‡∏®', '‡∏´‡∏°‡∏≤', '‡∏ï‡∏≠‡πÅ‡∏´‡∏•', '‡πÇ‡∏á‡πà', '‡∏ï‡πà‡∏≥', '‡∏ö‡πâ‡∏≤', '‡πÄ‡∏´‡πá‡∏ö', '‡πÄ‡∏•‡∏ß', '‡∏Å‡∏∞‡∏´‡∏£‡∏µ‡πà']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the toxic words from the text file\n",
        "with open('/content/drive/MyDrive/toxic_keywords_1.txt', 'r') as f:\n",
        "    toxic_words = [line.strip() for line in f]\n",
        "\n",
        "# Convert the list to a pandas Series (optional, for consistency)\n",
        "toxic_words_df = pd.DataFrame(toxic_words, columns=['word'])\n",
        "\n",
        "# Preview the toxic word list\n",
        "print(toxic_words[:10])  # Display the first 10 toxic words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k-R0Owcz0jNB",
        "outputId": "aba83fde-b8cb-43ea-cdf5-3f43d777d625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     processed_texts  category  weak_label\n",
            "0  ‡πÑ‡∏õ ‡∏à‡∏≠‡∏á ‡∏°‡∏≤ ‡πÅ‡∏•‡πâ ‡∏ß‡∏ô‡∏≤ ‡∏à‡∏≤   mitsubishi   attrage   ...         1           0\n",
            "1  ‡πÄ‡∏õ‡∏¥‡∏î ‡∏®‡∏±‡∏Å‡∏£‡∏≤‡∏ä ‡πÉ‡∏´‡∏°‡πà !   ‡∏ô‡∏≤‡∏¢‡∏Å‡∏Ø   ‡πÅ‡∏ñ‡∏•‡∏á‡∏Ç‡πà‡∏≤‡∏ß ‡∏Å‡πà‡∏≠‡∏ô ‡∏Å‡∏≤‡∏£...         1           0\n",
            "2                      ‡∏ö‡∏±‡∏ï‡∏£‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å ‡∏•‡∏î ‡πÑ‡∏î‡πâ ‡∏≠‡∏µ‡∏Å ‡πÑ‡∏´‡∏° ‡∏Ñ‡∏±‡∏ö         1           0\n",
            "3                          ‡∏™‡∏ô‡πÉ‡∏à   new   mazda 2 ‡∏Ñ‡∏£‡∏±‡∏ö         1           0\n",
            "4                                                 üòçüòç         0           0\n"
          ]
        }
      ],
      "source": [
        "# Create a function to check if a text contains any toxic words\n",
        "def contains_toxic_words(text, toxic_words):\n",
        "    # Tokenize the text using the same tokenizer (PyThaiNLP) used in preprocessing\n",
        "    tokens = word_tokenize(text, engine='newmm')\n",
        "    # Check if any token is in the toxic word list\n",
        "    return any(token in toxic_words for token in tokens)\n",
        "\n",
        "# Apply weak labeling based on sentiment and toxic words\n",
        "def weak_labeling(row, toxic_words):\n",
        "    # If the sentiment is negative, we flag it as potential hate speech (weakly labeled as 1)\n",
        "    if row['category'] == 'neg':\n",
        "        return 1\n",
        "    # If the message contains toxic words, we flag it as potential hate speech (weakly labeled as 1)\n",
        "    elif contains_toxic_words(row['processed_texts'], toxic_words):\n",
        "        return 1\n",
        "    # Otherwise, we consider it non-hateful (weakly labeled as 0)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Apply the weak labeling function to the dataset\n",
        "df['weak_label'] = df.apply(weak_labeling, axis=1, toxic_words=toxic_words)\n",
        "\n",
        "# Preview the newly labeled dataset\n",
        "print(df[['processed_texts', 'category', 'weak_label']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n3YAEyFT0wm5",
        "outputId": "d725fcb7-dffe-4db3-e53f-7c04bb205de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weak_label\n",
            "0    20783\n",
            "1      845\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check the distribution of weak labels (0 = non-hateful, 1 = potentially hateful)\n",
        "weak_label_distribution = df['weak_label'].value_counts()\n",
        "print(weak_label_distribution)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xLWfTp1m0_ma"
      },
      "outputs": [],
      "source": [
        "# Save the weakly labeled dataset to a CSV file for further use\n",
        "df[['processed_texts', 'weak_label']].to_csv('weakly_labeled_wisesight_sentiment.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KHiZXUWs2w9o",
        "outputId": "56231c39-83f9-425d-c53e-bbec8db22c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "weak_label\n",
            "0    20783\n",
            "1    20783\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Load the weakly labeled data (assuming it's saved as a CSV)\n",
        "df = pd.read_csv('weakly_labeled_wisesight_sentiment.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "texts = df['processed_texts']\n",
        "labels = df['weak_label']\n",
        "\n",
        "# Reshape data for oversampling\n",
        "texts_reshaped = texts.values.reshape(-1, 1)  # Needs to be 2D for oversampling\n",
        "\n",
        "# Initialize the RandomOverSampler\n",
        "ros = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
        "\n",
        "# Perform oversampling\n",
        "texts_resampled, labels_resampled = ros.fit_resample(texts_reshaped, labels)\n",
        "\n",
        "# Convert resampled data back to a DataFrame\n",
        "balanced_df = pd.DataFrame({\n",
        "    'texts': texts_resampled.flatten(),  # Flatten to 1D\n",
        "    'weak_label': labels_resampled\n",
        "})\n",
        "\n",
        "# Save or use the balanced dataset directly for further steps\n",
        "balanced_df.to_csv('balanced_weakly_labeled_data.csv', index=False)\n",
        "print(balanced_df['weak_label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qOLhpdnjiO9q",
        "outputId": "6baf6762-5365-48e1-e012-3bb3e0f5a24a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install Hugging Face transformers library\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch  # PyTorch for model training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "\n",
        "# Load the tokenizer for a multilingual model (mBERT in this case)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Function to tokenize text\n",
        "def tokenize_data(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# Load the balanced dataset (from the CSV saved after oversampling)\n",
        "balanced_df = pd.read_csv('balanced_weakly_labeled_data.csv')\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "train_val_df, test_df = train_test_split(balanced_df, test_size=0.1, random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize each dataset split and capture both 'input_ids' and 'attention_mask'\n",
        "train_encodings = tokenize_data(train_df['texts'].tolist())\n",
        "val_encodings = tokenize_data(val_df['texts'].tolist())\n",
        "test_encodings = tokenize_data(test_df['texts'].tolist())\n",
        "\n",
        "# Separate 'input_ids' and 'attention_mask' for each split\n",
        "train_texts, train_masks = train_encodings['input_ids'], train_encodings['attention_mask']\n",
        "val_texts, val_masks = val_encodings['input_ids'], val_encodings['attention_mask']\n",
        "test_texts, test_masks = test_encodings['input_ids'], test_encodings['attention_mask']\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "train_labels = torch.tensor(train_df['weak_label'].tolist())\n",
        "val_labels = torch.tensor(val_df['weak_label'].tolist())\n",
        "test_labels = torch.tensor(test_df['weak_label'].tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "fda6576012014ec2ad39e1ac1963f9f5",
            "1b38bcc4386b4deeb8036b2f416b5138",
            "0be306bc88974a34ac9ff94c4da978d8",
            "ea80abf491d94e79a705f3a927033e28",
            "ab444298634b4a30b65f1637c0478d1b",
            "465395b4d913421eb35eac1551dbdb9a",
            "5f64be4f7ae541c698155452470434a0",
            "521b4cd838b541aa951ec05a3bd4e86d",
            "bd0932037fa84f5faf0b9ab132fadccd",
            "6995d9fb464248489cbd31495b65a656",
            "4b501fd493cc4bd28c5962510df5a902",
            "a16eadf161c9416aa87af3c325dabb0e",
            "26b736f97dfc4017a01464a5a40d0b16",
            "82883a924fe1467f9f767ba7514dfdc6",
            "1206a6fb486c4839886df3b87735758d",
            "ee9dfd48c1e643be901ce9ce03532ee7",
            "1fdfd52c5a9d4b96b0a3f742cc9d0614",
            "44bbe2021fd44da5aabe73e6b4d93906",
            "c9dcf5edbf2c4080b43d9a4271e885bc",
            "f162912f777649ee999b474a028ec2f8",
            "507f5279b730462c9f40c29964261d63",
            "cbdaadb52d074972a4bd6ca8876a1b1d",
            "2ab6ccb2f287436b9d3bf6ab00ef8bd7",
            "d8241707f7fb47afb7ccf3bc7a7fb4c2",
            "e1acfd456e0a4c83aa054dab75a81a3e",
            "1bca25fdcf174f5ab87401909675129a",
            "9e2a6fac18b5490b9adb6f743bac3d1f",
            "394ed618ac384a8ca4bcc04c5dc7949c",
            "2311402d4dd940d191e761b18874c9a8",
            "db435260964d4c9cb299560c8d5cd9f3",
            "b912e4c274c54e0c9902c9d13e25b948",
            "a6cac576f93c43f88118060e7082a47e",
            "bddcf1bbc1a14be2bcec333ba9e9f42d",
            "b11cd67bb0d44bbfb64ac1a25d670cbf",
            "a39bfa3b79b14e08a6d049fb838666f4",
            "2ea12896d72e4a1d94ff43c7291f74b5",
            "a86f9bd87edc40af87beaa22626c26fe",
            "010ca851fc654ca3aabe653a0b06632c",
            "0418c54db15446259e77c4fc0850163b",
            "7e3e77a5269b41f4aa356d9ad3644d69",
            "4b9c73ec2de347a9b3239373e3c170f8",
            "eae9b2d6a25446b5b5d42a102c926b2e",
            "f98dd2b2b24a402b99baec316055726c",
            "fc2bdc15c8e14e6dada3058b07c4d539",
            "b32053f09293467fb803d3ebd4cf4ca9",
            "cd38724a0e5f41c0bcd6e7c1d79a1e51",
            "ff284cfdf86e4103909f52a33d11dd4d",
            "882742bc71ad4172884fa414aa5584da",
            "181b93166fc54544838c387139a6646d",
            "476d1c84b5eb46bab99966efbf8f835d",
            "0521fdf52b314ce98c83724027f709c7",
            "92edb1a82293467c9dd6459fa098825c",
            "10500a12741d4aff9fc7d7cb304ccd59",
            "9f0ffef357f54ffba8ae830d7da3f38f",
            "3939ebb8eaba4e98a246b950e40dba52"
          ]
        },
        "id": "Nak9dHcp5ySm",
        "outputId": "790cd8fd-3a06-4432-b9b4-19f4b977d7fc",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fda6576012014ec2ad39e1ac1963f9f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a16eadf161c9416aa87af3c325dabb0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ab6ccb2f287436b9d3bf6ab00ef8bd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b11cd67bb0d44bbfb64ac1a25d670cbf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b32053f09293467fb803d3ebd4cf4ca9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset class with attention mask support\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, masks, labels):\n",
        "        self.texts = texts\n",
        "        self.masks = masks\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.texts[idx],\n",
        "            'attention_mask': self.masks[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "# Create train, validation, and test datasets with attention masks\n",
        "train_dataset = TextDataset(train_texts, train_masks, train_labels)\n",
        "val_dataset = TextDataset(val_texts, val_masks, val_labels)\n",
        "test_dataset = TextDataset(test_texts, test_masks, test_labels)\n",
        "\n",
        "# Create DataLoader objects for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)  # No shuffle for test\n"
      ],
      "metadata": {
        "id": "cID08Whz6EUx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885,
          "referenced_widgets": [
            "b7f2b92183774041904327d36043eac4",
            "d4bb23ab0cce45869e00fed05abcfb99",
            "dcd49e678d6d4804938c302492bead73",
            "53845d48d4214abc8b6dcf162921deb0",
            "bcf8271419f84777844977b90c7acb32",
            "2240813d85054fc2b0f46036b4035841",
            "f508b649c1e24248ac4a6f5c30ad2b1e",
            "f0b0234fd0c148ce9028e7358dee9aa4",
            "7de30b43417c49f9970dc814ec30b061",
            "f84974caa4634ca8b8ed4fca81ad5b12",
            "8d87afca569d4a78bf337538229ef27a"
          ]
        },
        "collapsed": true,
        "id": "h3MUGZTNix8V",
        "outputId": "960a50bf-a980-413a-9c2a-68c4c396015c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7f2b92183774041904327d36043eac4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AdamW\n",
        "\n",
        "# Load pre-trained mBERT model for classification (binary classification: hate vs. non-hate)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\",\n",
        "    num_labels=2  # Binary classification (hate vs. non-hate)\n",
        ")\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Define label smoothing cross-entropy loss\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        # Number of classes (e.g., 2 for binary classification)\n",
        "        n_classes = outputs.size(-1)\n",
        "\n",
        "        # Apply log_softmax to outputs\n",
        "        log_probs = torch.nn.functional.log_softmax(outputs, dim=-1)\n",
        "\n",
        "        # Create smooth labels\n",
        "        targets = torch.zeros_like(log_probs).scatter(1, targets.unsqueeze(1), 1)  # One-hot encode targets\n",
        "        targets = (1 - self.smoothing) * targets + self.smoothing / n_classes  # Apply label smoothing\n",
        "\n",
        "        # Compute the smoothed cross-entropy loss\n",
        "        loss = (-targets * log_probs).mean()\n",
        "        return loss\n",
        "\n",
        "# Define optimizer with PyTorch's AdamW to avoid the deprecation warning\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Define a simple training loop with label smoothing\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss, total_val_loss = 0, 0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        # Training phase\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move batch data to GPU if available\n",
        "            input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "            attention_mask = batch['attention_mask'].squeeze(1).to(device)  # Added attention mask\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits  # Include attention_mask\n",
        "            loss = criterion(outputs, labels)  # Use custom criterion with label smoothing\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "                attention_mask = batch['attention_mask'].squeeze(1).to(device)  # Added attention mask\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits  # Include attention_mask\n",
        "                val_loss = criterion(outputs, labels)  # Use custom criterion with label smoothing\n",
        "\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_accuracy = correct / total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}, Val Accuracy: {val_accuracy}\")\n",
        "\n",
        "# Train the model with label smoothing\n",
        "train_model(model, train_loader, val_loader, criterion=LabelSmoothingCrossEntropy(smoothing=0.1), optimizer=optimizer, num_epochs=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nNG3983o4QNA",
        "outputId": "64b5b5b7-fdcf-4c3a-eb6e-eb35f695608e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.5.1-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.8 torchmetrics-1.5.1\n",
            "Epoch 1/3, Train Loss: 0.1474396990246788, Val Loss: 0.11015640469825166, Val Accuracy: 0.9887730553327987\n",
            "Epoch 2/3, Train Loss: 0.10660059831713942, Val Loss: 0.11256408228132969, Val Accuracy: 0.9859663191659984\n",
            "Epoch 3/3, Train Loss: 0.10421657228154463, Val Loss: 0.10319312343485335, Val Accuracy: 0.9965249933172948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sng8hnA5BFlJ",
        "outputId": "7100f695-b583-441a-d696-f9ec2ef931b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.12603263915158236, Test Accuracy: 0.9735386095742121\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Non-hate       0.96      0.99      0.97      2153\n",
            "        Hate       0.99      0.95      0.97      2004\n",
            "\n",
            "    accuracy                           0.97      4157\n",
            "   macro avg       0.98      0.97      0.97      4157\n",
            "weighted avg       0.97      0.97      0.97      4157\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Initialize variables for tracking test loss and correct predictions\n",
        "test_loss = 0\n",
        "correct, total = 0, 0\n",
        "\n",
        "# Store predictions and true labels\n",
        "all_preds = []\n",
        "y_true = []\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:  # Use val_loader if you don't have a separate test set\n",
        "        input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass (no labels argument here)\n",
        "        outputs = model(input_ids=input_ids)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Calculate loss\n",
        "        criterion = LabelSmoothingCrossEntropy(smoothing=0.1)  # Use the same criterion as training\n",
        "        loss = criterion(logits, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Get predictions\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())  # Store predictions\n",
        "        y_true.extend(labels.cpu().numpy())    # Store true labels\n",
        "\n",
        "        # Calculate accuracy\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "# Average test loss\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = correct / total\n",
        "\n",
        "print(f\"Test Loss: {avg_test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Generate classification report\n",
        "y_true = np.array(y_true)  # Convert true labels to numpy array\n",
        "y_pred = np.array(all_preds)  # Convert predictions to numpy array\n",
        "print(classification_report(y_true, y_pred, target_names=['Non-hate', 'Hate']))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of identifying misclassified samples\n",
        "misclassified = [\n",
        "    (input_ids, true, pred)\n",
        "    for input_ids, true, pred in zip(test_texts, y_true, y_pred)  # or val_texts if you're analyzing validation\n",
        "    if true != pred\n",
        "]\n",
        "\n",
        "# Display the first 10 misclassified examples in readable format\n",
        "for input_ids, true, pred in misclassified[:10]:  # First 10 misclassified examples\n",
        "    # Detokenize to retrieve original text\n",
        "    text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "    print(f\"Text: {text}\\nTrue Label: {true}, Predicted: {pred}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1cG2ZHNA9k0t",
        "outputId": "96cce288-bf0e-4b64-d06c-4a6d15367653"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: ‡∏Ü‡πà‡∏≤ ‡∏´‡∏±‡πà‡∏ô ‡∏®‡∏û ‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß ‡∏´‡∏ô‡∏µ ‡∏ï‡∏±‡πâ‡∏á ‡∏´‡∏•‡∏≤‡∏¢ ‡∏ß‡∏±‡∏ô ‡∏ô‡∏±‡πà‡∏á ‡∏Ñ‡∏∏‡∏¢ ‡∏Å‡∏±‡∏ö ‡∏ï‡∏≥‡∏£‡∏ß‡∏à ‡∏™‡∏ö‡∏≤‡∏¢‡πÉ‡∏à ‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏ö‡∏∏‡∏´‡∏£‡∏µ‡πà ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ ‡∏à‡∏±‡∏ö ‡∏•‡∏≤‡∏Å ‡∏™‡πà‡∏∞\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ‡∏Ü‡πà‡∏≤ ‡∏´‡∏±‡πà‡∏ô ‡∏®‡∏û ‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß ‡∏´‡∏ô‡∏µ ‡∏ï‡∏±‡πâ‡∏á ‡∏´‡∏•‡∏≤‡∏¢ ‡∏ß‡∏±‡∏ô ‡∏ô‡∏±‡πà‡∏á ‡∏Ñ‡∏∏‡∏¢ ‡∏Å‡∏±‡∏ö ‡∏ï‡∏≥‡∏£‡∏ß‡∏à ‡∏™‡∏ö‡∏≤‡∏¢‡πÉ‡∏à ‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏ö‡∏∏‡∏´‡∏£‡∏µ‡πà ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ ‡∏à‡∏±‡∏ö ‡∏•‡∏≤‡∏Å ‡∏™‡πà‡∏∞\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ‡πÅ‡∏Å‡∏á ‡∏Å‡∏∞‡∏´‡∏£‡∏µ‡πà ‡πÑ‡∏Ç‡πà ‡∏Ç‡πâ‡∏ô ‡πÅ‡∏ã‡∏ö ‡πÄ‡∏ß‡∏≠‡∏£‡πå ‡∏Å‡∏î like ‡∏Å‡∏±‡∏ô ‡πÑ‡∏õ ‡∏¢‡∏≤‡∏ß ‡πÜ # deliciouslyyours # showdc\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ‡πÑ‡∏Æ‡πÑ‡∏•‡∏ó‡πå ‡∏ó‡∏µ‡πà ‡∏û‡∏•‡∏≤‡∏î ‡πÑ‡∏°‡πà ‡πÑ‡∏î‡πâ ‡∏Ç‡∏≠‡∏á ‡∏™‡∏ß‡∏ô‡∏™‡∏±‡∏ï‡∏ß‡πå ‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô ‡∏Ñ‡∏∑‡∏≠ ‡∏Å‡∏≤‡∏£ ‡πÄ‡∏î‡∏¥‡∏ô ‡∏ä‡∏° ‡∏™‡∏±‡∏ï‡∏ß ‡∏≠‡∏±‡∏ü‡∏£‡∏¥‡∏Å‡∏≤ ‡∏ö‡∏ô ‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏ô ‡∏•‡∏≠‡∏¢‡∏ü‡πâ‡∏≤ ‡∏ó‡∏±‡πâ‡∏á ‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á ‡∏™‡∏±‡∏ï‡∏ß‡πå ‡∏à‡∏≤‡∏Å ‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á ‡πÅ‡∏•‡∏∞ ‡∏à‡∏∏‡∏î‡∏ä‡∏°‡∏ß‡∏¥‡∏ß ‡∏ó‡∏µ‡πà ‡∏á‡∏î‡∏á‡∏≤‡∏° ‡∏™‡∏∏‡∏î ‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ‡∏ó‡∏µ‡∏° ‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö ‡πÄ‡∏™‡∏∑‡∏≠‡∏î‡∏≥ ‡∏´‡∏≤ ‡∏¢‡∏≤‡∏Å ‡πÉ‡∏ô ‡πÄ‡∏Ñ‡∏ô‡∏¢‡∏≤ ‡∏ô‡∏±‡∏ö ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å ‡∏ó‡∏µ‡πà ‡∏û‡∏ö ‡πÄ‡∏™‡∏∑‡∏≠ ‡∏ä‡∏ô‡∏¥‡∏î ‡∏ô‡∏µ‡πâ ‡πÉ‡∏ô ‡πÅ‡∏≠‡∏ü‡∏£‡∏¥‡∏Å‡∏≤ ‡πÉ‡∏ô ‡∏£‡∏≠‡∏ö ‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö 100 ‡∏õ‡∏µ # ‡∏Ç‡πà‡∏≤‡∏ß ‡πÇ‡∏° ‡πÇ‡∏ô 29 # ‡πÄ‡∏™‡∏∑‡∏≠‡∏î‡∏≥ # ‡πÅ‡∏≠‡∏ü‡∏£‡∏¥‡∏Å‡∏≤ # ‡∏™‡∏±‡∏ï‡∏ß‡πå ‡∏´‡∏≤ ‡∏¢‡∏≤‡∏Å # mono29 # mono29news\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ‡πÑ‡∏°‡πà ‡πÄ‡∏à‡∏µ‡∏¢‡∏° ‡πÑ‡∏á ‡πÄ‡∏™‡∏∑‡∏≠‡∏Å ‡πÅ‡∏î‡∏Å ‡∏•‡∏µ‡πÇ‡∏≠\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ‡∏Ü‡πà‡∏≤ ‡∏Ñ‡∏ô‡∏ï‡∏≤‡∏¢ ‡πÇ‡∏ó‡∏©‡πÄ‡∏ö‡∏≤ ‡∏Å‡∏ß‡πà‡∏≤ ‡∏ï‡∏±‡πâ‡∏á ‡πÄ‡∏¢‡∏≠‡∏∞\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ‡πÅ‡∏™‡∏á‡πÇ‡∏™‡∏° ‡∏ô‡∏µ‡πà ‡∏û‡∏±‡∏Å ‡πÄ‡∏ô‡πâ‡∏≠ ‡∏ï‡∏∑‡πà‡∏ô ‡∏¢‡∏≤‡∏Å ‡∏â‡∏¥‡∏ö‡∏´‡∏≤‡∏¢ ‡∏Ç‡∏≥ ‡∏´‡∏±‡∏ß ‡∏≠‡∏µ ‡∏Å.\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ‡∏õ‡∏µ 2018 ‡∏ö‡∏≠ ‡∏Å‡∏ß‡πà‡∏≤ ‡∏î‡∏µ ‡πÅ‡∏ï‡πà ‡∏ï‡∏≠‡∏ô ‡∏ß‡∏µ‡∏≠‡∏≠‡∏™ 2013 ‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå 4 ‡∏™‡∏õ‡∏µ‡∏î ‡∏î‡πà‡∏≤ ‡∏Å‡∏±‡∏ô ‡∏â‡∏¥‡∏ö‡∏´‡∏≤‡∏¢ ‡∏ß‡∏≤‡∏¢ ‡∏õ‡∏ß‡∏á ‡πÄ‡∏≠‡∏≤ ‡∏™‡∏¥\n",
            "True Label: 1, Predicted: 0\n",
            "\n",
            "Text: ‡πÇ‡∏´ ‡∏ö‡∏∏‡∏´‡∏£‡∏µ‡πà ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ ‡∏ô‡∏∂‡∏Å ‡∏ß‡πà‡∏≤ ‡∏Ü‡πà‡∏≤ ‡∏Ñ‡∏ô‡∏ï‡∏≤‡∏¢\n",
            "True Label: 1, Predicted: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9hFtajfCXZx",
        "outputId": "1df20224-ba5d-49d0-dcad-956819476188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to /content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\n"
          ]
        }
      ],
      "source": [
        "# Specify the directory in Google Drive where you want to save the model\n",
        "save_directory = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(save_directory)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {save_directory}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXm6L1GwJJ6_"
      },
      "outputs": [],
      "source": [
        "# Specify destination directory in Google Drive\n",
        "import shutil\n",
        "save_directory = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "\n",
        "# Ensure the destination directory exists\n",
        "!mkdir -p \"{save_directory}\"\n",
        "\n",
        "# Paths to local files\n",
        "files_to_save = {\n",
        "    \"balanced_weakly_labeled_data.csv\": \"/content/balanced_weakly_labeled_data.csv\",\n",
        "    \"preprocessed_wisesight_sentiment.csv\": \"/content/preprocessed_wisesight_sentiment.csv\",\n",
        "    \"toxic_keywords_1.txt\": \"/content/toxic_keywords_1.txt\",\n",
        "    \"weakly_labeled_wisesight_sentiment.csv\": \"/content/weakly_labeled_wisesight_sentiment.csv\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6mFGAJK2BZyA",
        "outputId": "493008cc-a0da-4c7d-fe34-3591f470ae54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load your pre-trained BERT model and tokenizer\n",
        "model_path = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKAmOkkyBsL_",
        "outputId": "05fd0bc9-4e80-43af-f866-a2fea40e5376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized input IDs shape: torch.Size([41566, 128])\n"
          ]
        }
      ],
      "source": [
        "# Load your Thai dataset (replace with your actual file path)\n",
        "data_path = '/content/drive/MyDrive/balanced_weakly_labeled_data.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Clean text function to remove non-Thai characters (optional, depends on dataset)\n",
        "import re\n",
        "def clean_text(text):\n",
        "    return re.sub(r\"[^‡∏Å-‡πô\\s]\", \"\", text)  # Retain only Thai characters and spaces\n",
        "\n",
        "# Apply text cleaning\n",
        "df['cleaned_texts'] = df['texts'].apply(clean_text)\n",
        "\n",
        "# Tokenize the cleaned text using the loaded tokenizer\n",
        "def tokenize_texts(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        padding=True,          # Add padding to ensure equal length sequences\n",
        "        truncation=True,       # Truncate long sequences to max length\n",
        "        max_length=128,        # Adjust max length based on model needs\n",
        "        return_tensors=\"pt\"    # Return as PyTorch tensors\n",
        "    )\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_data = tokenize_texts(df['cleaned_texts'].tolist())\n",
        "print(f\"Tokenized input IDs shape: {tokenized_data['input_ids'].shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "StvnCyIlB6V9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define a custom Dataset class for the tokenized data\n",
        "class ThaiCharacterDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_mask, labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_mask[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "# Convert labels to tensors\n",
        "labels = torch.tensor(df['weak_label'].tolist())\n",
        "\n",
        "# Create Dataset and DataLoader\n",
        "thai_dataset = ThaiCharacterDataset(tokenized_data['input_ids'], tokenized_data['attention_mask'], labels)\n",
        "thai_dataloader = DataLoader(thai_dataset, batch_size=16, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezzGhIMhCAvB",
        "outputId": "40077106-f914-4f2c-ed3b-81ecd693489f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.026647572094142428\n",
            "Epoch 2/3, Loss: 0.01543018503167546\n",
            "Epoch 3/3, Loss: 0.013409500719137747\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "# Set up optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in thai_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(thai_dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jNHW5jQNGfXB",
        "outputId": "54681301-8078-403f-edc6-8c6c0a905f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model and tokenizer saved to /content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Define the directory in Google Drive where you want to save the model\n",
        "save_directory = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "\n",
        "# Save the model\n",
        "model.base_model.save_pretrained(save_directory)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {save_directory}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
        "\n",
        "# Load your fine-tuned BERT model\n",
        "model_path = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "base_model.to(device)\n",
        "\n",
        "# Define a new model with an additional phoneme prediction head\n",
        "class MultiTaskBERT(nn.Module):\n",
        "    def __init__(self, base_model, phoneme_vocab_size):\n",
        "        super(MultiTaskBERT, self).__init__()\n",
        "        self.base_model = base_model  # Main model for hate speech classification\n",
        "        self.phoneme_head = nn.Linear(base_model.config.hidden_size, phoneme_vocab_size)  # Phoneme prediction head\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Get outputs from the BERT model with hidden states\n",
        "        outputs = self.base_model.bert(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "        last_hidden_state = outputs.hidden_states[-1]  # Last hidden layer for phoneme prediction\n",
        "\n",
        "        # Phoneme prediction output (character-level)\n",
        "        phoneme_logits = self.phoneme_head(last_hidden_state)  # Shape: (batch_size, seq_len, phoneme_vocab_size)\n",
        "\n",
        "        # Hate speech classification output\n",
        "        cls_logits = self.base_model.classifier(outputs.pooler_output)  # Shape: (batch_size, num_labels)\n",
        "\n",
        "        return phoneme_logits, cls_logits\n",
        "\n",
        "# Set phoneme vocabulary size (customize based on your data)\n",
        "phoneme_vocab_size = 100  # Adjust based on actual phoneme classes\n",
        "model = MultiTaskBERT(base_model, phoneme_vocab_size).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kWWvjptbG-kj",
        "outputId": "1afee02f-02ef-4850-b4e4-95483227e37f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjkuxICCIfG8",
        "outputId": "47bdd44f-613d-4343-d4fa-85fe34a4d12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phoneme-like labels shape: torch.Size([41566, 128])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pythainlp.tokenize import syllable_tokenize\n",
        "import torch\n",
        "\n",
        "# Load your Thai dataset\n",
        "data_path = '/content/drive/MyDrive/balanced_weakly_labeled_data.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Step 1: Generate syllable tokens as phoneme-like approximations\n",
        "def generate_syllable_tokens(text):\n",
        "    syllables = syllable_tokenize(text, engine='dict')  # Use syllabic segmentation\n",
        "    return syllables\n",
        "\n",
        "df['syllable_tokens'] = df['texts'].apply(generate_syllable_tokens)\n",
        "\n",
        "# Step 2: Create a syllable vocabulary and map syllables to unique IDs\n",
        "syllable_vocab = {}\n",
        "current_id = 0\n",
        "\n",
        "for syllables in df['syllable_tokens']:\n",
        "    for syllable in syllables:\n",
        "        if syllable not in syllable_vocab:\n",
        "            syllable_vocab[syllable] = current_id\n",
        "            current_id += 1\n",
        "\n",
        "# Step 3: Convert syllable sequences to integer sequences\n",
        "def convert_to_ids(sequence):\n",
        "    return [syllable_vocab[syllable] for syllable in sequence]\n",
        "\n",
        "df['syllable_ids'] = df['syllable_tokens'].apply(convert_to_ids)\n",
        "\n",
        "# Step 4: Pad syllable sequences to a fixed length (e.g., 128)\n",
        "max_len = 128\n",
        "def pad_sequence(seq):\n",
        "    if len(seq) < max_len:\n",
        "        return seq + [0] * (max_len - len(seq))  # Pad with 0s for shorter sequences\n",
        "    else:\n",
        "        return seq[:max_len]  # Truncate longer sequences\n",
        "\n",
        "df['syllable_ids_padded'] = df['syllable_ids'].apply(pad_sequence)\n",
        "\n",
        "# Convert to tensor for training\n",
        "phoneme_labels = torch.tensor(df['syllable_ids_padded'].tolist())\n",
        "print(\"Phoneme-like labels shape:\", phoneme_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "67eUN2zwHfev"
      },
      "outputs": [],
      "source": [
        "phoneme_labels = torch.randint(0, phoneme_vocab_size, (len(df), 128))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "# Set up optimizer and loss functions\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "phoneme_loss_fn = CrossEntropyLoss()\n",
        "classification_loss_fn = CrossEntropyLoss()\n",
        "\n",
        "# Training loop with dual losses\n",
        "num_epochs = 3\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_phoneme_loss, total_classification_loss = 0, 0\n",
        "    for batch_idx, batch in enumerate(thai_dataloader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        classification_labels = batch['labels'].to(device)\n",
        "\n",
        "        # Retrieve the corresponding phoneme labels for the current batch\n",
        "        phoneme_label_batch = phoneme_labels[batch_idx * len(input_ids):(batch_idx + 1) * len(input_ids)].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        phoneme_logits, cls_logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Reshape phoneme_logits and phoneme_label_batch to match dimensions\n",
        "        phoneme_logits = phoneme_logits.view(-1, phoneme_vocab_size)  # Shape: (batch_size * seq_len, vocab_size)\n",
        "        phoneme_label_batch = phoneme_label_batch.view(-1)  # Shape: (batch_size * seq_len)\n",
        "\n",
        "        # Calculate phoneme loss\n",
        "        phoneme_loss = phoneme_loss_fn(phoneme_logits, phoneme_label_batch)\n",
        "\n",
        "        # Calculate classification loss\n",
        "        classification_loss = classification_loss_fn(cls_logits, classification_labels)\n",
        "\n",
        "        # Combine losses and optimize\n",
        "        total_loss = phoneme_loss + classification_loss\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_phoneme_loss += phoneme_loss.item()\n",
        "        total_classification_loss += classification_loss.item()\n",
        "\n",
        "    avg_phoneme_loss = total_phoneme_loss / len(thai_dataloader)\n",
        "    avg_classification_loss = total_classification_loss / len(thai_dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Phoneme Loss: {avg_phoneme_loss}, Classification Loss: {avg_classification_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEG5XKROIsnR",
        "outputId": "5b242748-50cc-4015-9c42-9aa4764a9d10"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Phoneme Loss: 4.6098831188137295, Classification Loss: 0.01307484107452516\n",
            "Epoch 2/3, Phoneme Loss: 4.607374034908021, Classification Loss: 0.008522843429922931\n",
            "Epoch 3/3, Phoneme Loss: 4.606879003604069, Classification Loss: 0.01000913630996141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJHzK4NHKO-X",
        "outputId": "7bc30e68-31ff-4afa-f93f-206c20b80a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Phoneme Loss: 3.639465255632687, Classification Loss: 0.024973187675885036\n",
            "Epoch 2/3, Phoneme Loss: 0.1615475686381731, Classification Loss: 0.01320341678564209\n",
            "Epoch 3/3, Phoneme Loss: 0.032623962771285146, Classification Loss: 0.008391529086575604\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "# Set up optimizer and loss functions\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "phoneme_loss_fn = CrossEntropyLoss()\n",
        "classification_loss_fn = CrossEntropyLoss()\n",
        "\n",
        "# Training loop with dual losses\n",
        "num_epochs = 3\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_phoneme_loss, total_classification_loss = 0, 0\n",
        "    for batch in thai_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        classification_labels = batch['labels'].to(device)\n",
        "\n",
        "        # Retrieve the corresponding phoneme labels for the current batch\n",
        "        phoneme_label_batch = phoneme_labels[batch['labels']]  # Ensure this matches batch size\n",
        "        phoneme_label_batch = phoneme_label_batch.to(device)  # Move phoneme labels to device\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        phoneme_logits, cls_logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Reshape phoneme_logits and phoneme_label_batch to match dimensions\n",
        "        phoneme_logits = phoneme_logits.view(-1, phoneme_vocab_size)  # Shape: (batch_size * seq_len, vocab_size)\n",
        "        phoneme_label_batch = phoneme_label_batch.view(-1)  # Shape: (batch_size * seq_len)\n",
        "\n",
        "        # Calculate phoneme loss\n",
        "        phoneme_loss = phoneme_loss_fn(phoneme_logits, phoneme_label_batch)\n",
        "\n",
        "        # Calculate classification loss\n",
        "        classification_loss = classification_loss_fn(cls_logits, classification_labels)\n",
        "\n",
        "        # Combine losses and optimize\n",
        "        total_loss = phoneme_loss + classification_loss\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_phoneme_loss += phoneme_loss.item()\n",
        "        total_classification_loss += classification_loss.item()\n",
        "\n",
        "    avg_phoneme_loss = total_phoneme_loss / len(thai_dataloader)\n",
        "    avg_classification_loss = total_classification_loss / len(thai_dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Phoneme Loss: {avg_phoneme_loss}, Classification Loss: {avg_classification_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jey_QyYRSKan",
        "outputId": "4024e3f8-4997-469a-cfdc-9095d5047971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model state dictionary and tokenizer saved to /content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "\n",
        "# Define the save path in Google Drive\n",
        "save_directory = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "# Save the model's state dictionary\n",
        "model_path = os.path.join(save_directory, \"pytorch_model.bin\")\n",
        "torch.save(model.state_dict(), model_path)\n",
        "\n",
        "# Save the model configuration if applicable (e.g., if you used a Hugging Face configuration object)\n",
        "if hasattr(model, \"config\"):\n",
        "    model.config.save_pretrained(save_directory)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Model state dictionary and tokenizer saved to {save_directory}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vmz3hKneTsI-",
        "outputId": "2a24f5ee-b400-45aa-9360-a9add4d08968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-34-ab372d224baf>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(state_dict_path)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer loaded successfully with partial loading!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Define the save path in Google Drive\n",
        "model_path = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "state_dict_path = f\"{model_path}/pytorch_model.bin\"\n",
        "\n",
        "# Step 1: Initialize the model architecture\n",
        "config_path = \"bert-base-multilingual-cased\"  # Original architecture\n",
        "model = AutoModelForSequenceClassification.from_pretrained(config_path, num_labels=2)  # Adjust labels as needed\n",
        "\n",
        "# Step 2: Load the saved state dictionary with strict=False\n",
        "state_dict = torch.load(state_dict_path)\n",
        "model.load_state_dict(state_dict, strict=False)  # Load only matching parameters\n",
        "\n",
        "# Step 3: Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(config_path)\n",
        "\n",
        "# Move model to the available device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully with partial loading!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6XkFUzHVWcsJ"
      },
      "outputs": [],
      "source": [
        "# Define phoneme prediction layer\n",
        "class MultiTaskBERT(nn.Module):\n",
        "    def __init__(self, base_model, phoneme_vocab_size):\n",
        "        super(MultiTaskBERT, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.phoneme_head = nn.Linear(self.base_model.config.hidden_size, phoneme_vocab_size)  # Phoneme prediction head\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None, phoneme_labels=None):\n",
        "        outputs = self.base_model.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "        phoneme_logits = self.phoneme_head(last_hidden_state)  # Shape: (batch_size, seq_len, phoneme_vocab_size)\n",
        "\n",
        "        return phoneme_logits\n",
        "\n",
        "# Instantiate the MultiTask model\n",
        "phoneme_vocab_size = 30  # Example size (adjust based on phoneme data)\n",
        "multi_task_model = MultiTaskBERT(model, phoneme_vocab_size).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "# Assuming your fine-tuned model is saved in 'model_path'\n",
        "model_path = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "base_model = AutoModel.from_pretrained(model_path, output_hidden_states=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "base_model.to(device)\n",
        "\n",
        "# Define a new model with an additional POS tagging head using the pre-fine-tuned BERT model\n",
        "class MultiTaskBERTWithPOS(nn.Module):\n",
        "    def __init__(self, base_model, pos_vocab_size):\n",
        "        super(MultiTaskBERTWithPOS, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.pos_head = nn.Linear(self.base_model.config.hidden_size, pos_vocab_size)  # POS tagging head\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None, pos_labels=None, output_hidden_states=False):\n",
        "        # Call the base model directly\n",
        "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=output_hidden_states)\n",
        "\n",
        "        # Access last hidden state directly from dictionary output\n",
        "        last_hidden_state = outputs['last_hidden_state']\n",
        "        hidden_states = outputs.get('hidden_states', None)  # Use .get() to avoid KeyError if hidden_states are not present\n",
        "\n",
        "        # POS tagging logits from the last hidden state\n",
        "        pos_logits = self.pos_head(last_hidden_state)  # Shape: (batch_size, seq_len, pos_vocab_size)\n",
        "\n",
        "        # Return dictionary with all relevant outputs\n",
        "        return {\n",
        "            \"last_hidden_state\": last_hidden_state,\n",
        "            \"pos_logits\": pos_logits,\n",
        "            \"hidden_states\": hidden_states\n",
        "        }\n",
        "\n",
        "# Initialize with your model and specified POS vocabulary size\n",
        "pos_vocab_size = 50  # Adjust based on actual POS vocabulary size\n",
        "multi_task_model = MultiTaskBERTWithPOS(base_model=base_model, pos_vocab_size=pos_vocab_size).to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i4hrar0QxWxl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pythainlp.tag import pos_tag\n",
        "from pythainlp import word_tokenize\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\")\n",
        "\n",
        "# Dummy POS vocabulary (expand with actual vocabulary from your dataset)\n",
        "pos_vocab = {\"NOUN\": 0, \"VERB\": 1, \"ADJ\": 2, \"ADV\": 3, \"PRON\": 4, \"DET\": 5, \"CONJ\": 6, \"NUM\": 7, \"PUNCT\": 8}\n",
        "pos_vocab_size = len(pos_vocab)\n",
        "\n",
        "# Function to tokenize and get POS tags\n",
        "def tokenize_and_pos_tag(text):\n",
        "    tokens = word_tokenize(text, engine=\"newmm\")  # Tokenize\n",
        "    pos_tags = [tag for word, tag in pos_tag(tokens, corpus=\"orchid\")]  # POS tagging using PyThaiNLP\n",
        "    return tokens, pos_tags\n",
        "\n",
        "# Function to convert POS tags to indices\n",
        "def pos_to_indices(pos_tags):\n",
        "    return [pos_vocab.get(tag, pos_vocab[\"NOUN\"]) for tag in pos_tags]  # Default to \"NOUN\" if tag is out of vocabulary\n",
        "\n",
        "# Custom Dataset for Multi-Task Learning\n",
        "class ThaiMultiTaskDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and get POS tags\n",
        "        tokens, pos_tags = tokenize_and_pos_tag(self.texts[idx])\n",
        "        pos_indices = pos_to_indices(pos_tags)\n",
        "\n",
        "        # Encode tokens using the tokenizer\n",
        "        encoding = tokenizer(tokens, is_split_into_words=True, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "        # Directly retrieve tensors\n",
        "        input_ids = encoding['input_ids'].squeeze(0)  # Remove batch dimension\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
        "\n",
        "        # Pad or truncate POS tags to match the max length (128)\n",
        "        pos_labels = torch.tensor(pos_indices[:128] + [0] * (128 - len(pos_indices)))\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'pos_labels': pos_labels\n",
        "        }\n",
        "\n",
        "# Prepare DataLoader\n",
        "texts = df['texts'].tolist()  # Assuming your texts are in a DataFrame column named 'texts'\n",
        "thai_dataset = ThaiMultiTaskDataset(texts)\n",
        "thai_dataloader = DataLoader(thai_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "print(\"DataLoader created with POS labels for Thai dataset.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3YXJcGdyYGM",
        "outputId": "21119ac8-e735-43ba-843b-9084e255efd3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoader created with POS labels for Thai dataset.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "# Initialize Multi-Task Model with POS tagging head\n",
        "multi_task_model = MultiTaskBERTWithPOS(base_model=model, pos_vocab_size=pos_vocab_size).to(device)\n",
        "\n",
        "# Define optimizer and loss functions\n",
        "optimizer = AdamW(multi_task_model.parameters(), lr=2e-5)\n",
        "classification_loss_fn = nn.CrossEntropyLoss()\n",
        "pos_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop with dual objectives\n",
        "num_epochs = 3\n",
        "multi_task_model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in thai_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Use tensors directly as they‚Äôre already in the right form\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        pos_labels = batch['pos_labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = multi_task_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Access the outputs using the correct keys\n",
        "        last_hidden_state = outputs[\"last_hidden_state\"]\n",
        "        pos_logits = outputs[\"pos_logits\"]\n",
        "\n",
        "        # Calculate POS tagging loss\n",
        "        pos_loss = pos_loss_fn(pos_logits.view(-1, pos_vocab_size), pos_labels.view(-1))\n",
        "\n",
        "        # Total loss for multi-task\n",
        "        loss = pos_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(thai_dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "TEUO_PQSCx7b",
        "outputId": "12f1d27c-de4c-4f12-f6f2-ecbf00c8d916"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'last_hidden_state'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e5f2423d0023>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_task_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Access the outputs using the correct keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-8ba43ba15952>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels, pos_labels, output_hidden_states)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Access last hidden state directly from dictionary output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlast_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_hidden_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hidden_states'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use .get() to avoid KeyError if hidden_states are not present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0minner_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'last_hidden_state'"
          ]
        }
      ]
    },
    {
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "# Assuming your fine-tuned model is saved in 'model_path'\n",
        "model_path = '/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW'\n",
        "base_model = AutoModel.from_pretrained(model_path, output_hidden_states=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "base_model.to(device)\n",
        "\n",
        "# Define a new model with an additional POS tagging head using the pre-fine-tuned BERT model\n",
        "class MultiTaskBERTWithPOS(nn.Module):\n",
        "    def __init__(self, base_model, pos_vocab_size):\n",
        "        super(MultiTaskBERTWithPOS, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.pos_head = nn.Linear(self.base_model.config.hidden_size, pos_vocab_size)  # POS tagging head\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None, pos_labels=None, output_hidden_states=False):\n",
        "        # Call the base model directly\n",
        "        # Changed model to base_model\n",
        "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=output_hidden_states)\n",
        "\n",
        "        # Access last hidden state directly from dictionary output\n",
        "        last_hidden_state = outputs['last_hidden_state']\n",
        "        hidden_states = outputs.get('hidden_states', None)  # Use .get() to avoid KeyError if hidden_states are not present\n",
        "\n",
        "        # POS tagging logits from the last hidden state\n",
        "        pos_logits = self.pos_head(last_hidden_state)  # Shape: (batch_size, seq_len, pos_vocab_size)\n",
        "\n",
        "        # Return dictionary with all relevant outputs\n",
        "        return {\n",
        "            \"last_hidden_state\": last_hidden_state,\n",
        "            \"pos_logits\": pos_logits,\n",
        "            \"hidden_states\": hidden_states\n",
        "        }\n",
        "\n",
        "# Initialize with your model and specified POS vocabulary size\n",
        "pos_vocab_size = 50  # Adjust based on actual POS vocabulary size\n",
        "multi_task_model = MultiTaskBERTWithPOS(base_model=base_model, pos_vocab_size=pos_vocab_size).to(device)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "TSdz8nJu5dE6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "BRgNufBCetOz"
      },
      "outputs": [],
      "source": [
        "class ThaiMultiTaskDataset(Dataset):\n",
        "    def __init__(self, texts, pos_tags, labels):\n",
        "        self.texts = texts\n",
        "        self.pos_tags = pos_tags\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens, pos_tags = tokenize_and_pos_tag(self.texts[idx])\n",
        "        pos_indices = pos_to_indices(pos_tags)\n",
        "\n",
        "        encoding = tokenizer(tokens, is_split_into_words=True, padding=\"max_length\", truncation=True, max_length=128)\n",
        "        input_ids = torch.tensor(encoding['input_ids'])\n",
        "        attention_mask = torch.tensor(encoding['attention_mask'])\n",
        "        pos_labels = torch.tensor(pos_indices[:128] + [0] * (128 - len(pos_indices)))  # Padding to max length\n",
        "        label = torch.tensor(self.labels[idx])  # Ensure labels are included\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'pos_labels': pos_labels,\n",
        "            'labels': label  # Add labels for hate speech classification\n",
        "        }\n",
        "\n",
        "# Example usage\n",
        "texts = df['texts'].tolist()\n",
        "pos_tags = [pos_to_indices(pos_tag(word_tokenize(text))) for text in texts]\n",
        "labels = df['weak_label'].tolist()  # Ensure this is the hate speech label column\n",
        "\n",
        "thai_dataset = ThaiMultiTaskDataset(texts, pos_tags, labels)\n",
        "thai_dataloader = DataLoader(thai_dataset, batch_size=16, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDxE3OiUeNNe",
        "outputId": "5800f19e-d772-4da7-d252-83c35b1f5252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thai prototypes: tensor([[-0.5080,  0.1452, -0.0776,  ..., -0.0991, -0.9618,  0.0271],\n",
            "        [ 0.1716, -0.0416,  0.7509,  ...,  0.2973,  0.7014, -0.3484]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to extract embeddings for a dataset\n",
        "def extract_embeddings(model, dataloader):\n",
        "    model.eval()\n",
        "    embeddings, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            label = batch['labels'].to(device)\n",
        "\n",
        "            # Get the outputs by calling the model directly\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Adjust this to access the last hidden state appropriately\n",
        "            last_hidden_state = outputs[\"last_hidden_state\"][:, 0, :]  # CLS token embedding\n",
        "            embeddings.append(last_hidden_state)\n",
        "            labels.append(label)\n",
        "\n",
        "    embeddings = torch.cat(embeddings)\n",
        "    labels = torch.cat(labels)\n",
        "    return embeddings, labels\n",
        "\n",
        "\n",
        "# Extract embeddings from the Thai dataset\n",
        "thai_embeddings, thai_labels = extract_embeddings(multi_task_model, thai_dataloader)\n",
        "\n",
        "# Calculate prototypes for each class (hate and non-hate)\n",
        "def calculate_prototypes(embeddings, labels, num_classes=2):\n",
        "    prototypes = []\n",
        "    for label in range(num_classes):\n",
        "        class_embeddings = embeddings[labels == label]\n",
        "        prototype = class_embeddings.mean(dim=0)\n",
        "        prototypes.append(prototype)\n",
        "    return torch.stack(prototypes)\n",
        "\n",
        "thai_prototypes = calculate_prototypes(thai_embeddings, thai_labels)\n",
        "print(\"Thai prototypes:\", thai_prototypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iy7cx5Y8lXzU",
        "outputId": "d8844a11-6ac5-462f-bc55-eb554c07e08f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 10/200, Meta-Loss: 0.5\n",
            "Episode 20/200, Meta-Loss: 0.5\n",
            "Episode 30/200, Meta-Loss: 0.5\n",
            "Episode 40/200, Meta-Loss: 0.5\n",
            "Episode 50/200, Meta-Loss: 0.5\n",
            "Episode 60/200, Meta-Loss: 0.5\n",
            "Episode 70/200, Meta-Loss: 0.5\n",
            "Episode 80/200, Meta-Loss: 1.1078805923461914\n",
            "Episode 90/200, Meta-Loss: 0.5\n",
            "Episode 100/200, Meta-Loss: 0.5\n",
            "Episode 110/200, Meta-Loss: 1.103718638420105\n",
            "Episode 120/200, Meta-Loss: 0.5\n",
            "Episode 130/200, Meta-Loss: 0.5\n",
            "Episode 140/200, Meta-Loss: 0.5\n",
            "Episode 150/200, Meta-Loss: 0.5\n",
            "Episode 160/200, Meta-Loss: 0.5\n",
            "Episode 170/200, Meta-Loss: 0.5\n",
            "Episode 180/200, Meta-Loss: 0.5\n",
            "Episode 190/200, Meta-Loss: 0.5\n",
            "Episode 200/200, Meta-Loss: 0.5\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.optim import RMSprop\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# Updated hyperparameters\n",
        "meta_learning_rate = 1e-4\n",
        "support_set_size = 64\n",
        "query_set_size = 32\n",
        "num_episodes = 200\n",
        "temperature = 0.3  # Reduced temperature for sharper separation\n",
        "margin = 0.5  # Reduced margin in contrastive loss\n",
        "\n",
        "# Initialize optimizer\n",
        "meta_optimizer = RMSprop(multi_task_model.parameters(), lr=meta_learning_rate)\n",
        "\n",
        "# Function to compute prototypes\n",
        "def compute_prototypes(embeddings, labels):\n",
        "    unique_labels = torch.unique(labels)\n",
        "    prototypes = []\n",
        "    for label in unique_labels:\n",
        "        class_embeddings = embeddings[labels == label]\n",
        "        class_prototype = class_embeddings.mean(dim=0)\n",
        "        prototypes.append(class_prototype)\n",
        "    return torch.stack(prototypes)\n",
        "\n",
        "# Function for contrastive loss\n",
        "def contrastive_loss(embeddings, prototypes, labels, margin=margin):\n",
        "    positive_distances = torch.norm(embeddings - prototypes[labels], dim=1)\n",
        "    negative_distances = torch.min(torch.norm(embeddings.unsqueeze(1) - prototypes, dim=2), dim=1)[0]\n",
        "    return F.relu(margin + positive_distances - negative_distances).mean()\n",
        "\n",
        "# Token dropout function\n",
        "def add_token_dropout(embeddings, dropout_rate=0.1):\n",
        "    mask = torch.bernoulli(torch.full(embeddings.shape, 1 - dropout_rate)).to(embeddings.device)\n",
        "    return embeddings * mask\n",
        "\n",
        "# Meta-learning loop\n",
        "for episode in range(num_episodes):\n",
        "    support_indices = np.random.choice(len(thai_labels), size=support_set_size, replace=False)\n",
        "    query_indices = np.random.choice(len(thai_labels), size=query_set_size, replace=False)\n",
        "\n",
        "    support_embeddings = thai_embeddings[support_indices].clone().detach().requires_grad_(True)\n",
        "    support_labels = thai_labels[support_indices]\n",
        "    query_embeddings = thai_embeddings[query_indices].clone().detach().requires_grad_(True)\n",
        "    query_labels = thai_labels[query_indices]\n",
        "\n",
        "    # Apply token dropout\n",
        "    support_embeddings = add_token_dropout(support_embeddings, dropout_rate=0.1)\n",
        "\n",
        "    # Compute prototypes\n",
        "    prototypes = compute_prototypes(support_embeddings, support_labels)\n",
        "\n",
        "    # Distance calculation with temperature scaling\n",
        "    distances = 1 - F.cosine_similarity(query_embeddings.unsqueeze(1), prototypes.unsqueeze(0), dim=2) / temperature\n",
        "    logits = -distances\n",
        "\n",
        "    # Calculate loss with adjusted contrastive loss and gradient penalty\n",
        "    contrastive = contrastive_loss(query_embeddings, prototypes, query_labels)\n",
        "    grad = torch.autograd.grad(contrastive, query_embeddings, create_graph=True)[0]\n",
        "    grad_penalty = (grad.norm(2, dim=1) ** 2).mean() * 0.05  # Reduced penalty weight\n",
        "    loss = contrastive + grad_penalty\n",
        "\n",
        "    # Optimization step\n",
        "    meta_optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    meta_optimizer.step()\n",
        "\n",
        "    if (episode + 1) % 10 == 0:\n",
        "        print(f\"Episode {episode + 1}/{num_episodes}, Meta-Loss: {loss.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EVZZI4Cocz7",
        "outputId": "043ed8e6-9fa2-4cc8-ca47-192b69828948",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model and related data saved to /content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the directory to save the model and create it if it doesn't exist\n",
        "save_directory = '/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes'\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "# Save the model state dictionary\n",
        "torch.save(multi_task_model.state_dict(), f\"{save_directory}/cross_lingual_meta_learning_model_state.pth\")\n",
        "\n",
        "# Save additional data (prototypes and other components if needed)\n",
        "torch.save({\n",
        "    'prototypes': prototypes,  # Save the last computed prototypes\n",
        "    'meta_optimizer_state': meta_optimizer.state_dict()  # Save optimizer state if needed for further training\n",
        "}, f\"{save_directory}/cross_lingual_meta_learning_additional_data.pth\")\n",
        "\n",
        "print(f\"Model and related data saved to {save_directory}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTkYaE8rrEM3",
        "outputId": "8ffc1ce0-2698-4a3e-8e60-a045da9fe2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lao Keywords: ['‡∫Ñ‡∫ß‡∫≤‡∫ç', '‡∫ö‡ªç‡ªà‡∫™‡∫±‡∫î‡∫ï‡∫∞‡∫™‡∫ª‡∫á', '‡∫´‡∫°‡∫≤', '‡∫ï‡ªç‡ªÅ‡∫´‡∫•', '‡ªÇ‡∫á‡ªà', '‡∫ï‡ªà‡ªç‡∫≤', '‡∫ö‡ªâ‡∫≤', '‡∫´‡∫°‡∫≤‡∫ç‡∫ï‡∫¥‡∫Å', '‡∫ä‡∫ª‡ªà‡∫ß', '‡∫Å‡∫∞‡ªÄ‡∫™‡∫µ‡∫°', '‡∫Ñ‡∫ß‡∫≤‡∫°‡∫ä‡∫ª‡ªà‡∫ß', '‡∫õ‡∫±‡∫Å‡∫´‡∫¥‡∫ô‡∫î‡∫≠‡∫ô', '‡ªÇ‡∫Å‡∫á', '‡∫™‡∫±‡∫î', '‡∫≠‡∫≠‡∫Å‡∫Ñ‡ªç‡∫≤‡∫Ñ‡∫¥‡∫î‡ªÄ‡∫´‡∫±‡∫ô', '‡∫•‡∫±‡∫Å‡∫ä‡∫∞‡∫ô‡∫∞', '‡∫´‡∫≠‡∫çfish', '‡∫•‡∫±‡∫á‡ªÅ‡∫™‡∫á', '‡∫õ‡∫ß‡∫Å', '‡∫Ç‡∫µ‡ªâ‡∫Ñ‡ªâ‡∫≤‡∫ô', '‡∫Ç‡∫µ‡ªâ‡ªÄ‡∫´‡∫ç‡∫∑‡ªâ‡∫≠', '‡∫Å‡∫±‡∫°', '‡ªÄ‡∫™‡∫±‡ªâ‡∫ô‡∫õ‡∫∞‡∫™‡∫≤‡∫î', '‡∫î‡∫≠‡∫Å', '‡∫™‡∫ª‡ªâ‡∫ô', '‡∫î‡∫¥‡∫ô‡ªÅ‡∫Æ‡ªà', '‡∫û‡∫ª‡∫ô‡ªÑ‡∫û‡ªà', '‡∫™‡∫¥‡ªà‡∫á‡∫ó‡∫µ‡ªà ', '‡∫´‡∫≠‡∫Å', '‡∫™‡∫≤‡∫°‡∫≤‡∫î', '‡∫Ç‡ªâ‡∫≤', '‡∫≠‡∫±‡∫î‡∫ï‡∫≤‡∫™‡ªà‡∫ß‡∫ô', '‡∫Ç‡∫µ‡ªâ‡∫ä‡ªà‡∫≤‡∫ô', '‡∫ô‡ªâ‡ªç‡∫≤‡ªÄ‡∫Ç‡∫µ‡∫ô', '‡∫Å‡∫∞‡∫´‡∫•‡∫µ‡ªà', '‡∫≠‡∫≠‡∫Å‡∫Ñ‡ªç‡∫≤‡∫Ñ‡∫¥‡∫î‡ªÄ‡∫´‡∫±‡∫ô', '‡ªÄ‡∫ß‡∫ô‡ªÅ‡∫¢‡∫Å', '‡ªÑ‡∫Å‡ªà', '‡∫Ç‡∫µ‡ªâ‡∫õ‡∫¥‡∫ö', '‡ªÄ‡∫™‡∫Ω‡∫Å‡ªç‡∫≤', '‡∫™‡∫±‡∫î‡∫ó‡∫µ‡ªà', '‡∫ä‡∫±‡∫Å‡∫ä‡ªâ‡∫≤', '‡ªÅ‡∫Æ‡∫î/‡ªù‡∫≤', '‡∫Ñ‡∫ß‡∫≤‡∫°‡∫ä‡∫ª‡ªà‡∫ß']\n",
            "Khmer Keywords: ['·ûö·ûÄ·ûî·û∏', '·ûò·û∑·ûì·ûü·üí·ûò·üÑ·üá·ûè·üí·ûö·ûÑ·üã', '·ûÜ·üí·ûÄ·üÅ', '·ûÄ·û∂·ûò·ûè·üÅ', '·ûï·üí·ûõ·û∏·ûï·üí·ûõ·ûæ', '·ûè·û∂·ûî', '·ûà·üí·ûÄ·ûº', '·ûÖ·üÉ', '·û¢·û∂·ûö·ûÄ·ûÄ·üã', '·ûÄ·û∂·ûö·û∏·ûà·û∏', '·ûä·üÅ·ûõ·ûÄ·üí·ûï·û∂·ûì·ûü·û∏·ûõ·ûí·üç·ûò', '·ûï·û∂·ûî', '·ûê·üí·ûñ·û∂·ûõ·üã', '·ûü·ûè·ûú', '·ûö·ûò·û∂·üÜn', '·ûÖ·ûö·û∑·ûè·ûö·ûî·û∂', '·ûü·üÇ·ûõ·û†·üí·ûú·û∏', '·ûè·û∂·ûö·ûª·ûÑ·ûö·ûø·ûÑ', '·ûÄ·ûì·üí·ûä·üí·ûô·üÅ·ûú', 'scurlilog', '·ûü·ûò·ûì·ûõ·üã·ûî·û∑·ûï·üí·ûë·û†·ûî·û∂·ûô', '·ûú·û∂·ûü·ûì·û∂', '·ûü·ûö·ûü·üÉ·ûö·ûî·ûü·û∂·ûè', '·ûï·üí·ûÄ·û∂', '·ûÄ·üÅ·ûÑ·ûÖ·ûæ·ûÑ', '·ûÄ·û∂·ûö·ûö·ûî·ûô·üê·ûî·ûì·üç', '·ûÄ·û∂·ûö·ûí·üÅ·ûú·û∏·ûî·üÅ·ûÄ·ûÖ·û∑·ûè·üç', '·û¢·üí·ûú·û∏·ûä·üÇ·ûõ heck ·ûì·üÅ·üá!', '·ûõ·ûò·ûî·üÅ·ûÑ', '·û¢·û∂·ûÖ', '·ûü·ûò·üí·ûõ·û∂·ûî·üã', '·ûü·ûò·û∂·ûò·û∂·ûö·ûè', '·ûö·ûî·ûü·ûï·û∂·ûî', '·ûâ·û∑·ûö·ûî·ûª·ûè', '·ûü·üí·ûõ·ûè·üã', '·ûö·ûò·û∂·üÜn', '·ûÄ·ûü·üÜ·ûé·ûπ·ûÄ', '·ûü·û∂·ûÄ·ûü·ûò', '·ûÄ·ûò·ûì·û∑·ûè·û•·ûè·ûÅ·üí·ûõ·ûπ·ûò·ûü·û∂·ûö', '·ûï·û∂·ûî·ûõ·üí·û¢', '·ûÖ·û∂·û†·ûè·ûª·ûö', '·ûî·û∂·ûì·ûê·ûô·ûÖ·ûª·üá', '·ûü·ûè·ûú·ûö·ûò·û∂·ûü', '·ûä·üÅ·ûõ·ûÄ·üí·ûï·û∂·ûì·ûü·û∏·ûõ·ûí·üç·ûò']\n",
            "Shan Keywords: ['·ÄÄ·Äº·Äæ·Ä≤', '·Äô·Äõ·Ä≠·ÄØ·Ä∏·Äô·Äû·Ä¨·Ä∏·Äñ·Äº·ÄÖ·Ä∫·Äú·Ä≠·Äô·Ä∑·Ä∫·Äô·Ää·Ä∫', '·ÄÅ·Ä±·Äæ·Ä∏', '·Ä°·Äñ·ÄÖ·Ä∫', '·Ä°·Äú·ÄΩ·Äî·Ä∫·Äë·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏·Äû·Ä±·Ä¨', '·Äî·Ä≠·Äô·Ä∑·Ä∫·Äû·Ä±·Ä¨', '·ÄÖ·Ä≠·Äê·Ä∫·Äî·Ä±·Ä¨·ÄÄ·Ä∫·Äû·Ä±·Ä¨', '·Äõ·Äæ·Äï·Ä≠·ÄØ·Ä∏', '·ÄÜ·Ä≠·ÄØ·Ä∏·Äû·Ä±·Ä¨', '·Äü·ÄÑ·Ä∫·Ä∏', '·ÄÜ·Ä≠·ÄØ·Ä∏·Äû·Ä±·Ä¨', 'pimp', '·ÄÅ·Äª·Äô·Ä∫·Ä∏·Äï·Ä±·Äº·Ä¨', '·Äê·Ä≠·Äõ·ÄÖ·Ä¨·Äπ·ÄÜ·Äî·Ä∫', '·Äû·Ä±·Äê·Ä¨·Äï·Ä≤', '·Äõ·Ä≠·ÄØ', '·ÄÅ·ÄΩ·Ä∂', '·Äô·Äë·Ä≠·ÄÅ·Ä≠·ÄØ·ÄÄ·Ä∫·Äû·Ä±·Ä¨', '·ÄÅ·Äº·ÄÄ·Ä±·Ä¨·ÄÑ·Ä∫', '·ÄÄ·Äº·ÄÆ·Ä∏·ÄÖ·ÄΩ·Ä¨·Äû·Ä±·Ä¨', '·Äô·ÄÆ·Ä∏·Äñ·Ä≠·ÄØ·Ä°·Äô·Ä≠·Äæ·ÄØ·ÄÄ·Ä∫', '·ÄÄ·Äº·Äô·Äπ·Äô·Ä¨', '·Ä°·Ä¨·Äõ·ÄØ·Ä∂·ÄÄ·Ä±·Äº·Ä¨', '·Äï·Äî·Ä∫·Ä∏', '·ÄÅ·Ä±·Äº·Äñ·Äî·Ä±·Ä¨·ÄÑ·Ä∑·Ä∫', 'mincing', 'proletarian ·Ä°·Äò·Ä≠·Äì·Ä´·Äî·Ä∫·Äô·Äæ·Äú·Äæ·Ä≠·ÄØ·ÄÄ·Ä∫·Äú·Äæ·Ä≤·ÄÖ·ÄΩ·Ä¨·ÄÄ·Äº·Ä≠·ÄØ·ÄÜ·Ä≠·ÄØ·Äï·Ä´·Äû·Ää·Ä∫', '·Ä°·Äò·Äö·Ä∫·Ä°·Äõ·Ä¨·ÄÄ·Ä≠·ÄØ heck!', '·Äú·Äæ·Ä∂·Äê·Ä∂', '·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫', '·Äû·Äê·Ä∫·Äñ·Äº·Äê·Ä∫', '·Ä°·ÄÅ·Äª·Ä≠·ÄØ·Ä∏·Ä°·ÄÖ·Ä¨·Ä∏', '·Ä°·Äê·Ä∞·Äï·ÄÑ·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏', '·Äô·Ä≠·Äî·Ä∫·Ä∏·Äô·ÄÇ·Äª·ÄÑ·Ä∫·Äú·ÄÑ·Ä∫·Ä∏', 'slut', '·Äû·Ä±·Äê·Ä¨·Äï·Ä≤', '·ÄÄ·Äª·Äî·Ä∫·Äõ·Äæ·Ä≠·Äû·Ä±·Ä¨', '·ÄÄ·Äº·ÄÄ·Ä∫', '·Ä°·Äô·Äæ·ÄØ·Ä≠·ÄÄ·Ä∫', '·Äî·Ä¨·ÄÄ·Äª·ÄÑ·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏', '·ÄÄ·Ä±·Äª·Ä¨·Ä∫·Äõ·Ä±·Äæ', '·Äî·Ä±·Ä¨·ÄÄ·Ä∫·ÄÄ·Äª', '·ÄÄ·Äº·Ä∂·Ä∑·ÄÄ·Ä±·Ä¨·ÄÑ·Ä∫', '·ÄÜ·Ä≠·ÄØ·Ä∏·Äû·Ä±·Ä¨']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV containing the hate keywords for each language\n",
        "keywords_path = '/content/Toxic_Words_translations.csv'  # Replace with your actual file path\n",
        "keywords_df = pd.read_csv(keywords_path)\n",
        "\n",
        "# Extract keywords for each language as lists, removing any NaN values\n",
        "keywords_lao = keywords_df['Lao'].dropna().tolist()\n",
        "keywords_khmer = keywords_df['Khmer'].dropna().tolist()\n",
        "keywords_shan = keywords_df['Shan'].dropna().tolist()\n",
        "\n",
        "# Verify the keywords were loaded correctly\n",
        "print(\"Lao Keywords:\", keywords_lao)\n",
        "print(\"Khmer Keywords:\", keywords_khmer)\n",
        "print(\"Shan Keywords:\", keywords_shan)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nP4k_U3NrjcA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "# Generating synthetic few-shot datasets using keywords\n",
        "def generate_few_shot_dataset(keywords, num_samples=10, non_hate_text=\"this is a neutral sentence\"):\n",
        "    \"\"\"Generate a few-shot dataset using keywords for hate and a generic non-hate sentence.\"\"\"\n",
        "    dataset = []\n",
        "    # Positive samples using keywords\n",
        "    for _ in range(num_samples // 2):\n",
        "        text = random.choice(keywords)\n",
        "        dataset.append((text, 1))  # Label 1 for hate\n",
        "    # Negative samples\n",
        "    for _ in range(num_samples // 2):\n",
        "        dataset.append((non_hate_text, 0))  # Label 0 for non-hate\n",
        "    return dataset\n",
        "\n",
        "# Generating few-shot datasets for each language\n",
        "few_shot_data_lao = generate_few_shot_dataset(keywords_lao)\n",
        "few_shot_data_khmer = generate_few_shot_dataset(keywords_khmer)\n",
        "few_shot_data_shan = generate_few_shot_dataset(keywords_shan)\n",
        "\n",
        "# Wrap into DataLoader for batch processing\n",
        "class FewShotDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text, label = self.data[idx]\n",
        "        encoding = self.tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", max_length=128, truncation=True)\n",
        "        input_ids = encoding[\"input_ids\"].squeeze()\n",
        "        attention_mask = encoding[\"attention_mask\"].squeeze()\n",
        "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"label\": torch.tensor(label)}\n",
        "\n",
        "\n",
        "# Load the tokenizer (use the name of your pre-trained model)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\")  # Replace with your specific model if different\n",
        "batch_size = 4\n",
        "\n",
        "few_shot_loader_lao = DataLoader(FewShotDataset(few_shot_data_lao, tokenizer), batch_size=batch_size)\n",
        "few_shot_loader_khmer = DataLoader(FewShotDataset(few_shot_data_khmer, tokenizer), batch_size=batch_size)\n",
        "few_shot_loader_shan = DataLoader(FewShotDataset(few_shot_data_shan, tokenizer), batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "YSC3tyJIrv7p"
      },
      "outputs": [],
      "source": [
        "def update_prototypes_with_few_shot(model, dataloader, initial_prototypes, embedding_dim=768):\n",
        "    \"\"\"Refine prototypes using few-shot data.\"\"\"\n",
        "    model.eval()\n",
        "    refined_prototypes = initial_prototypes.clone()\n",
        "\n",
        "    num_classes = initial_prototypes.shape[0]\n",
        "    refined_prototypes = refined_prototypes.to(device)\n",
        "    all_embeddings, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Attempt to use pooled output if available, otherwise use [CLS] token embedding\n",
        "            if 'pooler_output' in outputs and outputs['pooler_output'] is not None:\n",
        "                embeddings = outputs['pooler_output']\n",
        "            elif 'last_hidden_state' in outputs:\n",
        "                # Use [CLS] token (first token) from last hidden state as a fallback\n",
        "                embeddings = outputs['last_hidden_state'][:, 0, :]  # Shape: (batch_size, embedding_dim)\n",
        "            else:\n",
        "                raise ValueError(\"Neither 'pooler_output' nor 'last_hidden_state' found in model outputs\")\n",
        "\n",
        "            if embeddings.shape[1] != embedding_dim:\n",
        "                raise ValueError(f\"Embedding dimension mismatch. Expected {embedding_dim}, got {embeddings.shape[1]}\")\n",
        "\n",
        "            all_embeddings.append(embeddings)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    # Concatenate all embeddings and labels\n",
        "    all_embeddings = torch.cat(all_embeddings)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    # Update prototypes based on embeddings\n",
        "    for label in range(num_classes):\n",
        "        class_embeddings = all_embeddings[all_labels == label]\n",
        "        if class_embeddings.shape[0] > 0:  # Check that there are embeddings for this class\n",
        "            refined_prototypes[label] = class_embeddings.mean(dim=0)\n",
        "\n",
        "    return refined_prototypes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update prototypes for each language\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "embedding_dim = 768  # Expected embedding dimension\n",
        "\n",
        "# Ensure prototypes tensor matches the expected size (e.g., 2 classes for hate/non-hate, 768 embedding size)\n",
        "prototypes = torch.zeros((2, embedding_dim), device=device)\n",
        "\n",
        "updated_prototypes_lao = update_prototypes_with_few_shot(multi_task_model, few_shot_loader_lao, prototypes, embedding_dim)\n",
        "updated_prototypes_khmer = update_prototypes_with_few_shot(multi_task_model, few_shot_loader_khmer, prototypes, embedding_dim)\n",
        "updated_prototypes_shan = update_prototypes_with_few_shot(multi_task_model, few_shot_loader_shan, prototypes, embedding_dim)\n"
      ],
      "metadata": {
        "id": "QVxyN-s9OduC"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmN_Iqkr8opD",
        "outputId": "e4ec6af8-55c9-4d79-a500-7b17a6cc071c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-shot fine-tuning complete and refined prototypes saved.\n"
          ]
        }
      ],
      "source": [
        "# Save updated prototypes\n",
        "torch.save({\n",
        "    'prototypes_lao': updated_prototypes_lao,\n",
        "    'prototypes_khmer': updated_prototypes_khmer,\n",
        "    'prototypes_shan': updated_prototypes_shan\n",
        "}, \"/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes/updated_prototypes_few_shot.pth\")\n",
        "\n",
        "print(\"Few-shot fine-tuning complete and refined prototypes saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XuswlMxq9VI0",
        "outputId": "c78d5e22-b6dd-4c8b-932a-b16ee28a502b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-4aa89a1aaf21>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  multi_task_model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "<ipython-input-49-4aa89a1aaf21>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  updated_prototypes = torch.load(prototype_path)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "\n",
        "# Load the saved model state dictionary\n",
        "model_path = '/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes/cross_lingual_meta_learning_model_state.pth'\n",
        "multi_task_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "multi_task_model.to(device)\n",
        "multi_task_model.eval()\n",
        "\n",
        "# Load updated prototypes\n",
        "prototype_path = '/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes/updated_prototypes_few_shot.pth'\n",
        "updated_prototypes = torch.load(prototype_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YvilE4UpCK_u",
        "outputId": "f675cc30-3a67-4af5-8c18-9db8585226b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Sample:\n",
            "                                                 text  label\n",
            "0  ‡πÑ‡∏õ ‡∏à‡∏≠‡∏á ‡∏°‡∏≤ ‡πÅ‡∏•‡πâ ‡∏ß‡∏ô‡∏≤ ‡∏à‡∏≤   mitsubishi   attrage   ...    NaN\n",
            "1  ‡πÄ‡∏õ‡∏¥‡∏î ‡∏®‡∏±‡∏Å‡∏£‡∏≤‡∏ä ‡πÉ‡∏´‡∏°‡πà !   ‡∏ô‡∏≤‡∏¢‡∏Å‡∏Ø   ‡πÅ‡∏ñ‡∏•‡∏á‡∏Ç‡πà‡∏≤‡∏ß ‡∏Å‡πà‡∏≠‡∏ô ‡∏Å‡∏≤‡∏£...    NaN\n",
            "2                      ‡∏ö‡∏±‡∏ï‡∏£‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å ‡∏•‡∏î ‡πÑ‡∏î‡πâ ‡∏≠‡∏µ‡∏Å ‡πÑ‡∏´‡∏° ‡∏Ñ‡∏±‡∏ö    NaN\n",
            "3                          ‡∏™‡∏ô‡πÉ‡∏à   new   mazda 2 ‡∏Ñ‡∏£‡∏±‡∏ö    NaN\n",
            "4                                                 üòçüòç    NaN\n",
            "Post-Cleaning Data Sample:\n",
            "                                                 text  label\n",
            "0  ‡πÑ‡∏õ ‡∏à‡∏≠‡∏á ‡∏°‡∏≤ ‡πÅ‡∏•‡πâ ‡∏ß‡∏ô‡∏≤ ‡∏à‡∏≤ mitsubishi attrage ‡πÑ‡∏î‡πâ ‡∏´‡∏•...    NaN\n",
            "1  ‡πÄ‡∏õ‡∏¥‡∏î ‡∏®‡∏±‡∏Å‡∏£‡∏≤‡∏ä ‡πÉ‡∏´‡∏°‡πà ! ‡∏ô‡∏≤‡∏¢‡∏Å‡∏Ø ‡πÅ‡∏ñ‡∏•‡∏á‡∏Ç‡πà‡∏≤‡∏ß ‡∏Å‡πà‡∏≠‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á...    NaN\n",
            "2                      ‡∏ö‡∏±‡∏ï‡∏£‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å ‡∏•‡∏î ‡πÑ‡∏î‡πâ ‡∏≠‡∏µ‡∏Å ‡πÑ‡∏´‡∏° ‡∏Ñ‡∏±‡∏ö    NaN\n",
            "3                              ‡∏™‡∏ô‡πÉ‡∏à new mazda 2 ‡∏Ñ‡∏£‡∏±‡∏ö    NaN\n",
            "4                                                 üòçüòç    NaN\n",
            "Post-Truncating Data Sample:\n",
            "                                                 text  label\n",
            "0  ‡πÑ‡∏õ ‡∏à‡∏≠‡∏á ‡∏°‡∏≤ ‡πÅ‡∏•‡πâ ‡∏ß‡∏ô‡∏≤ ‡∏à‡∏≤ mitsubishi attrage ‡πÑ‡∏î‡πâ ‡∏´‡∏•...    NaN\n",
            "1  ‡πÄ‡∏õ‡∏¥‡∏î ‡∏®‡∏±‡∏Å‡∏£‡∏≤‡∏ä ‡πÉ‡∏´‡∏°‡πà ! ‡∏ô‡∏≤‡∏¢‡∏Å‡∏Ø ‡πÅ‡∏ñ‡∏•‡∏á‡∏Ç‡πà‡∏≤‡∏ß ‡∏Å‡πà‡∏≠‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á...    NaN\n",
            "2                      ‡∏ö‡∏±‡∏ï‡∏£‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å ‡∏•‡∏î ‡πÑ‡∏î‡πâ ‡∏≠‡∏µ‡∏Å ‡πÑ‡∏´‡∏° ‡∏Ñ‡∏±‡∏ö    NaN\n",
            "3                              ‡∏™‡∏ô‡πÉ‡∏à new mazda 2 ‡∏Ñ‡∏£‡∏±‡∏ö    NaN\n",
            "4                                                 üòçüòç    NaN\n",
            "Initial Data Sample:\n",
            "                                                 text  label\n",
            "0                        ‡∫ç‡∫ª‡∫ô‡∫£‡∫ª‡∫ö‡∫£‡∫±‡∫™‡ªÄ‡∫ä‡∫±‡∫ç‡∫ö‡ªç‡ªà‡∫°‡∫µ  ‡∫ö‡ªç‡ªà‡∫ó‡ªà‡∫≤‡∫ô    NaN\n",
            "1  ‡∫ï‡ªâ‡∫≠‡∫á‡∫ó‡∫≥‡ªÅ‡∫ö‡∫ö‡∫ô‡∫µ‡ªâ‡∫•‡∫∞ ‡∫î‡∫µ‡∫ó‡∫µ‡ªà‡∫™‡∫∏‡∫î‚Äã ‡∫à‡∫∞‡ªù‡∫ª‡∫î‡∫û‡∫ß‡∫Å‡∫≠‡∫±‡∫ö‡∫õ‡∫µ‡ªÑ‡∫õ‡∫à‡∫≤‡∫Å‡∫õ‡∫∞‡ªÄ...    NaN\n",
            "2                                               ‡∫™‡∫≤‡∫ó‡∫∏    NaN\n",
            "3                                       ‡ªÄ‡∫ö‡∫¥‡ªà‡∫á‡∫´‡∫ô‡ªâ‡∫≤‡ªÅ‡∫î‡ªà    NaN\n",
            "4                               ‡∫à‡∫±‡∫ö‡ªÑ‡∫î‡ªâ‡∫ï‡∫≠‡ªâ‡∫á‡∫õ‡∫∞‡∫´‡∫≤‡∫ô‡∫ä‡∫¥‡∫ß‡∫¥‡∫î    NaN\n",
            "Post-Cleaning Data Sample:\n",
            "                                                 text  label\n",
            "0                         ‡∫ç‡∫ª‡∫ô‡∫£‡∫ª‡∫ö‡∫£‡∫±‡∫™‡ªÄ‡∫ä‡∫±‡∫ç‡∫ö‡ªç‡ªà‡∫°‡∫µ ‡∫ö‡ªç‡ªà‡∫ó‡ªà‡∫≤‡∫ô    NaN\n",
            "1  ‡∫ï‡ªâ‡∫≠‡∫á‡∫ó‡∫≥‡ªÅ‡∫ö‡∫ö‡∫ô‡∫µ‡ªâ‡∫•‡∫∞ ‡∫î‡∫µ‡∫ó‡∫µ‡ªà‡∫™‡∫∏‡∫î‚Äã ‡∫à‡∫∞‡ªù‡∫ª‡∫î‡∫û‡∫ß‡∫Å‡∫≠‡∫±‡∫ö‡∫õ‡∫µ‡ªÑ‡∫õ‡∫à‡∫≤‡∫Å‡∫õ‡∫∞‡ªÄ...    NaN\n",
            "2                                               ‡∫™‡∫≤‡∫ó‡∫∏    NaN\n",
            "3                                       ‡ªÄ‡∫ö‡∫¥‡ªà‡∫á‡∫´‡∫ô‡ªâ‡∫≤‡ªÅ‡∫î‡ªà    NaN\n",
            "4                               ‡∫à‡∫±‡∫ö‡ªÑ‡∫î‡ªâ‡∫ï‡∫≠‡ªâ‡∫á‡∫õ‡∫∞‡∫´‡∫≤‡∫ô‡∫ä‡∫¥‡∫ß‡∫¥‡∫î    NaN\n",
            "Post-Truncating Data Sample:\n",
            "                                                 text  label\n",
            "0                         ‡∫ç‡∫ª‡∫ô‡∫£‡∫ª‡∫ö‡∫£‡∫±‡∫™‡ªÄ‡∫ä‡∫±‡∫ç‡∫ö‡ªç‡ªà‡∫°‡∫µ ‡∫ö‡ªç‡ªà‡∫ó‡ªà‡∫≤‡∫ô    NaN\n",
            "1  ‡∫ï‡ªâ‡∫≠‡∫á‡∫ó‡∫≥‡ªÅ‡∫ö‡∫ö‡∫ô‡∫µ‡ªâ‡∫•‡∫∞ ‡∫î‡∫µ‡∫ó‡∫µ‡ªà‡∫™‡∫∏‡∫î‚Äã ‡∫à‡∫∞‡ªù‡∫ª‡∫î‡∫û‡∫ß‡∫Å‡∫≠‡∫±‡∫ö‡∫õ‡∫µ‡ªÑ‡∫õ‡∫à‡∫≤‡∫Å‡∫õ‡∫∞‡ªÄ...    NaN\n",
            "2                                               ‡∫™‡∫≤‡∫ó‡∫∏    NaN\n",
            "3                                       ‡ªÄ‡∫ö‡∫¥‡ªà‡∫á‡∫´‡∫ô‡ªâ‡∫≤‡ªÅ‡∫î‡ªà    NaN\n",
            "4                               ‡∫à‡∫±‡∫ö‡ªÑ‡∫î‡ªâ‡∫ï‡∫≠‡ªâ‡∫á‡∫õ‡∫∞‡∫´‡∫≤‡∫ô‡∫ä‡∫¥‡∫ß‡∫¥‡∫î    NaN\n",
            "Initial Data Sample:\n",
            "                                                 text  label\n",
            "0  ·Äë·ÄΩ·Äô·Ä∫·Çá·Äö·Äù·Ä∫·Çâ·Åµ·Ä≠·Åº·Ä∫·Å∏·ÇÇ·Ä∫‚Äã·Äê·Ä±·Çâ·Åµ·ÇÇ·Å¢·Äô·Ä∫·Ä∏·ÇÅ·Ä∞·Äù·Ä∫·Åº·ÇÜ·Çâ ·Åº·Äô·Ä∫·Çâ·Äê·ÇÉ·Äö·Ä≠·ÄØ·ÄÑ·Ä∫·Çà...    NaN\n",
            "1                                 ·Äú·ÄÆ·Äë·ÄΩ·Äô·Ä∫·Çá·Äê·Ä±·Çâ·Äö·Äù·Ä∫·Çâ·Å∂·ÇÉ·Çà·Åã    NaN\n",
            "2                                             ·Å∂·Ä≠·ÄØ·Åµ·Ä∫·Çâ    NaN\n",
            "3            ·Äú·ÄØ·Åµ·Ä∫·Çà·Äú·Å¢·Åº·Ä∫·Äê·ÇÜ·Ä∏·Äú·ÄØ·Åµ·Ä∫·Çà·ÇÅ·ÄØ·Åº·Ä∫·Çà·Äô·ÇÇ·Ä∫·Çá·ÇÅ·Äù·Ä∫·Ä∏·Äô·Ä≠·Ä∞·Äù·Ä∫·Ä∏·Åº·ÇÉ·Çà    NaN\n",
            "4  ·Äô·ÇÇ·Ä∫·Çá·Äû·ÄØ·ÄÑ·Ä∫·Å∂·ÇÉ·Çà·Å∂·ÇÉ·Çà·ÇÅ·Äù·Ä∫·Ä∏·Äú·ÇÜ·Çà·ÇÅ·Åº·Ä∫·Å∏·ÄØ·Äô·Ä∫·Ä∏·Å∂·Äù·Ä∫·Çá·ÅΩ·Ä∞·Çà·Äê·ÄΩ·ÇÜ·Çá·ÇÅ·ÄΩ·Åµ·Ä∫·Çà·Äô...    NaN\n",
            "Post-Cleaning Data Sample:\n",
            "                                                 text  label\n",
            "0  ·Äë·ÄΩ·Äô·Ä∫·Çá·Äö·Äù·Ä∫·Çâ·Åµ·Ä≠·Åº·Ä∫·Å∏·ÇÇ·Ä∫‚Äã·Äê·Ä±·Çâ·Åµ·ÇÇ·Å¢·Äô·Ä∫·Ä∏·ÇÅ·Ä∞·Äù·Ä∫·Åº·ÇÜ·Çâ ·Åº·Äô·Ä∫·Çâ·Äê·ÇÉ·Äö·Ä≠·ÄØ·ÄÑ·Ä∫·Çà...    NaN\n",
            "1                                 ·Äú·ÄÆ·Äë·ÄΩ·Äô·Ä∫·Çá·Äê·Ä±·Çâ·Äö·Äù·Ä∫·Çâ·Å∂·ÇÉ·Çà·Åã    NaN\n",
            "2                                             ·Å∂·Ä≠·ÄØ·Åµ·Ä∫·Çâ    NaN\n",
            "3            ·Äú·ÄØ·Åµ·Ä∫·Çà·Äú·Å¢·Åº·Ä∫·Äê·ÇÜ·Ä∏·Äú·ÄØ·Åµ·Ä∫·Çà·ÇÅ·ÄØ·Åº·Ä∫·Çà·Äô·ÇÇ·Ä∫·Çá·ÇÅ·Äù·Ä∫·Ä∏·Äô·Ä≠·Ä∞·Äù·Ä∫·Ä∏·Åº·ÇÉ·Çà    NaN\n",
            "4  ·Äô·ÇÇ·Ä∫·Çá·Äû·ÄØ·ÄÑ·Ä∫·Å∂·ÇÉ·Çà·Å∂·ÇÉ·Çà·ÇÅ·Äù·Ä∫·Ä∏·Äú·ÇÜ·Çà·ÇÅ·Åº·Ä∫·Å∏·ÄØ·Äô·Ä∫·Ä∏·Å∂·Äù·Ä∫·Çá·ÅΩ·Ä∞·Çà·Äê·ÄΩ·ÇÜ·Çá·ÇÅ·ÄΩ·Åµ·Ä∫·Çà·Äô...    NaN\n",
            "Post-Truncating Data Sample:\n",
            "                                                 text  label\n",
            "0  ·Äë·ÄΩ·Äô·Ä∫·Çá·Äö·Äù·Ä∫·Çâ·Åµ·Ä≠·Åº·Ä∫·Å∏·ÇÇ·Ä∫‚Äã·Äê·Ä±·Çâ·Åµ·ÇÇ·Å¢·Äô·Ä∫·Ä∏·ÇÅ·Ä∞·Äù·Ä∫·Åº·ÇÜ·Çâ ·Åº·Äô·Ä∫·Çâ·Äê·ÇÉ·Äö·Ä≠·ÄØ·ÄÑ·Ä∫·Çà...    NaN\n",
            "1                                 ·Äú·ÄÆ·Äë·ÄΩ·Äô·Ä∫·Çá·Äê·Ä±·Çâ·Äö·Äù·Ä∫·Çâ·Å∂·ÇÉ·Çà·Åã    NaN\n",
            "2                                             ·Å∂·Ä≠·ÄØ·Åµ·Ä∫·Çâ    NaN\n",
            "3            ·Äú·ÄØ·Åµ·Ä∫·Çà·Äú·Å¢·Åº·Ä∫·Äê·ÇÜ·Ä∏·Äú·ÄØ·Åµ·Ä∫·Çà·ÇÅ·ÄØ·Åº·Ä∫·Çà·Äô·ÇÇ·Ä∫·Çá·ÇÅ·Äù·Ä∫·Ä∏·Äô·Ä≠·Ä∞·Äù·Ä∫·Ä∏·Åº·ÇÉ·Çà    NaN\n",
            "4  ·Äô·ÇÇ·Ä∫·Çá·Äû·ÄØ·ÄÑ·Ä∫·Å∂·ÇÉ·Çà·Å∂·ÇÉ·Çà·ÇÅ·Äù·Ä∫·Ä∏·Äú·ÇÜ·Çà·ÇÅ·Åº·Ä∫·Å∏·ÄØ·Äô·Ä∫·Ä∏·Å∂·Äù·Ä∫·Çá·ÅΩ·Ä∞·Çà·Äê·ÄΩ·ÇÜ·Çá·ÇÅ·ÄΩ·Åµ·Ä∫·Çà·Äô...    NaN\n",
            "Final Thai Data Sample:\n",
            "                                                 text  label\n",
            "0  ‡πÑ‡∏õ ‡∏à‡∏≠‡∏á ‡∏°‡∏≤ ‡πÅ‡∏•‡πâ ‡∏ß‡∏ô‡∏≤ ‡∏à‡∏≤ mitsubishi attrage ‡πÑ‡∏î‡πâ ‡∏´‡∏•...    NaN\n",
            "1  ‡πÄ‡∏õ‡∏¥‡∏î ‡∏®‡∏±‡∏Å‡∏£‡∏≤‡∏ä ‡πÉ‡∏´‡∏°‡πà ! ‡∏ô‡∏≤‡∏¢‡∏Å‡∏Ø ‡πÅ‡∏ñ‡∏•‡∏á‡∏Ç‡πà‡∏≤‡∏ß ‡∏Å‡πà‡∏≠‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á...    NaN\n",
            "2                      ‡∏ö‡∏±‡∏ï‡∏£‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å ‡∏•‡∏î ‡πÑ‡∏î‡πâ ‡∏≠‡∏µ‡∏Å ‡πÑ‡∏´‡∏° ‡∏Ñ‡∏±‡∏ö    NaN\n",
            "3                              ‡∏™‡∏ô‡πÉ‡∏à new mazda 2 ‡∏Ñ‡∏£‡∏±‡∏ö    NaN\n",
            "4                                                 üòçüòç    NaN\n",
            "\n",
            "Final Lao Data Sample:\n",
            "                                                 text  label\n",
            "0                         ‡∫ç‡∫ª‡∫ô‡∫£‡∫ª‡∫ö‡∫£‡∫±‡∫™‡ªÄ‡∫ä‡∫±‡∫ç‡∫ö‡ªç‡ªà‡∫°‡∫µ ‡∫ö‡ªç‡ªà‡∫ó‡ªà‡∫≤‡∫ô    NaN\n",
            "1  ‡∫ï‡ªâ‡∫≠‡∫á‡∫ó‡∫≥‡ªÅ‡∫ö‡∫ö‡∫ô‡∫µ‡ªâ‡∫•‡∫∞ ‡∫î‡∫µ‡∫ó‡∫µ‡ªà‡∫™‡∫∏‡∫î‚Äã ‡∫à‡∫∞‡ªù‡∫ª‡∫î‡∫û‡∫ß‡∫Å‡∫≠‡∫±‡∫ö‡∫õ‡∫µ‡ªÑ‡∫õ‡∫à‡∫≤‡∫Å‡∫õ‡∫∞‡ªÄ...    NaN\n",
            "2                                               ‡∫™‡∫≤‡∫ó‡∫∏    NaN\n",
            "3                                       ‡ªÄ‡∫ö‡∫¥‡ªà‡∫á‡∫´‡∫ô‡ªâ‡∫≤‡ªÅ‡∫î‡ªà    NaN\n",
            "4                               ‡∫à‡∫±‡∫ö‡ªÑ‡∫î‡ªâ‡∫ï‡∫≠‡ªâ‡∫á‡∫õ‡∫∞‡∫´‡∫≤‡∫ô‡∫ä‡∫¥‡∫ß‡∫¥‡∫î    NaN\n",
            "\n",
            "Final Shan Data Sample:\n",
            "                                                 text  label\n",
            "0  ·Äë·ÄΩ·Äô·Ä∫·Çá·Äö·Äù·Ä∫·Çâ·Åµ·Ä≠·Åº·Ä∫·Å∏·ÇÇ·Ä∫‚Äã·Äê·Ä±·Çâ·Åµ·ÇÇ·Å¢·Äô·Ä∫·Ä∏·ÇÅ·Ä∞·Äù·Ä∫·Åº·ÇÜ·Çâ ·Åº·Äô·Ä∫·Çâ·Äê·ÇÉ·Äö·Ä≠·ÄØ·ÄÑ·Ä∫·Çà...    NaN\n",
            "1                                 ·Äú·ÄÆ·Äë·ÄΩ·Äô·Ä∫·Çá·Äê·Ä±·Çâ·Äö·Äù·Ä∫·Çâ·Å∂·ÇÉ·Çà·Åã    NaN\n",
            "2                                             ·Å∂·Ä≠·ÄØ·Åµ·Ä∫·Çâ    NaN\n",
            "3            ·Äú·ÄØ·Åµ·Ä∫·Çà·Äú·Å¢·Åº·Ä∫·Äê·ÇÜ·Ä∏·Äú·ÄØ·Åµ·Ä∫·Çà·ÇÅ·ÄØ·Åº·Ä∫·Çà·Äô·ÇÇ·Ä∫·Çá·ÇÅ·Äù·Ä∫·Ä∏·Äô·Ä≠·Ä∞·Äù·Ä∫·Ä∏·Åº·ÇÉ·Çà    NaN\n",
            "4  ·Äô·ÇÇ·Ä∫·Çá·Äû·ÄØ·ÄÑ·Ä∫·Å∂·ÇÉ·Çà·Å∂·ÇÉ·Çà·ÇÅ·Äù·Ä∫·Ä∏·Äú·ÇÜ·Çà·ÇÅ·Åº·Ä∫·Å∏·ÄØ·Äô·Ä∫·Ä∏·Å∂·Äù·Ä∫·Çá·ÅΩ·Ä∞·Çà·Äê·ÄΩ·ÇÜ·Çá·ÇÅ·ÄΩ·Åµ·Ä∫·Çà·Äô...    NaN\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Define maximum character length\n",
        "max_length = 200\n",
        "\n",
        "# Load the datasets\n",
        "thai_df = pd.read_csv('/content/thai_test_data.csv')\n",
        "lao_df = pd.read_csv('/content/lao_test_data.csv')\n",
        "shan_df = pd.read_csv('/content/shan_test_data.csv')\n",
        "\n",
        "# Function to remove URLs and special characters, and clean text minimally\n",
        "def basic_clean_text(text):\n",
        "    text = re.sub(r'http\\S+|www.\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "    return text\n",
        "\n",
        "# Function to truncate text to max length\n",
        "def truncate_text(text, max_length):\n",
        "    return text[:max_length] if len(text) > max_length else text\n",
        "\n",
        "# Apply minimal cleaning and truncating to each dataset without dropping NaN labels\n",
        "def preprocess_dataframe_basic(df):\n",
        "    print(\"Initial Data Sample:\\n\", df.head())  # Initial data sample\n",
        "    df['text'] = df['text'].astype(str).apply(basic_clean_text)\n",
        "    print(\"Post-Cleaning Data Sample:\\n\", df.head())  # After cleaning\n",
        "    df['text'] = df['text'].apply(lambda x: truncate_text(x, max_length))\n",
        "    print(\"Post-Truncating Data Sample:\\n\", df.head())  # After truncating\n",
        "    return df\n",
        "\n",
        "# Preprocess each dataframe without filtering out NaN labels\n",
        "thai_df_cleaned = preprocess_dataframe_basic(thai_df)\n",
        "lao_df_cleaned = preprocess_dataframe_basic(lao_df)\n",
        "shan_df_cleaned = preprocess_dataframe_basic(shan_df)\n",
        "\n",
        "# Final samples for verification\n",
        "print(\"Final Thai Data Sample:\\n\", thai_df_cleaned.head())\n",
        "print(\"\\nFinal Lao Data Sample:\\n\", lao_df_cleaned.head())\n",
        "print(\"\\nFinal Shan Data Sample:\\n\", shan_df_cleaned.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load the toxic keywords from the CSV file\n",
        "keywords_df = pd.read_csv('/content/Toxic_Words_translations.csv')\n",
        "\n",
        "# Extract keywords for each language\n",
        "def extract_keywords_for_language(df, language_column):\n",
        "    # Drop NaN values and convert to a list\n",
        "    keywords = df[language_column].dropna().tolist()\n",
        "    # Ensure all keywords are strings\n",
        "    keywords = [str(keyword) for keyword in keywords]\n",
        "    return keywords\n",
        "\n",
        "# Extract keywords for each language\n",
        "thai_toxic_keywords = extract_keywords_for_language(keywords_df, 'Thai')\n",
        "lao_toxic_keywords = extract_keywords_for_language(keywords_df, 'Lao')\n",
        "shan_toxic_keywords = extract_keywords_for_language(keywords_df, 'Shan')\n",
        "\n",
        "# Function to label data based on toxic keywords\n",
        "def label_data_using_keywords(df, toxic_keywords):\n",
        "    # Compile regex pattern for faster matching\n",
        "    pattern = re.compile(r'\\b(' + '|'.join(map(re.escape, toxic_keywords)) + r')\\b', re.IGNORECASE)\n",
        "\n",
        "    # Function to check if text contains any toxic keywords\n",
        "    def check_toxic(text):\n",
        "        if pattern.search(text):\n",
        "            return 1  # Hate\n",
        "        else:\n",
        "            return 0  # Non-hate\n",
        "\n",
        "    # Apply the function to the 'text' column\n",
        "    df['label'] = df['text'].apply(check_toxic)\n",
        "    return df\n",
        "\n",
        "# Apply labeling to each dataset\n",
        "thai_df_labeled = label_data_using_keywords(thai_df_cleaned, thai_toxic_keywords)\n",
        "lao_df_labeled = label_data_using_keywords(lao_df_cleaned, lao_toxic_keywords)\n",
        "shan_df_labeled = label_data_using_keywords(shan_df_cleaned, shan_toxic_keywords)\n",
        "\n",
        "# Verify the new label distribution\n",
        "print(\"Thai Data Label Distribution:\\n\", thai_df_labeled['label'].value_counts())\n",
        "print(\"\\nLao Data Label Distribution:\\n\", lao_df_labeled['label'].value_counts())\n",
        "print(\"\\nShan Data Label Distribution:\\n\", shan_df_labeled['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EQv2DWraNIVi",
        "outputId": "4daf4926-aa1d-426b-c341-890caab0240b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thai Data Label Distribution:\n",
            " label\n",
            "0    23623\n",
            "1    17943\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Lao Data Label Distribution:\n",
            " label\n",
            "0    80\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Shan Data Label Distribution:\n",
            " label\n",
            "0    74\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to balance the dataset using oversampling\n",
        "def oversample_dataset(df):\n",
        "    # Separate minority and majority classes\n",
        "    hate_df = df[df['label'] == 1]\n",
        "    non_hate_df = df[df['label'] == 0]\n",
        "\n",
        "    # Calculate the number of samples in each class\n",
        "    num_hate = len(hate_df)\n",
        "    num_non_hate = len(non_hate_df)\n",
        "\n",
        "    # Check if either class is empty\n",
        "    if num_hate == 0 or num_non_hate == 0:\n",
        "        print(\"Warning: One of the classes is empty. Returning the original dataset.\")\n",
        "        return df.copy()\n",
        "\n",
        "    # Determine the class with the maximum samples\n",
        "    max_samples = max(num_hate, num_non_hate)\n",
        "\n",
        "    # Oversample the minority class\n",
        "    if num_hate < num_non_hate:\n",
        "        hate_df_oversampled = hate_df.sample(n=max_samples, replace=True, random_state=42)\n",
        "        non_hate_df_oversampled = non_hate_df\n",
        "    elif num_non_hate < num_hate:\n",
        "        non_hate_df_oversampled = non_hate_df.sample(n=max_samples, replace=True, random_state=42)\n",
        "        hate_df_oversampled = hate_df\n",
        "    else:\n",
        "        # Classes are already balanced\n",
        "        oversampled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "        return oversampled_df\n",
        "\n",
        "    # Combine and shuffle the dataset\n",
        "    oversampled_df = pd.concat([hate_df_oversampled, non_hate_df_oversampled]).sample(\n",
        "        frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    return oversampled_df\n",
        "\n",
        "# Apply the oversampling function to your datasets\n",
        "thai_df_oversampled = oversample_dataset(thai_df_labeled)\n",
        "lao_df_oversampled = oversample_dataset(lao_df_labeled)\n",
        "shan_df_oversampled = oversample_dataset(shan_df_labeled)\n",
        "\n",
        "# Verify the new label distribution\n",
        "print(\"Thai Data Label Distribution:\\n\", thai_df_oversampled['label'].value_counts())\n",
        "print(\"\\nLao Data Label Distribution:\\n\", lao_df_oversampled['label'].value_counts())\n",
        "print(\"\\nShan Data Label Distribution:\\n\", shan_df_oversampled['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zFWEi7QR-AJ7",
        "outputId": "cee73879-23c4-4426-cef8-3edbe337deb8"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: One of the classes is empty. Returning the original dataset.\n",
            "Thai Data Label Distribution:\n",
            " label\n",
            "0    23623\n",
            "1    23623\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Lao Data Label Distribution:\n",
            " label\n",
            "0    80\n",
            "1    80\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Shan Data Label Distribution:\n",
            " label\n",
            "0    74\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dREltNOnG5Yq",
        "outputId": "d499ce2d-c946-4671-f5b6-6c8d58a571c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders created for Thai, Lao, and Shan datasets.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize tokenizer (ensure it matches the model you fine-tuned)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\")\n",
        "\n",
        "class LanguageTestDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=200):\n",
        "        self.texts = texts\n",
        "        self.labels = labels.fillna(0).astype(int)  # Convert NaN to 0 for non-hate\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Indented block for __getitem__ method\n",
        "        text = self.texts.iloc[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long)  # Changed 'label' to 'labels'\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create dataset and dataloader for each language\n",
        "def create_dataloader(df, tokenizer, batch_size=8):\n",
        "    dataset = LanguageTestDataset(df['text'], df['label'], tokenizer)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "thai_dataloader = create_dataloader(thai_df_cleaned, tokenizer)\n",
        "lao_dataloader = create_dataloader(lao_df_cleaned, tokenizer)\n",
        "shan_dataloader = create_dataloader(shan_df_cleaned, tokenizer)\n",
        "\n",
        "\n",
        "print(\"DataLoaders created for Thai, Lao, and Shan datasets.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "collapsed": true,
        "id": "rMY8gbYIIAGJ",
        "outputId": "a2215932-ba14-41c4-a07a-3b0da5230143"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'load_state_dict'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-4aa89a1aaf21>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the saved model state dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes/cross_lingual_meta_learning_model_state.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmulti_task_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmulti_task_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmulti_task_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'load_state_dict'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "\n",
        "# Load the saved model state dictionary\n",
        "model_path = '/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes/cross_lingual_meta_learning_model_state.pth'\n",
        "multi_task_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "multi_task_model.to(device)\n",
        "multi_task_model.eval()\n",
        "\n",
        "# Load updated prototypes\n",
        "prototype_path = '/content/drive/MyDrive/cross_lingual_meta_learning_model_with_prototypes/updated_prototypes_few_shot.pth'\n",
        "updated_prototypes = torch.load(prototype_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_prototypes_with_weights(embeddings, labels, num_classes=2):\n",
        "    \"\"\"Calculate weighted prototypes for each class to emphasize core samples.\"\"\"\n",
        "    prototypes = []\n",
        "    for label in range(num_classes):\n",
        "        class_embeddings = embeddings[labels == label]\n",
        "        if class_embeddings.shape[0] > 0:\n",
        "            # Center the embeddings and compute distances\n",
        "            center = class_embeddings.mean(dim=0, keepdim=True)\n",
        "            distances = torch.norm(class_embeddings - center, dim=1)\n",
        "\n",
        "            # Calculate weights: closer embeddings have higher weights\n",
        "            weights = 1 / (distances + 1e-6)\n",
        "            weighted_embeddings = class_embeddings * weights.unsqueeze(1)\n",
        "            weighted_prototype = weighted_embeddings.sum(dim=0) / weights.sum()\n",
        "            prototypes.append(weighted_prototype)\n",
        "        else:\n",
        "            prototypes.append(torch.zeros(embeddings.shape[1]))  # Handle empty classes\n",
        "\n",
        "    return torch.stack(prototypes)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q5-thp3gZyd0"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import torch\n",
        "\n",
        "def evaluate_with_cosine_similarity(model, dataloader, prototypes):\n",
        "    \"\"\"Evaluate using cosine similarity to prototypes.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    prototypes = prototypes.to(device)  # Ensure prototypes are on the correct device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            label = batch['labels'].to(device)  # Changed 'label' to 'labels'\n",
        "\n",
        "            # Get embeddings from the model\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Handle different output structures\n",
        "            if hasattr(outputs, 'last_hidden_state'):\n",
        "                last_hidden_state = outputs.last_hidden_state\n",
        "            elif isinstance(outputs, tuple):\n",
        "                last_hidden_state = outputs[0]  # For models that return tuples\n",
        "            else:\n",
        "                raise ValueError(\"Unexpected model output structure.\")\n",
        "\n",
        "            embeddings = last_hidden_state[:, 0, :]  # Use [CLS] token representation\n",
        "\n",
        "            # Calculate cosine similarity to prototypes\n",
        "            similarities = torch.nn.functional.cosine_similarity(\n",
        "                embeddings.unsqueeze(1), prototypes.unsqueeze(0), dim=2\n",
        "            )\n",
        "            preds = torch.argmax(similarities, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(label.cpu().numpy())\n",
        "\n",
        "    # Calculate accuracy and F1-score\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    report = classification_report(all_labels, all_preds, target_names=[\"Non-hate\", \"Hate\"])\n",
        "\n",
        "    return accuracy, macro_f1, report\n"
      ],
      "metadata": {
        "id": "52i9qC6BfkIR"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_embeddings(model, dataloader):\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            batch_labels = batch['labels'].to(device)  # Changed 'label' to 'labels'\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "            # Assuming you use the last hidden state as embeddings\n",
        "            hidden_states = outputs.hidden_states[-1][:, 0, :]  # Use the [CLS] token representation\n",
        "            embeddings.append(hidden_states.cpu())\n",
        "            labels.append(batch_labels.cpu())\n",
        "    embeddings = torch.cat(embeddings)\n",
        "    labels = torch.cat(labels)\n",
        "    return embeddings, labels\n"
      ],
      "metadata": {
        "id": "Tc-8cXRY_It-"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize tokenizer (ensure it matches the model you fine-tuned)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Cross_Lingual_Meta_Learning_NEW\")\n",
        "\n",
        "# Define the dataset class\n",
        "class LanguageTestDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=200):\n",
        "        self.texts = texts.reset_index(drop=True)\n",
        "        self.labels = labels.fillna(0).astype(int).reset_index(drop=True)  # Convert NaN to 0 for non-hate\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts.iloc[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long)  # Use 'labels' as the key\n",
        "        }\n",
        "\n",
        "# Create dataset and dataloader for each language\n",
        "def create_dataloader(df, tokenizer, batch_size=8):\n",
        "    dataset = LanguageTestDataset(df['text'], df['label'], tokenizer)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Replace these with your actual cleaned DataFrames\n",
        "# thai_df_cleaned = ...\n",
        "# lao_df_cleaned = ...\n",
        "# shan_df_cleaned = ...\n",
        "\n",
        "thai_dataloader = create_dataloader(thai_df_cleaned, tokenizer)\n",
        "lao_dataloader = create_dataloader(lao_df_cleaned, tokenizer)\n",
        "shan_dataloader = create_dataloader(shan_df_cleaned, tokenizer)\n",
        "\n",
        "print(\"DataLoaders created for Thai, Lao, and Shan datasets.\")\n",
        "\n",
        "# Load your trained model\n",
        "# Ensure that the model is configured to output hidden states\n",
        "multi_task_model = AutoModel.from_pretrained(\"/content/drive/MyDrive/Cross_Lingual_Meta_Learning\", output_hidden_states=True)\n",
        "multi_task_model.to(device)\n",
        "\n",
        "# Define the embedding extraction function\n",
        "def extract_embeddings(model, dataloader):\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            batch_labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "            # Access the last hidden state\n",
        "            hidden_states = outputs.hidden_states[-1][:, 0, :]  # Use the [CLS] token representation\n",
        "            embeddings.append(hidden_states.cpu())\n",
        "            labels.append(batch_labels.cpu())\n",
        "    embeddings = torch.cat(embeddings)\n",
        "    labels = torch.cat(labels)\n",
        "    return embeddings, labels\n",
        "\n",
        "# Define the function to calculate weighted prototypes\n",
        "def calculate_prototypes_with_weights(embeddings, labels, num_classes=2):\n",
        "    \"\"\"Calculate weighted prototypes for each class to emphasize core samples.\"\"\"\n",
        "    prototypes = []\n",
        "    for label in range(num_classes):\n",
        "        class_embeddings = embeddings[labels == label]\n",
        "        if class_embeddings.shape[0] > 0:\n",
        "            # Center the embeddings and compute distances\n",
        "            center = class_embeddings.mean(dim=0, keepdim=True)\n",
        "            distances = torch.norm(class_embeddings - center, dim=1)\n",
        "\n",
        "            # Calculate weights: closer embeddings have higher weights\n",
        "            weights = 1 / (distances + 1e-6)\n",
        "            weighted_embeddings = class_embeddings * weights.unsqueeze(1)\n",
        "            weighted_prototype = weighted_embeddings.sum(dim=0) / weights.sum()\n",
        "            prototypes.append(weighted_prototype)\n",
        "        else:\n",
        "            prototypes.append(torch.zeros(embeddings.shape[1]))  # Handle empty classes\n",
        "\n",
        "    return torch.stack(prototypes)\n",
        "\n",
        "# Define the evaluation function\n",
        "def evaluate_with_cosine_similarity(model, dataloader, prototypes):\n",
        "    \"\"\"Evaluate using cosine similarity to prototypes.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    prototypes = prototypes.to(device)  # Ensure prototypes are on the correct device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            batch_labels = batch['labels'].to(device)\n",
        "\n",
        "            # Get embeddings from the model\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "\n",
        "            # Access hidden states\n",
        "            if hasattr(outputs, 'hidden_states'):\n",
        "                hidden_states = outputs.hidden_states[-1]\n",
        "            elif isinstance(outputs, tuple):\n",
        "                hidden_states = outputs[-1]  # For models that return tuples\n",
        "            else:\n",
        "                raise ValueError(\"Unexpected model output structure.\")\n",
        "\n",
        "            embeddings = hidden_states[:, 0, :]  # Use [CLS] token representation\n",
        "\n",
        "            # Calculate cosine similarity to prototypes\n",
        "            similarities = torch.nn.functional.cosine_similarity(\n",
        "                embeddings.unsqueeze(1), prototypes.unsqueeze(0), dim=2\n",
        "            )\n",
        "            preds = torch.argmax(similarities, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "    # Calculate accuracy and F1-score\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    report = classification_report(all_labels, all_preds, target_names=[\"Non-hate\", \"Hate\"])\n",
        "\n",
        "    return accuracy, macro_f1, report\n",
        "\n",
        "# Step 1: Extract embeddings for each language\n",
        "print(\"Extracting embeddings for Thai dataset...\")\n",
        "thai_embeddings, thai_labels = extract_embeddings(multi_task_model, thai_dataloader)\n",
        "print(\"Extracting embeddings for Lao dataset...\")\n",
        "lao_embeddings, lao_labels = extract_embeddings(multi_task_model, lao_dataloader)\n",
        "print(\"Extracting embeddings for Shan dataset...\")\n",
        "shan_embeddings, shan_labels = extract_embeddings(multi_task_model, shan_dataloader)\n",
        "\n",
        "# Step 2: Generate prototypes using the new weighted approach\n",
        "print(\"Calculating weighted prototypes for Thai dataset...\")\n",
        "updated_prototypes_thai = calculate_prototypes_with_weights(thai_embeddings, thai_labels, num_classes=2)\n",
        "print(\"Calculating weighted prototypes for Lao dataset...\")\n",
        "updated_prototypes_lao = calculate_prototypes_with_weights(lao_embeddings, lao_labels, num_classes=2)\n",
        "print(\"Calculating weighted prototypes for Shan dataset...\")\n",
        "updated_prototypes_shan = calculate_prototypes_with_weights(shan_embeddings, shan_labels, num_classes=2)\n",
        "\n",
        "# Step 3: Use the refined prototypes in evaluation\n",
        "print(\"\\nEvaluating Lao Test Set...\")\n",
        "accuracy, macro_f1, report = evaluate_with_cosine_similarity(\n",
        "    multi_task_model, lao_dataloader, updated_prototypes_lao\n",
        ")\n",
        "print(f\"Accuracy: {accuracy}\\nMacro F1: {macro_f1}\\n{report}\")\n",
        "\n",
        "print(\"\\nEvaluating Shan Test Set...\")\n",
        "accuracy, macro_f1, report = evaluate_with_cosine_similarity(\n",
        "    multi_task_model, shan_dataloader, updated_prototypes_shan\n",
        ")\n",
        "print(f\"Accuracy: {accuracy}\\nMacro F1: {macro_f1}\\n{report}\")\n"
      ],
      "metadata": {
        "id": "4Q-ws4UXVo0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5b044b33-3686-4958-98ec-3b0de8f81ab2"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders created for Thai, Lao, and Shan datasets.\n",
            "Extracting embeddings for Thai dataset...\n",
            "Extracting embeddings for Lao dataset...\n",
            "Extracting embeddings for Shan dataset...\n",
            "Calculating weighted prototypes for Thai dataset...\n",
            "Calculating weighted prototypes for Lao dataset...\n",
            "Calculating weighted prototypes for Shan dataset...\n",
            "\n",
            "Evaluating Lao Test Set...\n",
            "Accuracy: 0.7037037037037037\n",
            "Macro F1: 0.5533088235294118\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Non-hate       0.95      0.71      0.81        73\n",
            "        Hate       0.19      0.62      0.29         8\n",
            "\n",
            "    accuracy                           0.70        81\n",
            "   macro avg       0.57      0.67      0.55        81\n",
            "weighted avg       0.87      0.70      0.76        81\n",
            "\n",
            "\n",
            "Evaluating Shan Test Set...\n",
            "Accuracy: 0.5135135135135135\n",
            "Macro F1: 0.4322250639386189\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Non-hate       0.94      0.49      0.65        67\n",
            "        Hate       0.13      0.71      0.22         7\n",
            "\n",
            "    accuracy                           0.51        74\n",
            "   macro avg       0.54      0.60      0.43        74\n",
            "weighted avg       0.87      0.51      0.61        74\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2cf7cd1a6cb4291aa1513872980726c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3118c452da7d45c3be8e0b07881d9ed6",
              "IPY_MODEL_52e797caae8a48849d16960c17099781",
              "IPY_MODEL_0ed153b502ec455895d07e0696849b97"
            ],
            "layout": "IPY_MODEL_a10e2a287f9a4066a9e2e8e642e50935"
          }
        },
        "3118c452da7d45c3be8e0b07881d9ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6ae568d6a904d2497bc64c7047f5b54",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_188d2506ea864b5fa171458bbd13b7d2",
            "value": "README.md:‚Äá100%"
          }
        },
        "52e797caae8a48849d16960c17099781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea765a2de7af4466891b53a179f83f04",
            "max": 12125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0a202a25715488fb88ce951d7ae48e0",
            "value": 12125
          }
        },
        "0ed153b502ec455895d07e0696849b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd0daeb2de004500b8ec9fda4325554c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_08af85cb2afa473b9e059fd2696a21ea",
            "value": "‚Äá12.1k/12.1k‚Äá[00:00&lt;00:00,‚Äá830kB/s]"
          }
        },
        "a10e2a287f9a4066a9e2e8e642e50935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ae568d6a904d2497bc64c7047f5b54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "188d2506ea864b5fa171458bbd13b7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea765a2de7af4466891b53a179f83f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a202a25715488fb88ce951d7ae48e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd0daeb2de004500b8ec9fda4325554c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08af85cb2afa473b9e059fd2696a21ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0628f97d1999424c86ed4ba7e02a9629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e10df31544b446da1fba70cd9193b54",
              "IPY_MODEL_f0e0d7a9c2cf4c54aa712459f7f32378",
              "IPY_MODEL_65c2f3f4bc71453d804820af241eee98"
            ],
            "layout": "IPY_MODEL_a4a46e3807864bb2b8df48596e0e630b"
          }
        },
        "2e10df31544b446da1fba70cd9193b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b9d804121e94047a49a6fe90d23ff62",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cd9e18bc9dc24a149ec9bfb7c069b6aa",
            "value": "train-00000-of-00001.parquet:‚Äá100%"
          }
        },
        "f0e0d7a9c2cf4c54aa712459f7f32378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94a0c932bad446829b2d226ccccb6774",
            "max": 2582961,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b445c0b52e64b17924ea32e3cfaa512",
            "value": 2582961
          }
        },
        "65c2f3f4bc71453d804820af241eee98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23c4b5e5a2f1431c962ace49bf19ed8c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e11d112b78704b2a882d9df883bbafbd",
            "value": "‚Äá2.58M/2.58M‚Äá[00:00&lt;00:00,‚Äá42.8MB/s]"
          }
        },
        "a4a46e3807864bb2b8df48596e0e630b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b9d804121e94047a49a6fe90d23ff62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd9e18bc9dc24a149ec9bfb7c069b6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94a0c932bad446829b2d226ccccb6774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b445c0b52e64b17924ea32e3cfaa512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23c4b5e5a2f1431c962ace49bf19ed8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e11d112b78704b2a882d9df883bbafbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92ebe4161bb14c2986f5b549984af8a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b2c8675071e491a8508fe5143e67abe",
              "IPY_MODEL_4e78879c1b3440a38d24e620cd4be366",
              "IPY_MODEL_efb3e4245ebb4fbeaeed48f7d33a09e0"
            ],
            "layout": "IPY_MODEL_8dc09c800e72445cb9b97a31af95a002"
          }
        },
        "9b2c8675071e491a8508fe5143e67abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b580207825974b558aba8657c85ea7ea",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cec94597a1744a8483d93c0a23d2f38f",
            "value": "validation-00000-of-00001.parquet:‚Äá100%"
          }
        },
        "4e78879c1b3440a38d24e620cd4be366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0896c34f6c482397242bccd542709a",
            "max": 286045,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80506a1fedcf413e8e7bd396dd0938d3",
            "value": 286045
          }
        },
        "efb3e4245ebb4fbeaeed48f7d33a09e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a45de62ff38461ebf0393cffd9b5516",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_982251c1782047c2ae898d310dfbc502",
            "value": "‚Äá286k/286k‚Äá[00:00&lt;00:00,‚Äá21.3MB/s]"
          }
        },
        "8dc09c800e72445cb9b97a31af95a002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b580207825974b558aba8657c85ea7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cec94597a1744a8483d93c0a23d2f38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b0896c34f6c482397242bccd542709a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80506a1fedcf413e8e7bd396dd0938d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a45de62ff38461ebf0393cffd9b5516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "982251c1782047c2ae898d310dfbc502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb43c59e931a49299e6ddc5ec0c202e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1383531a913540539409f5dbcc069320",
              "IPY_MODEL_9deefa74148b413789ccbf7ab98dc55e",
              "IPY_MODEL_65ee7327f61746e19b5ddda4c29ac926"
            ],
            "layout": "IPY_MODEL_0e2f49d880334798a5bbfd714d56f3ba"
          }
        },
        "1383531a913540539409f5dbcc069320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5f1a980483a4a4580e1d5c8ef4e31a5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1d8222f82a0441899dcda7f0931c2f98",
            "value": "test-00000-of-00001.parquet:‚Äá100%"
          }
        },
        "9deefa74148b413789ccbf7ab98dc55e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9b8d40494a94156904b84f70bc0e740",
            "max": 326621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2fdfc120cc944dfba23897a505c266e",
            "value": 326621
          }
        },
        "65ee7327f61746e19b5ddda4c29ac926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72ab34eb123f472e9d97c7501e8c10bb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_12e49cab7bdb49a79316591a56ba2c10",
            "value": "‚Äá327k/327k‚Äá[00:00&lt;00:00,‚Äá25.3MB/s]"
          }
        },
        "0e2f49d880334798a5bbfd714d56f3ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5f1a980483a4a4580e1d5c8ef4e31a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8222f82a0441899dcda7f0931c2f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9b8d40494a94156904b84f70bc0e740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2fdfc120cc944dfba23897a505c266e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72ab34eb123f472e9d97c7501e8c10bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e49cab7bdb49a79316591a56ba2c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f16c58b03ac74c7c9064b608d2442bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1120ee0478e14ed6959baa94dcd07dc8",
              "IPY_MODEL_054d76747d3d44c49910467197672b97",
              "IPY_MODEL_35b900134f1c4c89ab49c62736a2224b"
            ],
            "layout": "IPY_MODEL_806409c4c2c146cea3d6d94316b73463"
          }
        },
        "1120ee0478e14ed6959baa94dcd07dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57f6abce6db24c7fbe58204af6b65043",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bcb7026577004223ab4dd97ef79403ce",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "054d76747d3d44c49910467197672b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28762ed72b01497e91493565a18aab52",
            "max": 21628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46432f44830249199059c1a67f195372",
            "value": 21628
          }
        },
        "35b900134f1c4c89ab49c62736a2224b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c50075952c246faac381eea8c77c413",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_06bcd787198f4df2bdf2a7b5e5c65f9e",
            "value": "‚Äá21628/21628‚Äá[00:00&lt;00:00,‚Äá307701.52‚Äáexamples/s]"
          }
        },
        "806409c4c2c146cea3d6d94316b73463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57f6abce6db24c7fbe58204af6b65043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb7026577004223ab4dd97ef79403ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28762ed72b01497e91493565a18aab52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46432f44830249199059c1a67f195372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c50075952c246faac381eea8c77c413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06bcd787198f4df2bdf2a7b5e5c65f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93599cf2909547d9b5fb75620abb2648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75e65585fbcd4b97ae8e375d01e77a49",
              "IPY_MODEL_c1de5707342345198153098fac4a3fec",
              "IPY_MODEL_a153d192673a410ab587bdabaa0445df"
            ],
            "layout": "IPY_MODEL_4e5387aede014891b997a2b9ef1f7a4f"
          }
        },
        "75e65585fbcd4b97ae8e375d01e77a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36772199650e473e9b16bb3096819e23",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_36a7dc31b5944daa91eba0909495ac7d",
            "value": "Generating‚Äávalidation‚Äásplit:‚Äá100%"
          }
        },
        "c1de5707342345198153098fac4a3fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65d222571a9f45ad9021daa3c358031b",
            "max": 2404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1b82cdd7da44a4eb2cd2bedc18d778a",
            "value": 2404
          }
        },
        "a153d192673a410ab587bdabaa0445df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee023fdebf364ff999d11b86d1c3966d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_42d4c72d60a144d19e1a6a6da7345549",
            "value": "‚Äá2404/2404‚Äá[00:00&lt;00:00,‚Äá129067.07‚Äáexamples/s]"
          }
        },
        "4e5387aede014891b997a2b9ef1f7a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36772199650e473e9b16bb3096819e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a7dc31b5944daa91eba0909495ac7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65d222571a9f45ad9021daa3c358031b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b82cdd7da44a4eb2cd2bedc18d778a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee023fdebf364ff999d11b86d1c3966d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d4c72d60a144d19e1a6a6da7345549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04736a9bfee2489a8d48287034a3c7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9203e02da3934a5f84a79c000469fe47",
              "IPY_MODEL_c1d668b7d3d647989618292b69233ba2",
              "IPY_MODEL_2aaa0f66f00f4035add3df4ffe9dd148"
            ],
            "layout": "IPY_MODEL_7d3538121f62480ea7b69d4368d9d8f3"
          }
        },
        "9203e02da3934a5f84a79c000469fe47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c3a416a7d364146b282e66eb80e4f90",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c81e80d34dd24920a790e8a74d64bcc1",
            "value": "Generating‚Äátest‚Äásplit:‚Äá100%"
          }
        },
        "c1d668b7d3d647989618292b69233ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43876c2aed454349b74378d659203168",
            "max": 2671,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be38420a570c46a4bf4b939857aaeb99",
            "value": 2671
          }
        },
        "2aaa0f66f00f4035add3df4ffe9dd148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd8342a1b9f24fca9b2c04414e63562a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0a2b24457db8447f811005561bce6af7",
            "value": "‚Äá2671/2671‚Äá[00:00&lt;00:00,‚Äá143731.22‚Äáexamples/s]"
          }
        },
        "7d3538121f62480ea7b69d4368d9d8f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c3a416a7d364146b282e66eb80e4f90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c81e80d34dd24920a790e8a74d64bcc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43876c2aed454349b74378d659203168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be38420a570c46a4bf4b939857aaeb99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd8342a1b9f24fca9b2c04414e63562a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a2b24457db8447f811005561bce6af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fda6576012014ec2ad39e1ac1963f9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b38bcc4386b4deeb8036b2f416b5138",
              "IPY_MODEL_0be306bc88974a34ac9ff94c4da978d8",
              "IPY_MODEL_ea80abf491d94e79a705f3a927033e28"
            ],
            "layout": "IPY_MODEL_ab444298634b4a30b65f1637c0478d1b"
          }
        },
        "1b38bcc4386b4deeb8036b2f416b5138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_465395b4d913421eb35eac1551dbdb9a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5f64be4f7ae541c698155452470434a0",
            "value": ""
          }
        },
        "0be306bc88974a34ac9ff94c4da978d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521b4cd838b541aa951ec05a3bd4e86d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd0932037fa84f5faf0b9ab132fadccd",
            "value": 0
          }
        },
        "ea80abf491d94e79a705f3a927033e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6995d9fb464248489cbd31495b65a656",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4b501fd493cc4bd28c5962510df5a902",
            "value": "‚Äá0/0‚Äá[00:00&lt;?,‚Äá?it/s]"
          }
        },
        "ab444298634b4a30b65f1637c0478d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "465395b4d913421eb35eac1551dbdb9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f64be4f7ae541c698155452470434a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "521b4cd838b541aa951ec05a3bd4e86d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bd0932037fa84f5faf0b9ab132fadccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6995d9fb464248489cbd31495b65a656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b501fd493cc4bd28c5962510df5a902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a16eadf161c9416aa87af3c325dabb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26b736f97dfc4017a01464a5a40d0b16",
              "IPY_MODEL_82883a924fe1467f9f767ba7514dfdc6",
              "IPY_MODEL_1206a6fb486c4839886df3b87735758d"
            ],
            "layout": "IPY_MODEL_ee9dfd48c1e643be901ce9ce03532ee7"
          }
        },
        "26b736f97dfc4017a01464a5a40d0b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fdfd52c5a9d4b96b0a3f742cc9d0614",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_44bbe2021fd44da5aabe73e6b4d93906",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "82883a924fe1467f9f767ba7514dfdc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9dcf5edbf2c4080b43d9a4271e885bc",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f162912f777649ee999b474a028ec2f8",
            "value": 49
          }
        },
        "1206a6fb486c4839886df3b87735758d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_507f5279b730462c9f40c29964261d63",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cbdaadb52d074972a4bd6ca8876a1b1d",
            "value": "‚Äá49.0/49.0‚Äá[00:00&lt;00:00,‚Äá3.83kB/s]"
          }
        },
        "ee9dfd48c1e643be901ce9ce03532ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fdfd52c5a9d4b96b0a3f742cc9d0614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44bbe2021fd44da5aabe73e6b4d93906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9dcf5edbf2c4080b43d9a4271e885bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f162912f777649ee999b474a028ec2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "507f5279b730462c9f40c29964261d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbdaadb52d074972a4bd6ca8876a1b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ab6ccb2f287436b9d3bf6ab00ef8bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8241707f7fb47afb7ccf3bc7a7fb4c2",
              "IPY_MODEL_e1acfd456e0a4c83aa054dab75a81a3e",
              "IPY_MODEL_1bca25fdcf174f5ab87401909675129a"
            ],
            "layout": "IPY_MODEL_9e2a6fac18b5490b9adb6f743bac3d1f"
          }
        },
        "d8241707f7fb47afb7ccf3bc7a7fb4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_394ed618ac384a8ca4bcc04c5dc7949c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2311402d4dd940d191e761b18874c9a8",
            "value": "config.json:‚Äá100%"
          }
        },
        "e1acfd456e0a4c83aa054dab75a81a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db435260964d4c9cb299560c8d5cd9f3",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b912e4c274c54e0c9902c9d13e25b948",
            "value": 625
          }
        },
        "1bca25fdcf174f5ab87401909675129a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6cac576f93c43f88118060e7082a47e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bddcf1bbc1a14be2bcec333ba9e9f42d",
            "value": "‚Äá625/625‚Äá[00:00&lt;00:00,‚Äá48.1kB/s]"
          }
        },
        "9e2a6fac18b5490b9adb6f743bac3d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394ed618ac384a8ca4bcc04c5dc7949c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2311402d4dd940d191e761b18874c9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db435260964d4c9cb299560c8d5cd9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b912e4c274c54e0c9902c9d13e25b948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6cac576f93c43f88118060e7082a47e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bddcf1bbc1a14be2bcec333ba9e9f42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b11cd67bb0d44bbfb64ac1a25d670cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a39bfa3b79b14e08a6d049fb838666f4",
              "IPY_MODEL_2ea12896d72e4a1d94ff43c7291f74b5",
              "IPY_MODEL_a86f9bd87edc40af87beaa22626c26fe"
            ],
            "layout": "IPY_MODEL_010ca851fc654ca3aabe653a0b06632c"
          }
        },
        "a39bfa3b79b14e08a6d049fb838666f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0418c54db15446259e77c4fc0850163b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7e3e77a5269b41f4aa356d9ad3644d69",
            "value": "vocab.txt:‚Äá100%"
          }
        },
        "2ea12896d72e4a1d94ff43c7291f74b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b9c73ec2de347a9b3239373e3c170f8",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eae9b2d6a25446b5b5d42a102c926b2e",
            "value": 995526
          }
        },
        "a86f9bd87edc40af87beaa22626c26fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f98dd2b2b24a402b99baec316055726c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fc2bdc15c8e14e6dada3058b07c4d539",
            "value": "‚Äá996k/996k‚Äá[00:00&lt;00:00,‚Äá1.53MB/s]"
          }
        },
        "010ca851fc654ca3aabe653a0b06632c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0418c54db15446259e77c4fc0850163b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e3e77a5269b41f4aa356d9ad3644d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b9c73ec2de347a9b3239373e3c170f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eae9b2d6a25446b5b5d42a102c926b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f98dd2b2b24a402b99baec316055726c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc2bdc15c8e14e6dada3058b07c4d539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b32053f09293467fb803d3ebd4cf4ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd38724a0e5f41c0bcd6e7c1d79a1e51",
              "IPY_MODEL_ff284cfdf86e4103909f52a33d11dd4d",
              "IPY_MODEL_882742bc71ad4172884fa414aa5584da"
            ],
            "layout": "IPY_MODEL_181b93166fc54544838c387139a6646d"
          }
        },
        "cd38724a0e5f41c0bcd6e7c1d79a1e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_476d1c84b5eb46bab99966efbf8f835d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0521fdf52b314ce98c83724027f709c7",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "ff284cfdf86e4103909f52a33d11dd4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92edb1a82293467c9dd6459fa098825c",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10500a12741d4aff9fc7d7cb304ccd59",
            "value": 1961828
          }
        },
        "882742bc71ad4172884fa414aa5584da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f0ffef357f54ffba8ae830d7da3f38f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3939ebb8eaba4e98a246b950e40dba52",
            "value": "‚Äá1.96M/1.96M‚Äá[00:00&lt;00:00,‚Äá8.67MB/s]"
          }
        },
        "181b93166fc54544838c387139a6646d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "476d1c84b5eb46bab99966efbf8f835d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0521fdf52b314ce98c83724027f709c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92edb1a82293467c9dd6459fa098825c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10500a12741d4aff9fc7d7cb304ccd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f0ffef357f54ffba8ae830d7da3f38f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3939ebb8eaba4e98a246b950e40dba52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7f2b92183774041904327d36043eac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4bb23ab0cce45869e00fed05abcfb99",
              "IPY_MODEL_dcd49e678d6d4804938c302492bead73",
              "IPY_MODEL_53845d48d4214abc8b6dcf162921deb0"
            ],
            "layout": "IPY_MODEL_bcf8271419f84777844977b90c7acb32"
          }
        },
        "d4bb23ab0cce45869e00fed05abcfb99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2240813d85054fc2b0f46036b4035841",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f508b649c1e24248ac4a6f5c30ad2b1e",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "dcd49e678d6d4804938c302492bead73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0b0234fd0c148ce9028e7358dee9aa4",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7de30b43417c49f9970dc814ec30b061",
            "value": 714290682
          }
        },
        "53845d48d4214abc8b6dcf162921deb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f84974caa4634ca8b8ed4fca81ad5b12",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8d87afca569d4a78bf337538229ef27a",
            "value": "‚Äá714M/714M‚Äá[00:03&lt;00:00,‚Äá219MB/s]"
          }
        },
        "bcf8271419f84777844977b90c7acb32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2240813d85054fc2b0f46036b4035841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f508b649c1e24248ac4a6f5c30ad2b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0b0234fd0c148ce9028e7358dee9aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de30b43417c49f9970dc814ec30b061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f84974caa4634ca8b8ed4fca81ad5b12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d87afca569d4a78bf337538229ef27a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}